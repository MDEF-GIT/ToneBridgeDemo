import { useState, useRef, useCallback, useEffect } from "react";

interface AudioRecordingState {
  isRecording: boolean;
  audioStream: MediaStream | null;
  audioContext: AudioContext | null;
  analyser: AnalyserNode | null;
  error: string | null;
  recordedBlob: Blob | null;
  isPlayingRecorded: boolean;
}

export const useAudioRecording = () => {
  const [state, setState] = useState<AudioRecordingState>({
    isRecording: false,
    audioStream: null,
    audioContext: null,
    analyser: null,
    error: null,
    recordedBlob: null,
    isPlayingRecorded: false,
  });

  const animationFrameRef = useRef<number | undefined>(undefined);
  const onPitchDataRef = useRef<
    ((frequency: number, timestamp: number) => void) | null
  >(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordedAudioRef = useRef<HTMLAudioElement | null>(null);

  // üéØ ÏÉÅÌÉú Î≥ÄÌôî Ï∂îÏ†Å Î°úÍ∑∏
  useEffect(() => {
    console.log('üéØ [STEP 3] Hook ÏÉÅÌÉú Î≥ÄÌôî Í∞êÏßÄ:', {
      'state.isPlayingRecorded': state.isPlayingRecorded,
      'state.recordedBlob': !!state.recordedBlob,
      'recordedAudioRef.current': !!recordedAudioRef.current
    });
  }, [state.isPlayingRecorded, state.recordedBlob]);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 44100,
        },
      });

      const audioContext = new AudioContext({ sampleRate: 44100 });
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);

      analyser.fftSize = 4096;
      analyser.smoothingTimeConstant = 0.3;
      source.connect(analyser);

      // Setup MediaRecorder for file saving
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
      });

      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, {
          type: "audio/webm",
        });

        setState((prev) => ({
          ...prev,
          recordedBlob: audioBlob,
        }));

        // Upload to backend
        await uploadRecordedAudio(audioBlob);
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start(1000); // Record in 1-second chunks

      setState((prev) => ({
        ...prev,
        isRecording: true,
        audioStream: stream,
        audioContext,
        analyser,
        error: null,
      }));

      // Start pitch detection
      const detectPitch = () => {
        if (!analyser) return;

        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Float32Array(bufferLength);
        analyser.getFloatFrequencyData(dataArray);

        // Simple pitch detection using autocorrelation
        const sampleRate = audioContext.sampleRate;
        const timeDomainData = new Float32Array(analyser.fftSize);
        analyser.getFloatTimeDomainData(timeDomainData);

        const frequency = autoCorrelate(timeDomainData, sampleRate);

        if (frequency > 0 && onPitchDataRef.current) {
          onPitchDataRef.current(frequency, Date.now());
        }

        animationFrameRef.current = requestAnimationFrame(detectPitch);
      };

      detectPitch();
    } catch (error) {
      setState((prev) => ({
        ...prev,
        error: `ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑º Ïã§Ìå®: ${error instanceof Error ? error.message : "Ïïå Ïàò ÏóÜÎäî Ïò§Î•ò"}`,
      }));
    }
  }, []);
  console.log("‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå");
  const stopRecording = useCallback(() => {
    console.log("‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå2222");
    if (animationFrameRef.current) {
      console.log("‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå33333");
      cancelAnimationFrame(animationFrameRef.current);
    }

    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      console.log("‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå44444");
      mediaRecorderRef.current.stop();
    }

    if (state.audioStream) {
      console.log("‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå55555");
      state.audioStream.getTracks().forEach((track) => track.stop());
    }

    if (state.audioContext) {
      console.log("‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå‚ùå66666");
      state.audioContext.close();
    }

    setState((prev) => ({
      ...prev,
      isRecording: false,
      audioStream: null,
      audioContext: null,
      analyser: null,
      error: null,
      recordedBlob: null,
    }));
  }, [state]);

  const uploadRecordedAudio = async (audioBlob: Blob) => {
    try {
      const formData = new FormData();
      formData.append("audio_data", audioBlob, "recording.webm");
      formData.append("session_id", `session_${Date.now()}`);

      const response = await fetch("/api/record_realtime", {
        method: "POST",
        body: formData,
      });

      if (response.ok) {
        console.log("‚úÖ ÎÖπÏùå ÌååÏùº ÏóÖÎ°úÎìú ÏÑ±Í≥µ");
      } else {
        console.error("‚ùå ÎÖπÏùå ÌååÏùº ÏóÖÎ°úÎìú Ïã§Ìå®:", response.statusText);
      }
    } catch (error) {
      console.error("‚ùå ÏóÖÎ°úÎìú Ï§ë Ïò§Î•ò:", error);
    }
  };

  const playRecordedAudio = useCallback(() => {
    console.log('üéØüéØüéØ [STEP 2] playRecordedAudio Ìï®Ïàò ÏßÑÏûÖ!');
    
    // ÌòÑÏû¨ ÏÉÅÌÉú ÏÉÅÏÑ∏ Î°úÍπÖ
    console.log('üéØ [STEP 2.1] ÌòÑÏû¨ Hook ÏÉÅÌÉú Ï≤¥ÌÅ¨:', {
      'state.recordedBlob': !!state.recordedBlob,
      'state.isPlayingRecorded': state.isPlayingRecorded,
      'state.isRecording': state.isRecording,
      'recordedAudioRef.current': !!recordedAudioRef.current
    });
    
    // ÌòÑÏû¨ ÏÉÅÌÉú ÌôïÏù∏
    if (!state.recordedBlob) {
      console.log("‚ùå [STEP 2.2] ÎÖπÏùåÎêú ÏùåÏÑ±Ïù¥ ÏóÜÏäµÎãàÎã§ - Ìï®Ïàò Ï¢ÖÎ£å");
      return;
    }
    console.log("‚úÖ [STEP 2.2] ÎÖπÏùåÎêú ÏùåÏÑ± Ï°¥Ïû¨ ÌôïÏù∏Îê®");

    // ÌòÑÏû¨ Ïû¨ÏÉù Ï§ëÏù¥Î©¥ Ï†ïÏßÄ
    if (state.isPlayingRecorded) {
      console.log("üõë [STEP 2.3] ÌòÑÏû¨ Ïû¨ÏÉù Ï§ë - Ï§ëÏßÄ ÌîÑÎ°úÏÑ∏Ïä§ ÏãúÏûë");
      
      if (recordedAudioRef.current) {
        console.log("üõë [STEP 2.3.1] Ïò§ÎîîÏò§ Î†àÌçºÎü∞Ïä§ Ï°¥Ïû¨ - pause() Ìò∏Ï∂ú");
        recordedAudioRef.current.pause();
        
        console.log("üõë [STEP 2.3.2] currentTime = 0 ÏÑ§Ï†ï");
        recordedAudioRef.current.currentTime = 0;
        
        console.log("üõë [STEP 2.3.3] Î†àÌçºÎü∞Ïä§ nullÎ°ú ÏÑ§Ï†ï");
        recordedAudioRef.current = null;
      } else {
        console.log("‚ö†Ô∏è [STEP 2.3.1] Ïò§ÎîîÏò§ Î†àÌçºÎü∞Ïä§Í∞Ä nullÏûÑ");
      }
      
      console.log("üõë [STEP 2.3.4] setStateÎ°ú isPlayingRecorded: false ÏÑ§Ï†ï");
      setState(prev => {
        console.log("üõë [STEP 2.3.5] setState ÏΩúÎ∞± Ïã§Ìñâ - Ïù¥Ï†Ñ ÏÉÅÌÉú:", prev.isPlayingRecorded);
        return { ...prev, isPlayingRecorded: false };
      });
      
      console.log("üõë [STEP 2.3.6] Ï§ëÏßÄ ÌîÑÎ°úÏÑ∏Ïä§ ÏôÑÎ£å - Ìï®Ïàò Ï¢ÖÎ£å");
      return;
    }
    console.log("‚úÖ [STEP 2.3] ÌòÑÏû¨ Ïû¨ÏÉù Ï§ëÏù¥ ÏïÑÎãò - Ïû¨ÏÉù ÏãúÏûë ÌîÑÎ°úÏÑ∏Ïä§Î°ú ÏßÑÌñâ");

    // Ïû¨ÏÉù ÏãúÏûë
    console.log("‚ñ∂Ô∏è [STEP 2.4] ÎÖπÏùåÏùåÏÑ± Ïû¨ÏÉù ÏãúÏûë ÌîÑÎ°úÏÑ∏Ïä§");
    try {
      console.log("‚ñ∂Ô∏è [STEP 2.4.1] URL.createObjectURL() Ìò∏Ï∂ú");
      const audioUrl = URL.createObjectURL(state.recordedBlob);
      console.log("‚ñ∂Ô∏è [STEP 2.4.2] Ïò§ÎîîÏò§ URL ÏÉùÏÑ± ÏôÑÎ£å:", audioUrl.substring(0, 50) + '...');
      
      console.log("‚ñ∂Ô∏è [STEP 2.4.3] new Audio() Í∞ùÏ≤¥ ÏÉùÏÑ±");
      const audio = new Audio(audioUrl);
      console.log("‚ñ∂Ô∏è [STEP 2.4.4] Ïò§ÎîîÏò§ Í∞ùÏ≤¥ ÏÉùÏÑ± ÏôÑÎ£å");

      console.log("‚ñ∂Ô∏è [STEP 2.4.5] recordedAudioRef.currentÏóê Ïò§ÎîîÏò§ Í∞ùÏ≤¥ Ìï†Îãπ");
      recordedAudioRef.current = audio;

      console.log("‚ñ∂Ô∏è [STEP 2.4.6] Ïù¥Î≤§Ìä∏ Î¶¨Ïä§ÎÑà ÏÑ§Ï†ï ÏãúÏûë");
      audio.onended = () => {
        console.log("üîö [EVENT] ÎÖπÏùåÏùåÏÑ± Ïû¨ÏÉù ÏôÑÎ£å Ïù¥Î≤§Ìä∏ Î∞úÏÉù");
        setState(prev => {
          console.log("üîö [EVENT] setStateÎ°ú isPlayingRecorded: false ÏÑ§Ï†ï");
          return { ...prev, isPlayingRecorded: false };
        });
        recordedAudioRef.current = null;
        URL.revokeObjectURL(audioUrl);
        console.log("üîö [EVENT] Ï†ïÎ¶¨ ÏûëÏóÖ ÏôÑÎ£å");
      };

      audio.onerror = (event) => {
        console.log("‚ùå [EVENT] ÎÖπÏùåÏùåÏÑ± Ïû¨ÏÉù Ïò§Î•ò Ïù¥Î≤§Ìä∏ Î∞úÏÉù:", event);
        setState(prev => {
          console.log("‚ùå [EVENT] setStateÎ°ú isPlayingRecorded: false ÏÑ§Ï†ï");
          return { ...prev, isPlayingRecorded: false };
        });
        recordedAudioRef.current = null;
        URL.revokeObjectURL(audioUrl);
        console.log("‚ùå [EVENT] Ïò§Î•ò Ï†ïÎ¶¨ ÏûëÏóÖ ÏôÑÎ£å");
      };
      console.log("‚ñ∂Ô∏è [STEP 2.4.7] Ïù¥Î≤§Ìä∏ Î¶¨Ïä§ÎÑà ÏÑ§Ï†ï ÏôÑÎ£å");

      // ÎπÑÎèôÍ∏∞ Ïû¨ÏÉù ÏãúÏûë
      console.log("‚ñ∂Ô∏è [STEP 2.4.8] audio.play() Ìò∏Ï∂ú ÏãúÏûë");
      audio.play().then(() => {
        console.log("‚úÖ [STEP 2.4.9] audio.play() ÏÑ±Í≥µ - Ïû¨ÏÉù ÏãúÏûëÎê®");
        setState(prev => {
          console.log("‚úÖ [STEP 2.4.10] setStateÎ°ú isPlayingRecorded: true ÏÑ§Ï†ï");
          return { ...prev, isPlayingRecorded: true };
        });
        console.log("‚úÖ [STEP 2.4.11] Ïû¨ÏÉù ÏãúÏûë ÌîÑÎ°úÏÑ∏Ïä§ ÏôÑÎ£å");
      }).catch((error) => {
        console.error("‚ùå [STEP 2.4.9] audio.play() Ïã§Ìå®:", error);
        setState(prev => {
          console.log("‚ùå [STEP 2.4.10] setStateÎ°ú isPlayingRecorded: false ÏÑ§Ï†ï");
          return { ...prev, isPlayingRecorded: false };
        });
        recordedAudioRef.current = null;
        URL.revokeObjectURL(audioUrl);
        console.log("‚ùå [STEP 2.4.11] Ïû¨ÏÉù Ïã§Ìå® Ï†ïÎ¶¨ ÏûëÏóÖ ÏôÑÎ£å");
      });

    } catch (error) {
      console.error("‚ùå [STEP 2.4] try-catch Î∏îÎ°ùÏóêÏÑú ÏòàÏô∏ Î∞úÏÉù:", error);
      setState(prev => {
        console.log("‚ùå [STEP 2.4.ERROR] setStateÎ°ú isPlayingRecorded: false ÏÑ§Ï†ï");
        return { ...prev, isPlayingRecorded: false };
      });
    }
    
    console.log('üéØüéØüéØ [STEP 2] playRecordedAudio Ìï®Ïàò Ï¢ÖÎ£å');
  }, [state.recordedBlob, state.isPlayingRecorded]);

  const setPitchCallback = useCallback(
    (callback: (frequency: number, timestamp: number) => void) => {
      onPitchDataRef.current = callback;
    },
    [],
  );

  return {
    ...state,
    startRecording,
    stopRecording,
    playRecordedAudio,
    setPitchCallback,
  };
};

// Autocorrelation pitch detection algorithm
function autoCorrelate(buffer: Float32Array, sampleRate: number): number {
  const SIZE = buffer.length;
  const MAX_SAMPLES = Math.floor(SIZE / 2);
  let bestOffset = -1;
  let bestCorrelation = 0;
  let rms = 0;
  let foundGoodCorrelation = false;
  const correlations = new Array(MAX_SAMPLES);

  for (let i = 0; i < SIZE; i++) {
    const val = buffer[i];
    rms += val * val;
  }
  rms = Math.sqrt(rms / SIZE);

  if (rms < 0.01) return -1;

  let lastCorrelation = 1;
  for (let offset = 1; offset < MAX_SAMPLES; offset++) {
    let correlation = 0;
    for (let i = 0; i < MAX_SAMPLES; i++) {
      correlation += Math.abs(buffer[i] - buffer[i + offset]);
    }
    correlation = 1 - correlation / MAX_SAMPLES;
    correlations[offset] = correlation;

    if (correlation > 0.9 && correlation > lastCorrelation) {
      foundGoodCorrelation = true;
      if (correlation > bestCorrelation) {
        bestCorrelation = correlation;
        bestOffset = offset;
      }
    } else if (foundGoodCorrelation) {
      const shift =
        (correlations[bestOffset + 1] - correlations[bestOffset - 1]) /
        correlations[bestOffset];
      return sampleRate / (bestOffset + 8 * shift);
    }
    lastCorrelation = correlation;
  }

  if (bestCorrelation > 0.01) {
    return sampleRate / bestOffset;
  }
  return -1;
}
