# ToneBridge Voice Analysis Demo - ì™„ì „ êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° ê°œìš”

```
voice-analysis-demo/
â”œâ”€â”€ backend_server.py          # FastAPI ë°±ì—”ë“œ ì„œë²„ (1765ì¤„)
â”œâ”€â”€ models.py                  # SQLAlchemy ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ (51ì¤„)
â”œâ”€â”€ templates/                 # Jinja2 HTML í…œí”Œë¦¿
â”‚   â”œâ”€â”€ base.html             # ê¸°ë³¸ ë ˆì´ì•„ì›ƒ (122ì¤„)
â”‚   â””â”€â”€ index.html            # ë©”ì¸ í˜ì´ì§€ (467ì¤„)
â”œâ”€â”€ static/                   # ì •ì  íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ css/custom.css        # ì‚¬ìš©ì ì •ì˜ ìŠ¤íƒ€ì¼ (714ì¤„)
â”‚   â””â”€â”€ js/audio-analysis.js  # ë©”ì¸ JavaScript (5188ì¤„)
â”œâ”€â”€ react-app/                # React TypeScript ë²„ì „
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ VoiceAnalysisApp.tsx  # ë©”ì¸ React ì»´í¬ë„ŒíŠ¸ (451ì¤„)
â”‚       â””â”€â”€ hooks/                # ì»¤ìŠ¤í…€ í›…ë“¤
â””â”€â”€ reference_files/          # ì°¸ì¡° ìŒì„± íŒŒì¼ë“¤ (WAV + TextGrid)
```

## ğŸ¯ í•µì‹¬ ê¸°ëŠ¥ë³„ ìƒì„¸ êµ¬í˜„ ë¶„ì„

### 1. WAV íŒŒì¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### 1.1 ë°±ì—”ë“œ WAV ì²˜ë¦¬ (backend_server.py)
**íŒŒì¼:** `voice-analysis-demo/backend_server.py`
**ë¼ì¸:** 965-1050

```python
# WAV íŒŒì¼ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze_ref", response_model=RefAnalysis)
async def analyze_ref(
    wav: UploadFile = File(..., description="Reference WAV"),
    textgrid: UploadFile = File(..., description="Reference TextGrid"),
    # ... ê¸°íƒ€ íŒŒë¼ë¯¸í„°ë“¤
):
    # íŒŒì¼ ê²€ì¦ (ë¼ì¸ 984-988)
    if wav.filename and not wav.filename.lower().endswith('.wav'):
        raise HTTPException(status_code=400, detail="WAV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # ë°”ì´íŠ¸ ë°ì´í„° ì½ê¸° (ë¼ì¸ 990-993)
    wav_bytes = await wav.read()
    tg_bytes = await textgrid.read()
    
    # ì„ì‹œ íŒŒì¼ ìƒì„± (ë¼ì¸ 996-1002)
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_temp:
        wav_temp.write(wav_bytes)
        wav_temp_path = wav_temp.name
```

#### 1.2 Parselmouthë¥¼ ì´ìš©í•œ ìŒì„± ë¶„ì„
**íŒŒì¼:** `voice-analysis-demo/backend_server.py`
**ë¼ì¸:** 1005-1010

```python
# Parselmouthë¡œ WAV íŒŒì¼ ë¡œë”©
import parselmouth as pm
snd = pm.Sound(wav_temp_path)

# í”¼ì¹˜ ë¶„ì„ ì„¤ì •
pitch_floor = 75.0    # ìµœì†Œ ì£¼íŒŒìˆ˜ (Hz)
pitch_ceiling = 600.0 # ìµœëŒ€ ì£¼íŒŒìˆ˜ (Hz)
time_step = 0.01      # ì‹œê°„ ê°„ê²© (ì´ˆ)
```

#### 1.3 í”„ë¡ íŠ¸ì—”ë“œ WAV ì—…ë¡œë“œ (audio-analysis.js)
**íŒŒì¼:** `voice-analysis-demo/static/js/audio-analysis.js`
**ë¼ì¸:** 675-720

```javascript
// WAV íŒŒì¼ ê²€ì¦ ë° FormData ìƒì„±
if (!$wav.files[0] || !$tg.files[0]) {
    throw new Error("WAV íŒŒì¼ê³¼ TextGrid íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.");
}

const fd = new FormData();
fd.append("wav", $wav.files[0]);
fd.append("textgrid", $tg.files[0]);

// ì„œë²„ë¡œ ì—…ë¡œë“œ
const resp = await fetch(`${API_BASE}/analyze_ref?t=${Date.now()}`, {
    method: "POST",
    body: fd,
    cache: 'no-cache',
    headers: {
        'Cache-Control': 'no-cache, no-store, must-revalidate',
        'Pragma': 'no-cache'
    }
});
```

### 2. TextGrid íŒŒì¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### 2.1 TextGrid íŒŒì‹± (backend_server.py)
**íŒŒì¼:** `voice-analysis-demo/backend_server.py`
**ë¼ì¸:** 140-210

```python
def parse_textgrid_praat_call(textgrid_path):
    """Parselmouthë¥¼ ì´ìš©í•œ TextGrid íŒŒì‹±"""
    try:
        import parselmouth as pm
        
        # TextGrid ë¡œë”©
        tg = pm.TextGrid.read(textgrid_path)
        
        # í‹°ì–´ ì •ë³´ ì¶”ì¶œ
        with open(textgrid_path, 'r', encoding='utf-8') as f:
            tg_content = f.read()
            
        # ì •ê·œì‹ì„ ì´ìš©í•œ ìŒì ˆ ì¶”ì¶œ
        import re
        interval_pattern = r'intervals\s*\[\s*(\d+)\s*\]:\s*\n\s*xmin\s*=\s*([0-9.]+)\s*\n\s*xmax\s*=\s*([0-9.]+)\s*\n\s*text\s*=\s*"([^"]*)"'
        
        intervals = re.findall(interval_pattern, tg_content)
        syllables = []
        
        for match in intervals:
            index, xmin, xmax, text = match
            if text.strip():  # ë¹ˆ í…ìŠ¤íŠ¸ ì œì™¸
                syllables.append({
                    "label": text.strip(),
                    "start": float(xmin),
                    "end": float(xmax)
                })
        
        return syllables
    except Exception as e:
        print(f"âŒ TextGrid íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []
```

#### 2.2 TextGrid HTML ì…ë ¥ ìš”ì†Œ
**íŒŒì¼:** `voice-analysis-demo/templates/index.html`
**ë¼ì¸:** ì—†ìŒ (íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹ ì‚¬ìš©)

TextGridëŠ” WAVì™€ í•¨ê»˜ FormDataë¡œ ì—…ë¡œë“œë©ë‹ˆë‹¤.

### 3. ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œìŠ¤í…œ

#### 3.1 WebAudio API ê¸°ë°˜ ì‹¤ì‹œê°„ ë…¹ìŒ
**íŒŒì¼:** `voice-analysis-demo/static/js/audio-analysis.js`
**ë¼ì¸:** 1200-1400 (ì¶”ì •)

```javascript
// AudioContext ì´ˆê¸°í™”
let audioCtx, micNode, procNode, analyserNode;

// ë§ˆì´í¬ ì ‘ê·¼ ë° ë…¹ìŒ ì‹œì‘
async function startRecording() {
    try {
        // ì‚¬ìš©ì ë¯¸ë””ì–´ ì ‘ê·¼
        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                sampleRate: realTimeCfg.sampleRate,
                channelCount: 1,
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false
            }
        });
        
        // AudioContext ìƒì„±
        audioCtx = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: realTimeCfg.sampleRate
        });
        
        // ë§ˆì´í¬ ë…¸ë“œ ìƒì„±
        micNode = audioCtx.createMediaStreamSource(stream);
        analyserNode = audioCtx.createAnalyser();
        analyserNode.fftSize = realTimeCfg.fftSize;
        
        // ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì‹± ë…¸ë“œ ìƒì„±
        procNode = audioCtx.createScriptProcessor(
            realTimeCfg.bufferSize, 1, 1
        );
        
        // ì‹¤ì‹œê°„ í”¼ì¹˜ ë¶„ì„ ì½œë°±
        procNode.onaudioprocess = function(e) {
            const inputBuffer = e.inputBuffer.getChannelData(0);
            const pitch = yinPitchDetector.getPitch(inputBuffer);
            
            if (pitch > 0) {
                const currentTime = audioCtx.currentTime;
                const semitone = 12 * Math.log2(pitch / refMedian);
                
                // ì°¨íŠ¸ì— ì‹¤ì‹œê°„ ë°ì´í„° ì¶”ê°€
                addRealTimePitchData({
                    x: currentTime,
                    y: semitone,
                    frequency: pitch
                });
            }
        };
        
        // ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²°
        micNode.connect(analyserNode);
        analyserNode.connect(procNode);
        procNode.connect(audioCtx.destination);
        
        isRecording = true;
        
    } catch (error) {
        console.error('ğŸš¨ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
        throw error;
    }
}
```

#### 3.2 YIN í”¼ì¹˜ ê²€ì¶œ ì•Œê³ ë¦¬ì¦˜
**íŒŒì¼:** `voice-analysis-demo/static/js/audio-analysis.js`
**ë¼ì¸:** 149-250

```javascript
class YINPitchDetector {
    constructor(sampleRate = 16000, bufferSize = 4096) {
        this.sampleRate = sampleRate;
        this.bufferSize = bufferSize;
        this.threshold = 0.15;
        this.yinBuffer = new Float32Array(bufferSize / 2);
    }

    // ì°¨ë¶„ í•¨ìˆ˜ ê³„ì‚° (ë¼ì¸ 160-171)
    differenceFunction(buffer) {
        const N = this.bufferSize;
        const maxTau = this.yinBuffer.length;
        
        for (let tau = 0; tau < maxTau; tau++) {
            this.yinBuffer[tau] = 0;
            for (let i = 0; i < N - maxTau; i++) {
                const delta = buffer[i] - buffer[i + tau];
                this.yinBuffer[tau] += delta * delta;
            }
        }
    }

    // ëˆ„ì  í‰ê·  ì •ê·œí™” (ë¼ì¸ 173-182)
    cumulativeMeanNormalizedDifferenceFunction() {
        this.yinBuffer[0] = 1;
        let runningSum = 0;
        
        for (let tau = 1; tau < this.yinBuffer.length; tau++) {
            runningSum += this.yinBuffer[tau];
            this.yinBuffer[tau] *= tau / runningSum;
        }
    }

    // í”¼ì¹˜ ê²€ì¶œ ë©”ì¸ í•¨ìˆ˜
    getPitch(buffer) {
        this.differenceFunction(buffer);
        this.cumulativeMeanNormalizedDifferenceFunction();
        const tau = this.absoluteThreshold();
        
        if (tau !== 0) {
            const betterTau = this.parabolicInterpolation(tau);
            return this.sampleRate / betterTau;
        }
        
        return 0; // í”¼ì¹˜ ê²€ì¶œ ì‹¤íŒ¨
    }
}
```

#### 3.3 ì‹¤ì‹œê°„ ë…¹ìŒ ë²„íŠ¼ UI
**íŒŒì¼:** `voice-analysis-demo/templates/index.html`
**ë¼ì¸:** 229-237

```html
<!-- í†µí•© ë…¹ìŒ ë²„íŠ¼ -->
<button id="btnUnifiedRecord" class="btn btn-sm" disabled 
        style="background-color: #e67e22; border-color: #e67e22; color: white;">
    <i class="fas fa-microphone me-1"></i> <strong>ë…¹ìŒ</strong>
</button>

<!-- ì •ì§€ ë²„íŠ¼ -->
<button id="btnStopRecord" class="btn btn-sm btn-outline-danger" disabled>
    <i class="fas fa-stop me-1"></i> <strong>ì •ì§€</strong>
</button>
```

### 4. Chart.jsë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ì‹œê°í™”

#### 4.1 Chart.js ì„¤ì • ë° ì´ˆê¸°í™”
**íŒŒì¼:** `voice-analysis-demo/templates/base.html`
**ë¼ì¸:** 41-59

```html
<!-- Chart.js ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© -->
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-annotation@3"></script>

<script>
// annotation í”ŒëŸ¬ê·¸ì¸ ë“±ë¡
document.addEventListener('DOMContentLoaded', function() {
    if (typeof Chart !== 'undefined' && typeof window.chartjs !== 'undefined') {
        Chart.register(window.chartjs.annotation);
        console.log('ğŸ¯ Chart.js annotation í”ŒëŸ¬ê·¸ì¸ ë“±ë¡ ì™„ë£Œ');
    }
});
</script>
```

#### 4.2 ì°¨íŠ¸ ìº”ë²„ìŠ¤ HTML
**íŒŒì¼:** `voice-analysis-demo/templates/index.html`
**ë¼ì¸:** 268-324

```html
<div class="card-body px-2 py-2">
    <div class="chart-container" style="position: relative; height: 500px;">
        <!-- ë©”ì¸ ì°¨íŠ¸ ìº”ë²„ìŠ¤ -->
        <canvas id="chart"></canvas>
        
        <!-- í‚¤ ì¡°ì • ì»¨íŠ¸ë¡¤ (ìš°ì¸¡ í•˜ë‹¨) -->
        <div id="pitchAdjustmentButtons" style="position: absolute; bottom: 10px; right: 10px;">
            <button id="btnPitchDown" class="btn btn-sm btn-outline-success">
                <i class="fas fa-arrow-down"></i>
            </button>
            <button id="btnPitchUp" class="btn btn-sm btn-outline-success">
                <i class="fas fa-arrow-up"></i>
            </button>
        </div>
        
        <!-- í™•ëŒ€/ìŠ¤í¬ë¡¤ ì»¨íŠ¸ë¡¤ (ìš°ì¸¡ ìƒë‹¨) -->
        <div style="position: absolute; top: 10px; right: 10px;">
            <button id="btnZoomIn" class="btn btn-sm btn-outline-primary">
                <i class="fas fa-search-plus"></i>
            </button>
            <button id="btnZoomOut" class="btn btn-sm btn-outline-primary">
                <i class="fas fa-search-minus"></i>
            </button>
        </div>
    </div>
</div>
```

#### 4.3 ì°¨íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ (JavaScript)
**íŒŒì¼:** `voice-analysis-demo/static/js/audio-analysis.js`
**ë¼ì¸:** 833-850

```javascript
// ì°¸ì¡° ê³¡ì„  ë°ì´í„° ì—…ë°ì´íŠ¸
const chartData = refCurve.map(p => ({x: p.t, y: p.semitone || 0}));
chart.data.datasets[0].data = chartData;  // Dataset 0: ì°¸ì¡° ì–µì–‘ íŒ¨í„´

// ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ ë°ì´í„° ì—…ë°ì´íŠ¸ (ë¼ì¸ 901-910)
if (chart.data.datasets[1] && syllableCenterPoints.length > 0) {
    chart.data.datasets[1].data = syllableCenterPoints;  // Dataset 1: ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜
    chart.data.datasets[1].hidden = false;
    
    // ê°•ì œ ì°¨íŠ¸ ì¬ë Œë”ë§
    chart.update('none');
}
```

### 5. ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸

#### 5.1 SQLAlchemy ëª¨ë¸ ì •ì˜
**íŒŒì¼:** `voice-analysis-demo/models.py`
**ë¼ì¸:** 1-51

```python
from sqlalchemy import Column, Integer, String, Text, DateTime, Boolean, Float
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

# ì‚¬ìš©ì ëª¨ë¸ (ë¼ì¸ 9-15)
class User(UserMixin, Base):
    __tablename__ = 'user'
    id = Column(Integer, primary_key=True)
    username = Column(String(64), unique=True, nullable=False)
    email = Column(String(120), unique=True, nullable=False)
    password_hash = Column(String(256))
    created_at = Column(DateTime, default=datetime.utcnow)

# ë¶„ì„ ì„¸ì…˜ ëª¨ë¸ (ë¼ì¸ 17-24)
class AnalysisSession(Base):
    __tablename__ = 'analysis_session'
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey('user.id'), nullable=True)
    session_data = Column(Text)  # JSON ë°ì´í„°
    created_at = Column(DateTime, default=datetime.utcnow)
    session_type = Column(String(50))  # 'reference', 'realtime' ë“±

# ì°¸ì¡° íŒŒì¼ ëª¨ë¸ (ë¼ì¸ 34-50)
class ReferenceFile(Base):
    __tablename__ = 'reference_file'
    id = Column(Integer, primary_key=True)
    title = Column(String(200), nullable=False)
    wav_filename = Column(String(255), nullable=False)
    textgrid_filename = Column(String(255), nullable=False)
    duration = Column(Float)  # ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
    average_f0 = Column(Float)  # í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ (Hz)
    detected_gender = Column(String(10))  # 'male'/'female'
    is_public = Column(Boolean, default=True)
```

### 6. CSS ìŠ¤íƒ€ì¼ë§ ì‹œìŠ¤í…œ

#### 6.1 ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì„¤ì •
**íŒŒì¼:** `voice-analysis-demo/static/css/custom.css`
**ë¼ì¸:** 6-42

```css
/* Pretendard í°íŠ¸ ì ìš© */
body {
    font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, 
                 Roboto, 'Helvetica Neue', 'Segoe UI', 'Apple SD Gothic Neo', 
                 'Noto Sans KR', 'Malgun Gothic', sans-serif;
    font-feature-settings: 'tnum';
    font-variant-numeric: tabular-nums;
    font-weight: 400;
}

/* í—¤ë”© ìš”ì†Œ í°íŠ¸ */
h1, h2, h3, h4, h5, h6 {
    font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, sans-serif !important;
    font-weight: 600;
}
```

#### 6.2 ë…¹ìŒ ë²„íŠ¼ ì• ë‹ˆë©”ì´ì…˜
**íŒŒì¼:** `voice-analysis-demo/static/css/custom.css`
**ë¼ì¸:** 74-130

```css
/* ë…¹ìŒ ì¤‘ í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ */
.recording-pulse {
    animation: recording-pulse 1.5s ease-in-out infinite;
}

@keyframes recording-pulse {
    0% { transform: scale(1); opacity: 1; }
    50% { transform: scale(1.1); opacity: 0.7; }
    100% { transform: scale(1); opacity: 1; }
}

/* ë…¹ìŒ ë²„íŠ¼ ê¸€ë¡œìš° íš¨ê³¼ */
.btn-recording {
    animation: btn-recording-glow 2s ease-in-out infinite;
    position: relative;
    overflow: hidden;
}

@keyframes btn-recording-glow {
    0% { box-shadow: 0 0 5px rgba(220, 53, 69, 0.5); }
    50% { box-shadow: 0 0 20px rgba(220, 53, 69, 0.8); }
    100% { box-shadow: 0 0 5px rgba(220, 53, 69, 0.5); }
}
```

#### 6.3 ì°¨íŠ¸ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼
**íŒŒì¼:** `voice-analysis-demo/static/css/custom.css`
**ë¼ì¸:** 66-72

```css
/* Chart container for light mode */
.chart-container {
    background: #ffffff;
    border: 1px solid #e0e0e0;
    border-radius: 0.5rem;
    padding: 1rem;
}
```

### 7. React ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°

#### 7.1 ë©”ì¸ React ì»´í¬ë„ŒíŠ¸
**íŒŒì¼:** `voice-analysis-demo/react-app/src/VoiceAnalysisApp.tsx`
**ë¼ì¸:** 1-50

```typescript
import React, { useState, useEffect, useRef } from 'react';
import { useAudioRecording } from './hooks/useAudioRecording';
import { usePitchChart } from './hooks/usePitchChart';

// íƒ€ì… ì •ì˜
interface LearnerInfo {
    name: string;
    gender: 'male' | 'female' | '';
    level: string;
}

interface ReferenceFile {
    id: string;
    sentence_text: string;
    duration: number;
    detected_gender: string;
    average_f0: number;
}

const VoiceAnalysisApp: React.FC = () => {
    // ìƒíƒœ ê´€ë¦¬
    const [learnerInfo, setLearnerInfo] = useState<LearnerInfo>({
        name: '', gender: '', level: ''
    });
    const [learningMethod, setLearningMethod] = useState<string>('');
    
    // ì»¤ìŠ¤í…€ í›… ì‚¬ìš©
    const audioRecording = useAudioRecording();
    const pitchChart = usePitchChart(canvasRef);
    
    // ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    useEffect(() => {
        loadReferenceFiles();
        audioRecording.setPitchCallback((frequency: number, timestamp: number) => {
            pitchChart.addPitchData(frequency, timestamp, 'live');
        });
    }, []);
    
    return (
        // JSX ë Œë”ë§...
    );
};
```

## ğŸ”§ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì˜ì¡´ì„±

### JavaScript/Frontend
- **Chart.js 4.4.0**: ì‹¤ì‹œê°„ ì°¨íŠ¸ ì‹œê°í™”
- **chartjs-plugin-annotation 3.0.1**: ì°¨íŠ¸ ì£¼ì„ ê¸°ëŠ¥
- **Bootstrap 5.3.3**: UI í”„ë ˆì„ì›Œí¬
- **Font Awesome 6.5.1**: ì•„ì´ì½˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Pretendard í°íŠ¸**: í•œêµ­ì–´ ìµœì í™” í°íŠ¸

### Python/Backend
- **FastAPI 0.104.1**: ê³ ì„±ëŠ¥ ì›¹ API í”„ë ˆì„ì›Œí¬
- **uvicorn 0.24.0**: ASGI ì„œë²„
- **praat-parselmouth 0.4.3**: ìŒì„± ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **SQLAlchemy 2.0.23**: ORM ë°ì´í„°ë² ì´ìŠ¤
- **numpy 1.25.2**: ìˆ˜ì¹˜ ì—°ì‚°
- **jinja2 3.1.2**: í…œí”Œë¦¿ ì—”ì§„

### React (ì„ íƒì‚¬í•­)
- **React 19.1.1**: UI ë¼ì´ë¸ŒëŸ¬ë¦¬
- **TypeScript 4.9.5**: ì •ì  íƒ€ì… ì–¸ì–´
- **axios 1.6.0**: HTTP í´ë¼ì´ì–¸íŠ¸
- **@tanstack/react-query 5.0.0**: ì„œë²„ ìƒíƒœ ê´€ë¦¬

## ğŸš€ ì‹¤í–‰ ë° ë°°í¬

### ê°œë°œ í™˜ê²½ ì‹¤í–‰
```bash
# Python ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# Node.js ì˜ì¡´ì„± ì„¤ì¹˜
npm install concurrently
cd react-app && npm install && cd ..

# ì„œë²„ ì‹¤í–‰ (í¬íŠ¸ 5000)
uvicorn backend_server:app --host 0.0.0.0 --port 5000 --reload
```

### í”„ë¡œë•ì…˜ ë°°í¬
```bash
# ê°€ìƒí™˜ê²½ ì„¤ì •
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ë˜ëŠ” venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ì„œë²„ ì‹¤í–‰
./run.sh  # ë˜ëŠ” run.bat (Windows)
```

## ğŸ“ êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­

1. **CORS ì„¤ì •**: ê°œë°œ/í”„ë¡œë•ì…˜ í™˜ê²½ì— ë§ëŠ” CORS ì •ì±… ì„¤ì •
2. **íŒŒì¼ ì—…ë¡œë“œ ì œí•œ**: WAV/TextGrid íŒŒì¼ í¬ê¸° ë° í˜•ì‹ ê²€ì¦
3. **ë¸Œë¼ìš°ì € í˜¸í™˜ì„±**: WebAudio API ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
4. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
5. **ì—ëŸ¬ í•¸ë“¤ë§**: ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ë° ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì˜¤ë¥˜ ì²˜ë¦¬

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ToneBridgeì™€ ë™ì¼í•œ ìŒì„± ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì™„ì „íˆ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.