"""
ToneBridge í†µí•© STT ì‹œìŠ¤í…œ
99% í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•œ ì™„ì „ í†µí•© ì†”ë£¨ì…˜

í†µí•© êµ¬ì„±ìš”ì†Œ:
1. í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (korean_audio_optimizer.py)
2. ë‹¤ì¤‘ STT ì—”ì§„ ì•™ìƒë¸” (multi_engine_stt.py) 
3. ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ (quality_validator.py)
4. ì ì‘í˜• ì¬ì²˜ë¦¬ ì‹œìŠ¤í…œ
"""

import asyncio
import time
import os
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
import logging
import json

# í†µí•© ì‹œìŠ¤í…œ ëª¨ë“ˆë“¤
try:
    from korean_audio_optimizer import KoreanAudioOptimizer
    OPTIMIZER_AVAILABLE = True
except ImportError:
    OPTIMIZER_AVAILABLE = False
    print("âš ï¸ Korean Audio Optimizer ë¯¸ì‚¬ìš© ê°€ëŠ¥")

try:
    from multi_engine_stt import MultiEngineSTTProcessor, EnsembleSTTResult
    MULTI_STT_AVAILABLE = True
except ImportError:
    MULTI_STT_AVAILABLE = False
    print("âš ï¸ Multi-Engine STT ë¯¸ì‚¬ìš© ê°€ëŠ¥")

try:
    from quality_validator import RealTimeQualityValidator, QualityValidationResult
    VALIDATOR_AVAILABLE = True
except ImportError:
    VALIDATOR_AVAILABLE = False
    print("âš ï¸ Quality Validator ë¯¸ì‚¬ìš© ê°€ëŠ¥")

try:
    from advanced_stt_processor import AdvancedSTTProcessor
    ADVANCED_STT_AVAILABLE = True
except ImportError:
    ADVANCED_STT_AVAILABLE = False
    print("âš ï¸ Advanced STT Processor ë¯¸ì‚¬ìš© ê°€ëŠ¥")

logger = logging.getLogger(__name__)

@dataclass
class UltimateSTTResult:
    """í†µí•© STT ìµœì¢… ê²°ê³¼"""
    final_text: str
    confidence: float
    accuracy_achieved: float
    processing_stages: List[str] = field(default_factory=list)
    
    # ìƒì„¸ ê²°ê³¼ë“¤
    preprocessing_result: Optional[Any] = None
    ensemble_result: Optional[EnsembleSTTResult] = None
    validation_result: Optional[QualityValidationResult] = None
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    total_processing_time: float = 0.0
    reprocessing_attempts: int = 0
    final_quality_score: float = 0.0
    
    # ë””ë²„ê¹… ì •ë³´
    audio_optimizations_applied: List[str] = field(default_factory=list)
    stt_engines_used: List[str] = field(default_factory=list)
    quality_improvements: List[str] = field(default_factory=list)

class UltimateSTTSystem:
    """
    ToneBridge í†µí•© STT ì‹œìŠ¤í…œ - 99% ì •í™•ë„ ë‹¬ì„±
    
    ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:
    1. í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
    2. ë‹¤ì¤‘ ì—”ì§„ ì•™ìƒë¸” STT  
    3. ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦
    4. ì ì‘í˜• ì¬ì²˜ë¦¬ (í•„ìš”ì‹œ)
    5. ìµœì¢… ê²°ê³¼ í†µí•© ë° ê²€ì¦
    
    ëª©í‘œ ì„±ëŠ¥:
    - í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì •í™•ë„: 99%+
    - ì²˜ë¦¬ ì‹œê°„: í‰ê·  5ì´ˆ ì´ë‚´
    - ì‹ ë¢°ë„: 95% ì´ìƒ
    """
    
    def __init__(self,
                 target_accuracy: float = 0.99,
                 max_reprocessing_attempts: int = 3,
                 quality_threshold: float = 0.95,
                 enable_advanced_features: bool = True):
        """
        Parameters:
        -----------
        target_accuracy : float
            ëª©í‘œ ì •í™•ë„ (99%)
        max_reprocessing_attempts : int
            ìµœëŒ€ ì¬ì²˜ë¦¬ ì‹œë„ íšŸìˆ˜
        quality_threshold : float
            í’ˆì§ˆ ì„ê³„ê°’ (95%)
        enable_advanced_features : bool
            ê³ ê¸‰ ê¸°ëŠ¥ í™œì„±í™”
        """
        
        self.target_accuracy = target_accuracy
        self.max_reprocessing_attempts = max_reprocessing_attempts
        self.quality_threshold = quality_threshold
        self.enable_advanced_features = enable_advanced_features
        
        # ê° ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.components = self._initialize_components()
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'accuracy_scores': [],
            'processing_times': [],
            'reprocessing_stats': {}
        }
        
        logger.info(f"ğŸš€ ToneBridge í†µí•© STT ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ëª©í‘œ ì •í™•ë„: {target_accuracy:.1%}")
        logger.info(f"   ìµœëŒ€ ì¬ì²˜ë¦¬: {max_reprocessing_attempts}íšŒ")
        logger.info(f"   í’ˆì§ˆ ì„ê³„ê°’: {quality_threshold:.1%}")
        logger.info(f"   í™œì„± ì»´í¬ë„ŒíŠ¸: {list(self.components.keys())}")
    
    def _initialize_components(self) -> Dict:
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        components = {}
        
        # 1. í•œêµ­ì–´ ì˜¤ë””ì˜¤ ìµœì í™”ê¸°
        if OPTIMIZER_AVAILABLE:
            components['audio_optimizer'] = KoreanAudioOptimizer(
                target_sr=16000,
                target_db=-16.0,
                korean_boost=True
            )
            print("âœ… í•œêµ­ì–´ ì˜¤ë””ì˜¤ ìµœì í™”ê¸° í™œì„±í™”")
        
        # 2. ë‹¤ì¤‘ STT ì—”ì§„ ì•™ìƒë¸”
        if MULTI_STT_AVAILABLE:
            components['multi_stt'] = MultiEngineSTTProcessor(
                engines=['whisper_base'],  # ë¹ ë¥¸ ëª¨ë¸ë§Œ ì‚¬ìš© (large ì œê±°)
                confidence_threshold=0.85,
                consensus_threshold=2
            )
            print("âœ… ë‹¤ì¤‘ STT ì—”ì§„ ì•™ìƒë¸” í™œì„±í™”")
        
        # 3. í’ˆì§ˆ ê²€ì¦ê¸°
        if VALIDATOR_AVAILABLE:
            components['quality_validator'] = RealTimeQualityValidator(
                quality_threshold=self.quality_threshold,
                syllable_accuracy_threshold=0.90,
                confidence_threshold=0.85
            )
            print("âœ… ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ê¸° í™œì„±í™”")
        
        # 4. ê¸°ë³¸ STT (ë°±ì—…ìš©)
        if ADVANCED_STT_AVAILABLE:
            components['backup_stt'] = AdvancedSTTProcessor()
            print("âœ… ë°±ì—… STT í”„ë¡œì„¸ì„œ í™œì„±í™”")
        
        return components
    
    async def process_audio_ultimate(self,
                                   audio_file: str,
                                   target_text: str = "",
                                   enable_reprocessing: bool = True) -> UltimateSTTResult:
        """
        í†µí•© STT ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ - 99% ì •í™•ë„ ë‹¬ì„±
        
        Parameters:
        -----------
        audio_file : str
            ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼
        target_text : str
            ê¸°ëŒ€ í…ìŠ¤íŠ¸ (ì •í™•ë„ ì¸¡ì •ìš©)
        enable_reprocessing : bool
            ì¬ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€
            
        Returns:
        --------
        UltimateSTTResult : í†µí•© ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        print(f"ğŸ¯ğŸ¯ğŸ¯ ToneBridge í†µí•© STT ì‹œì‘: {Path(audio_file).name} ğŸ¯ğŸ¯ğŸ¯")
        print(f"   ëª©í‘œ: {self.target_accuracy:.1%} ì •í™•ë„ ë‹¬ì„±")
        
        # ê²°ê³¼ ê°ì²´ ì´ˆê¸°í™”
        result = UltimateSTTResult(
            final_text="",
            confidence=0.0,
            accuracy_achieved=0.0
        )
        
        current_audio_file = audio_file
        attempt = 0
        
        # ì²˜ë¦¬ ì‹œë„ ë£¨í”„ (ìµœëŒ€ ì¬ì²˜ë¦¬ íšŸìˆ˜ê¹Œì§€)
        while attempt <= self.max_reprocessing_attempts:
            attempt += 1
            
            print(f"\nğŸ”„ ì²˜ë¦¬ ì‹œë„ {attempt}/{self.max_reprocessing_attempts + 1}")
            
            try:
                # 1ë‹¨ê³„: í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
                stage_result = await self._stage_1_audio_preprocessing(current_audio_file, attempt)
                current_audio_file = stage_result['optimized_file']
                result.audio_optimizations_applied.extend(stage_result['optimizations'])
                result.processing_stages.append(f"ì „ì²˜ë¦¬_ì‹œë„_{attempt}")
                
                # 2ë‹¨ê³„: ë‹¤ì¤‘ ì—”ì§„ ì•™ìƒë¸” STT
                stage_result = await self._stage_2_ensemble_stt(current_audio_file, target_text)
                result.ensemble_result = stage_result['ensemble_result']
                result.stt_engines_used.extend(stage_result['engines_used'])
                result.processing_stages.append(f"STT_ì‹œë„_{attempt}")
                
                # 3ë‹¨ê³„: ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦
                stage_result = await self._stage_3_quality_validation(
                    result.ensemble_result, target_text, current_audio_file
                )
                result.validation_result = stage_result['validation_result']
                result.processing_stages.append(f"ê²€ì¦_ì‹œë„_{attempt}")
                
                # í’ˆì§ˆ ì¶©ì¡± ì—¬ë¶€ í™•ì¸
                if result.validation_result and result.validation_result.is_valid:
                    print(f"âœ… ëª©í‘œ í’ˆì§ˆ ë‹¬ì„±! (ì‹œë„ {attempt})")
                    break
                
                # ì¬ì²˜ë¦¬ í•„ìš”ì„± íŒë‹¨
                if not enable_reprocessing or attempt > self.max_reprocessing_attempts:
                    print(f"âš ï¸ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬, í˜„ì¬ ê²°ê³¼ë¡œ ì™„ë£Œ")
                    break
                
                # 4ë‹¨ê³„: ì ì‘í˜• ì¬ì²˜ë¦¬ ì „ëµ ì ìš©
                if result.validation_result and result.validation_result.suggested_strategies:
                    print(f"ğŸ”§ ì¬ì²˜ë¦¬ ì „ëµ ì ìš© ì¤‘...")
                    current_audio_file = await self._stage_4_adaptive_reprocessing(
                        audio_file, result.validation_result.suggested_strategies[0]
                    )
                    result.reprocessing_attempts += 1
                    result.quality_improvements.extend([
                        result.validation_result.suggested_strategies[0].strategy_name
                    ])
                
            except Exception as e:
                logger.error(f"ì²˜ë¦¬ ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
                if attempt > self.max_reprocessing_attempts:
                    raise
        
        # ìµœì¢… ê²°ê³¼ ì •ë¦¬
        await self._finalize_result(result, target_text, start_time)
        
        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
        self._update_performance_stats(result)
        
        # ìµœì¢… ë³´ê³ ì„œ ì¶œë ¥
        self._print_ultimate_report(result)
        
        return result
    
    async def _stage_1_audio_preprocessing(self, audio_file: str, attempt: int) -> Dict:
        """1ë‹¨ê³„: í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬"""
        print("ğŸµ 1ë‹¨ê³„: í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬")
        
        optimizations = []
        optimized_file = audio_file
        
        if 'audio_optimizer' in self.components:
            try:
                # ì‹œë„ íšŸìˆ˜ì— ë”°ë¼ ì „ì²˜ë¦¬ ê°•ë„ ì¡°ì •
                optimizer = self.components['audio_optimizer']
                
                if attempt == 1:
                    # ì²« ì‹œë„: ê¸°ë³¸ ìµœì í™”
                    optimized_file = optimizer.optimize_for_korean_stt(
                        audio_file, stt_engine='whisper'
                    )
                    optimizations.append("ê¸°ë³¸_í•œêµ­ì–´_ìµœì í™”")
                
                elif attempt == 2:
                    # ë‘ ë²ˆì§¸ ì‹œë„: ê°•í™”ëœ ììŒ ì²˜ë¦¬
                    optimizer.korean_phoneme_profiles['consonants']['stops']['boost_db'] = [5, 6]
                    optimized_file = optimizer.optimize_for_korean_stt(
                        audio_file, stt_engine='whisper'
                    )
                    optimizations.append("ê°•í™”_ììŒ_ì²˜ë¦¬")
                
                else:
                    # ì„¸ ë²ˆì§¸ ì´í›„: ìµœëŒ€ ê°•ë„ ì²˜ë¦¬
                    optimizer.korean_boost = True
                    optimizer.target_db = -14.0  # ë” ë†’ì€ ë³¼ë¥¨
                    optimized_file = optimizer.optimize_for_korean_stt(
                        audio_file, stt_engine='whisper'
                    )
                    optimizations.append("ìµœëŒ€_ê°•ë„_ì²˜ë¦¬")
                
                print(f"âœ… ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì™„ë£Œ: {optimizations}")
                
            except Exception as e:
                logger.warning(f"ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                optimized_file = audio_file
                optimizations.append("ì „ì²˜ë¦¬_ì‹¤íŒ¨")
        
        return {
            'optimized_file': optimized_file,
            'optimizations': optimizations
        }
    
    async def _stage_2_ensemble_stt(self, audio_file: str, target_text: str) -> Dict:
        """2ë‹¨ê³„: ë‹¤ì¤‘ ì—”ì§„ ì•™ìƒë¸” STT"""
        print("ğŸ¤ 2ë‹¨ê³„: ë‹¤ì¤‘ ì—”ì§„ ì•™ìƒë¸” STT")
        
        ensemble_result = None
        engines_used = []
        
        if 'multi_stt' in self.components:
            try:
                multi_stt = self.components['multi_stt']
                ensemble_result = await multi_stt.transcribe_with_ensemble(
                    audio_file, target_text
                )
                engines_used = [r.engine for r in ensemble_result.engine_results if r.success]
                print(f"âœ… ì•™ìƒë¸” STT ì™„ë£Œ: {engines_used}")
                
            except Exception as e:
                logger.warning(f"ì•™ìƒë¸” STT ì‹¤íŒ¨: {e}")
        
        # ë°±ì—… STT ì‚¬ìš©
        if not ensemble_result and 'backup_stt' in self.components:
            try:
                backup_stt = self.components['backup_stt']
                backup_result = backup_stt.process_audio_with_confidence(audio_file, target_text)
                
                # EnsembleSTTResult í˜•íƒœë¡œ ë³€í™˜
                ensemble_result = type('EnsembleSTTResult', (), {
                    'final_text': backup_result.get('transcription', {}).get('text', ''),
                    'confidence': backup_result.get('overall_confidence', 0.0),
                    'processing_time': 0.0
                })()
                engines_used = ['backup_whisper']
                print("âœ… ë°±ì—… STT ì‚¬ìš©")
                
            except Exception as e:
                logger.error(f"ë°±ì—… STTë„ ì‹¤íŒ¨: {e}")
        
        return {
            'ensemble_result': ensemble_result,
            'engines_used': engines_used
        }
    
    async def _stage_3_quality_validation(self, 
                                        ensemble_result: Any,
                                        target_text: str,
                                        audio_file: str) -> Dict:
        """3ë‹¨ê³„: ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦"""
        print("ğŸ” 3ë‹¨ê³„: ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦")
        
        validation_result = None
        
        if 'quality_validator' in self.components and ensemble_result:
            try:
                validator = self.components['quality_validator']
                validation_result = await validator.validate_stt_quality(
                    ensemble_result, target_text, audio_file
                )
                print(f"âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ: ì ìˆ˜ {validation_result.quality_metrics.overall_score:.3f}")
                
            except Exception as e:
                logger.warning(f"í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
        
        return {
            'validation_result': validation_result
        }
    
    async def _stage_4_adaptive_reprocessing(self, 
                                           original_audio: str,
                                           strategy) -> str:
        """4ë‹¨ê³„: ì ì‘í˜• ì¬ì²˜ë¦¬"""
        print(f"ğŸ”§ 4ë‹¨ê³„: ì ì‘í˜• ì¬ì²˜ë¦¬ - {strategy.strategy_name}")
        
        try:
            # ì¬ì²˜ë¦¬ ì „ëµì— ë”°ë¥¸ ì˜¤ë””ì˜¤ ìµœì í™”
            if 'audio_optimizer' in self.components:
                optimizer = self.components['audio_optimizer']
                
                # ì „ëµë³„ íŒŒë¼ë¯¸í„° ì ìš©
                for key, value in strategy.audio_adjustments.items():
                    if hasattr(optimizer, key):
                        setattr(optimizer, key, value)
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì¬ìµœì í™”
                temp_dir = tempfile.gettempdir()
                reprocessed_file = os.path.join(
                    temp_dir, 
                    f"reprocessed_{strategy.strategy_name}_{Path(original_audio).name}"
                )
                
                final_file = optimizer.optimize_for_korean_stt(
                    original_audio, reprocessed_file
                )
                
                print(f"âœ… ì¬ì²˜ë¦¬ ì™„ë£Œ: {strategy.strategy_name}")
                return final_file
            
        except Exception as e:
            logger.warning(f"ì¬ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        return original_audio
    
    async def _finalize_result(self, result: UltimateSTTResult, target_text: str, start_time: float):
        """ìµœì¢… ê²°ê³¼ ì •ë¦¬"""
        # ìµœì¢… í…ìŠ¤íŠ¸ ë° ì‹ ë¢°ë„
        if result.ensemble_result:
            result.final_text = result.ensemble_result.final_text
            result.confidence = result.ensemble_result.confidence
        
        # ì •í™•ë„ ê³„ì‚° (target_textê°€ ìˆëŠ” ê²½ìš°)
        if target_text and result.final_text:
            result.accuracy_achieved = self._calculate_final_accuracy(
                result.final_text, target_text
            )
        
        # ìµœì¢… í’ˆì§ˆ ì ìˆ˜
        if result.validation_result:
            result.final_quality_score = result.validation_result.quality_metrics.overall_score
        
        # ì´ ì²˜ë¦¬ ì‹œê°„
        result.total_processing_time = time.time() - start_time
    
    def _calculate_final_accuracy(self, predicted: str, target: str) -> float:
        """ìµœì¢… ì •í™•ë„ ê³„ì‚°"""
        if not target:
            return 1.0 if not predicted else 0.0
        
        # í•œêµ­ì–´ ìŒì ˆ ë‹¨ìœ„ ì •í™•ë„
        pred_syllables = [c for c in predicted.replace(' ', '') if 0xAC00 <= ord(c) <= 0xD7A3]
        target_syllables = [c for c in target.replace(' ', '') if 0xAC00 <= ord(c) <= 0xD7A3]
        
        if not target_syllables:
            return 1.0
        
        # í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ ì •í™•ë„
        len_pred, len_target = len(pred_syllables), len(target_syllables)
        
        # DP í…Œì´ë¸” ìƒì„±
        dp = [[0] * (len_target + 1) for _ in range(len_pred + 1)]
        
        for i in range(len_pred + 1):
            dp[i][0] = i
        for j in range(len_target + 1):
            dp[0][j] = j
        
        for i in range(1, len_pred + 1):
            for j in range(1, len_target + 1):
                if pred_syllables[i-1] == target_syllables[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
        
        edit_distance = dp[len_pred][len_target]
        accuracy = 1.0 - (edit_distance / len_target)
        
        return max(0.0, accuracy)
    
    def _update_performance_stats(self, result: UltimateSTTResult):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.performance_stats['total_requests'] += 1
        
        if result.accuracy_achieved >= self.target_accuracy:
            self.performance_stats['successful_requests'] += 1
        
        self.performance_stats['accuracy_scores'].append(result.accuracy_achieved)
        self.performance_stats['processing_times'].append(result.total_processing_time)
        
        # ì¬ì²˜ë¦¬ í†µê³„
        if result.reprocessing_attempts > 0:
            attempts_key = f"{result.reprocessing_attempts}_attempts"
            self.performance_stats['reprocessing_stats'][attempts_key] = \
                self.performance_stats['reprocessing_stats'].get(attempts_key, 0) + 1
    
    def _print_ultimate_report(self, result: UltimateSTTResult):
        """ìµœì¢… ë³´ê³ ì„œ ì¶œë ¥"""
        print(f"\nğŸ¯ğŸ¯ğŸ¯ ToneBridge í†µí•© STT ìµœì¢… ë³´ê³ ì„œ ğŸ¯ğŸ¯ğŸ¯")
        print(f"   ìµœì¢… í…ìŠ¤íŠ¸: '{result.final_text}'")
        print(f"   ë‹¬ì„± ì •í™•ë„: {result.accuracy_achieved:.1%} ({'âœ… ëª©í‘œ ë‹¬ì„±' if result.accuracy_achieved >= self.target_accuracy else 'âŒ ëª©í‘œ ë¯¸ë‹¬'})")
        print(f"   ì‹ ë¢°ë„: {result.confidence:.3f}")
        print(f"   í’ˆì§ˆ ì ìˆ˜: {result.final_quality_score:.3f}")
        print(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {result.total_processing_time:.2f}ì´ˆ")
        print(f"   ì¬ì²˜ë¦¬ íšŸìˆ˜: {result.reprocessing_attempts}íšŒ")
        
        print(f"\n   ì²˜ë¦¬ ë‹¨ê³„: {' â†’ '.join(result.processing_stages)}")
        print(f"   ì ìš©ëœ ìµœì í™”: {', '.join(result.audio_optimizations_applied)}")
        print(f"   ì‚¬ìš©ëœ STT ì—”ì§„: {', '.join(result.stt_engines_used)}")
        
        if result.quality_improvements:
            print(f"   í’ˆì§ˆ ê°œì„  ê¸°ë²•: {', '.join(result.quality_improvements)}")
        
        # ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìš”ì•½
        if self.performance_stats['total_requests'] > 0:
            success_rate = self.performance_stats['successful_requests'] / self.performance_stats['total_requests']
            avg_accuracy = sum(self.performance_stats['accuracy_scores']) / len(self.performance_stats['accuracy_scores'])
            avg_time = sum(self.performance_stats['processing_times']) / len(self.performance_stats['processing_times'])
            
            print(f"\nğŸ“Š ì‹œìŠ¤í…œ ì „ì²´ ì„±ëŠ¥:")
            print(f"   ì„±ê³µë¥ : {success_rate:.1%} ({self.performance_stats['successful_requests']}/{self.performance_stats['total_requests']})")
            print(f"   í‰ê·  ì •í™•ë„: {avg_accuracy:.1%}")
            print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        print("âœ… ToneBridge í†µí•© STT ì²˜ë¦¬ ì™„ë£Œ\n")
    
    async def test_system_performance(self, test_cases: List[Dict]) -> Dict:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"ğŸ§ª ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘: {len(test_cases)}ê°œ ì¼€ì´ìŠ¤")
        
        test_results = []
        
        for i, test_case in enumerate(test_cases):
            print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}/{len(test_cases)}: {test_case.get('name', 'Unknown')}")
            
            try:
                result = await self.process_audio_ultimate(
                    test_case['audio_file'],
                    test_case.get('target_text', ''),
                    enable_reprocessing=test_case.get('enable_reprocessing', True)
                )
                
                test_results.append({
                    'test_case': test_case['name'],
                    'success': result.accuracy_achieved >= self.target_accuracy,
                    'accuracy': result.accuracy_achieved,
                    'confidence': result.confidence,
                    'processing_time': result.total_processing_time,
                    'reprocessing_attempts': result.reprocessing_attempts
                })
                
            except Exception as e:
                logger.error(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1} ì‹¤íŒ¨: {e}")
                test_results.append({
                    'test_case': test_case['name'],
                    'success': False,
                    'error': str(e)
                })
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„
        successful_tests = [r for r in test_results if r.get('success', False)]
        
        summary = {
            'total_tests': len(test_cases),
            'successful_tests': len(successful_tests),
            'success_rate': len(successful_tests) / len(test_cases) if test_cases else 0,
            'average_accuracy': sum(r.get('accuracy', 0) for r in successful_tests) / len(successful_tests) if successful_tests else 0,
            'average_processing_time': sum(r.get('processing_time', 0) for r in successful_tests) / len(successful_tests) if successful_tests else 0,
            'test_results': test_results
        }
        
        # í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ì¶œë ¥
        print(f"\nğŸ§ª ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë³´ê³ ì„œ:")
        print(f"   ì „ì²´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}ê°œ")
        print(f"   ì„±ê³µ í…ŒìŠ¤íŠ¸: {summary['successful_tests']}ê°œ")
        print(f"   ì„±ê³µë¥ : {summary['success_rate']:.1%}")
        print(f"   í‰ê·  ì •í™•ë„: {summary['average_accuracy']:.1%}")
        print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['average_processing_time']:.2f}ì´ˆ")
        
        return summary

# í¸ì˜ í•¨ìˆ˜ë“¤
async def process_audio_with_ultimate_accuracy(audio_file: str, target_text: str = "") -> UltimateSTTResult:
    """
    99% ì •í™•ë„ STT ì²˜ë¦¬ í¸ì˜ í•¨ìˆ˜
    
    Parameters:
    -----------
    audio_file : str
        ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼
    target_text : str
        ê¸°ëŒ€ í…ìŠ¤íŠ¸
        
    Returns:
    --------
    UltimateSTTResult : í†µí•© ì²˜ë¦¬ ê²°ê³¼
    """
    system = UltimateSTTSystem()
    return await system.process_audio_ultimate(audio_file, target_text)

def create_test_suite() -> List[Dict]:
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±"""
    return [
        {
            'name': 'ê¸°ë³¸_í•œêµ­ì–´_ì¸ì‚¬',
            'audio_file': 'test_audio/ì•ˆë…•í•˜ì„¸ìš”.wav',
            'target_text': 'ì•ˆë…•í•˜ì„¸ìš”',
            'enable_reprocessing': True
        },
        {
            'name': 'ë³µì¡_í•œêµ­ì–´_ë¬¸ì¥',
            'audio_file': 'test_audio/ë°˜ê°‘ìŠµë‹ˆë‹¤.wav', 
            'target_text': 'ë°˜ê°‘ìŠµë‹ˆë‹¤',
            'enable_reprocessing': True
        },
        {
            'name': 'ë¹ ë¥¸_ì²˜ë¦¬_ëª¨ë“œ',
            'audio_file': 'test_audio/ê°ì‚¬í•©ë‹ˆë‹¤.wav',
            'target_text': 'ê°ì‚¬í•©ë‹ˆë‹¤',
            'enable_reprocessing': False
        }
    ]

if __name__ == "__main__":
    # ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    import sys
    
    if len(sys.argv) > 1:
        audio_file = sys.argv[1]
        target_text = sys.argv[2] if len(sys.argv) > 2 else ""
        
        result = asyncio.run(process_audio_with_ultimate_accuracy(audio_file, target_text))
        print(f"ìµœì¢… ê²°ê³¼: {result.final_text} (ì •í™•ë„: {result.accuracy_achieved:.1%})")
    else:
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        system = UltimateSTTSystem()
        test_cases = create_test_suite()
        test_summary = asyncio.run(system.test_system_performance(test_cases))