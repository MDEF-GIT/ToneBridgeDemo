"""
ToneBridge ìŒì„± ë¶„ì„ í•µì‹¬ ëª¨ë“ˆ

ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ë¶„ì„ ë„êµ¬ë“¤:
- ì •ë°€ ìŒì ˆ ë¶„ì ˆ (PreciseSyllableSegmenter)
- ìŒì„± íŠ¹ì§• ì¶”ì¶œ (AudioFeatureExtractor) 
- ìŒì ˆ ê²½ê³„ íƒì§€ (SyllableBoundaryDetector)
- TextGrid ìƒì„± (TextGridGenerator)

ì˜ì¡´ì„± ì—†ì´ ì–´ë””ì„œë“  importí•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥
"""

import numpy as np
import parselmouth as pm
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import tempfile
import os

@dataclass
class SyllableSegment:
    """ìŒì ˆ êµ¬ê°„ ì •ë³´"""
    label: str
    start: float
    end: float
    duration: float
    confidence: float = 1.0

@dataclass
class AudioFeatures:
    """ìŒì„± íŠ¹ì§• ë°ì´í„°"""
    intensity_times: np.ndarray
    intensity_values: np.ndarray
    pitch_times: np.ndarray
    pitch_values: np.ndarray
    duration: float
    valid_speech_start: float
    valid_speech_end: float

class AudioFeatureExtractor:
    """
    ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì „ìš© í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        extractor = AudioFeatureExtractor()
        features = extractor.extract(sound)
    """
    
    def __init__(self, 
                 pitch_floor: float = 75.0, 
                 pitch_ceiling: float = 600.0,
                 silence_threshold_ratio: float = 0.25):
        self.pitch_floor = pitch_floor
        self.pitch_ceiling = pitch_ceiling
        self.silence_threshold_ratio = silence_threshold_ratio
    
    def extract(self, sound: pm.Sound) -> AudioFeatures:
        """ìŒì„±ì—ì„œ í•µì‹¬ íŠ¹ì§•ë“¤ ì¶”ì¶œ"""
        try:
            # ê¸°ë³¸ ì •ë³´
            duration = sound.get_total_duration()
            start_time = sound.xmin
            end_time = sound.xmax
            
            # ê°•ë„(ì—ë„ˆì§€) ë¶„ì„
            intensity = sound.to_intensity(minimum_pitch=self.pitch_floor)
            intensity_times = intensity.xs()
            intensity_values = intensity.values.T.flatten()
            
            # í”¼ì¹˜ ë¶„ì„
            pitch = sound.to_pitch(
                pitch_floor=self.pitch_floor, 
                pitch_ceiling=self.pitch_ceiling
            )
            pitch_times = pitch.xs()
            pitch_values = pitch.selected_array['frequency']
            
            # ìœ íš¨í•œ ìŒì„± êµ¬ê°„ íƒì§€
            valid_start, valid_end = self._find_valid_speech_region(
                intensity_times, intensity_values, start_time, end_time
            )
            
            return AudioFeatures(
                intensity_times=intensity_times,
                intensity_values=intensity_values,
                pitch_times=pitch_times,
                pitch_values=pitch_values,
                duration=duration,
                valid_speech_start=valid_start,
                valid_speech_end=valid_end
            )
            
        except Exception as e:
            raise Exception(f"ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    def _find_valid_speech_region(self, times: np.ndarray, values: np.ndarray, 
                                  start_time: float, end_time: float) -> Tuple[float, float]:
        """ìœ íš¨í•œ ìŒì„± êµ¬ê°„ íƒì§€ (ë¬´ìŒ ì œê±°)"""
        try:
            # ë¬´ìŒ ì„ê³„ê°’ ê³„ì‚°
            mean_intensity = np.mean(values[values > 0])
            silence_threshold = mean_intensity * self.silence_threshold_ratio
            
            # ìœ íš¨í•œ ìŒì„± êµ¬ê°„ ì°¾ê¸°
            valid_regions = []
            in_speech = False
            speech_start = None
            
            for t, intensity_val in zip(times, values):
                if intensity_val > silence_threshold and not in_speech:
                    speech_start = t
                    in_speech = True
                elif intensity_val <= silence_threshold and in_speech:
                    if speech_start is not None:
                        valid_regions.append((speech_start, t))
                    in_speech = False
                    speech_start = None
            
            # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
            if in_speech and speech_start is not None:
                valid_regions.append((speech_start, end_time))
            
            if not valid_regions:
                return start_time, end_time
            
            # ì „ì²´ ìŒì„± êµ¬ê°„ ë³‘í•©
            speech_start_time = min(r[0] for r in valid_regions)
            speech_end_time = max(r[1] for r in valid_regions)
            
            return speech_start_time, speech_end_time
            
        except Exception as e:
            print(f"âš ï¸ ìŒì„± êµ¬ê°„ íƒì§€ ì‹¤íŒ¨: {e}")
            return start_time, end_time

class SyllableBoundaryDetector:
    """
    ìŒì ˆ ê²½ê³„ íƒì§€ ì „ìš© í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        detector = SyllableBoundaryDetector()
        boundaries = detector.detect(features, target_syllable_count)
    """
    
    def __init__(self, 
                 energy_percentile: float = 70.0,
                 pitch_threshold_semitones: float = 1.0):
        self.energy_percentile = energy_percentile
        self.pitch_threshold_semitones = pitch_threshold_semitones
    
    def detect(self, features: AudioFeatures, target_count: int) -> List[float]:
        """ìŒì„±í•™ì  íŠ¹ì§•ì„ ì¢…í•©í•œ ìŒì ˆ ê²½ê³„ íƒì§€"""
        try:
            # 1. ì—ë„ˆì§€ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€
            energy_boundaries = self._find_energy_boundaries(
                features.intensity_times, features.intensity_values,
                features.valid_speech_start, features.valid_speech_end
            )
            
            # 2. í”¼ì¹˜ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€
            pitch_boundaries = self._find_pitch_boundaries(
                features.pitch_times, features.pitch_values,
                features.valid_speech_start, features.valid_speech_end
            )
            
            # 3. ê²½ê³„ì  í†µí•© ë° ìµœì í™”
            all_boundaries = sorted(set(energy_boundaries + pitch_boundaries))
            
            # ì‹œì‘/ë ë³´ì¥
            boundaries = [features.valid_speech_start]
            for b in all_boundaries:
                if features.valid_speech_start < b < features.valid_speech_end:
                    boundaries.append(b)
            boundaries.append(features.valid_speech_end)
            
            # 4. ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ì¶¤
            optimized_boundaries = self._optimize_boundaries(boundaries, target_count)
            
            return optimized_boundaries
            
        except Exception as e:
            print(f"âŒ ê²½ê³„ íƒì§€ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê· ë“± ë¶„í• 
            return self._equal_division_fallback(
                features.valid_speech_start, features.valid_speech_end, target_count
            )
    
    def _find_energy_boundaries(self, times: np.ndarray, values: np.ndarray, 
                               start_time: float, end_time: float) -> List[float]:
        """ì—ë„ˆì§€ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€"""
        try:
            # ê´€ì‹¬ êµ¬ê°„ë§Œ ì¶”ì¶œ
            mask = (times >= start_time) & (times <= end_time)
            region_times = times[mask]
            region_values = values[mask]
            
            if len(region_values) < 10:
                return []
            
            # 1ì°¨ ë¯¸ë¶„ìœ¼ë¡œ ë³€í™”ìœ¨ ê³„ì‚°
            energy_diff = np.abs(np.diff(region_values))
            
            # ë³€í™”ê°€ í° ì§€ì  íƒì§€
            threshold = np.percentile(energy_diff, self.energy_percentile)
            peak_indices = []
            
            for i in range(1, len(energy_diff) - 1):
                if (energy_diff[i] > threshold and 
                    energy_diff[i] > energy_diff[i-1] and 
                    energy_diff[i] > energy_diff[i+1]):
                    peak_indices.append(i)
            
            # ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            boundaries = [region_times[idx] for idx in peak_indices 
                         if idx < len(region_times)]
            
            return boundaries
            
        except Exception as e:
            print(f"âŒ ì—ë„ˆì§€ ê²½ê³„ íƒì§€ ì‹¤íŒ¨: {e}")
            return []
    
    def _find_pitch_boundaries(self, times: np.ndarray, values: np.ndarray,
                              start_time: float, end_time: float) -> List[float]:
        """í”¼ì¹˜ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€"""
        try:
            # ê´€ì‹¬ êµ¬ê°„ë§Œ ì¶”ì¶œ (ìœ íš¨í•œ í”¼ì¹˜ë§Œ)
            mask = (times >= start_time) & (times <= end_time) & (values > 0)
            region_times = times[mask]
            region_values = values[mask]
            
            if len(region_values) < 5:
                return []
            
            # í”¼ì¹˜ ë³€í™”ìœ¨ ê³„ì‚° (ì„¸ë¯¸í†¤ ë‹¨ìœ„)
            pitch_semitones = 12 * np.log2(region_values / 440) + 69
            pitch_diff = np.abs(np.diff(pitch_semitones))
            
            # í° í”¼ì¹˜ ë³€í™” ì§€ì  íƒì§€
            boundary_indices = []
            for i in range(len(pitch_diff)):
                if pitch_diff[i] > self.pitch_threshold_semitones:
                    boundary_indices.append(i)
            
            # ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            boundaries = [region_times[idx] for idx in boundary_indices 
                         if idx < len(region_times)]
            
            return boundaries
            
        except Exception as e:
            print(f"âŒ í”¼ì¹˜ ê²½ê³„ íƒì§€ ì‹¤íŒ¨: {e}")
            return []
    
    def _optimize_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ê²½ê³„ì ì„ ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ê²Œ ìµœì í™”"""
        try:
            if len(boundaries) <= 2:
                return self._equal_division_fallback(
                    boundaries[0], boundaries[-1], target_count
                )
            
            current_segments = len(boundaries) - 1
            
            if current_segments == target_count:
                return boundaries
            elif current_segments > target_count:
                # ë„ˆë¬´ ë§ì€ ê²½ê³„ - ê°€ì¥ ê°•í•œ ê²ƒë“¤ë§Œ ì„ íƒ
                return self._select_strongest_boundaries(boundaries, target_count)
            else:
                # ë¶€ì¡±í•œ ê²½ê³„ - ê¸´ êµ¬ê°„ì„ ë¶„í• 
                return self._add_missing_boundaries(boundaries, target_count)
                
        except Exception as e:
            print(f"âŒ ê²½ê³„ ìµœì í™” ì‹¤íŒ¨: {e}")
            return self._equal_division_fallback(
                boundaries[0], boundaries[-1], target_count
            )
    
    def _select_strongest_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ê°€ì¥ ê°•í•œ ê²½ê³„ì ë“¤ë§Œ ì„ íƒ"""
        if len(boundaries) <= target_count + 1:
            return boundaries
            
        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ì€ í•­ìƒ ìœ ì§€
        result = [boundaries[0]]
        
        # ì¤‘ê°„ ê²½ê³„ë“¤ ì¤‘ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
        middle = boundaries[1:-1]
        if middle and target_count > 1:
            step = len(middle) / (target_count - 1)
            for i in range(target_count - 1):
                idx = int(i * step)
                if idx < len(middle):
                    result.append(middle[idx])
        
        result.append(boundaries[-1])
        return sorted(result)
    
    def _add_missing_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ë¶€ì¡±í•œ ê²½ê³„ì  ì¶”ê°€"""
        result = boundaries[:]
        
        while len(result) - 1 < target_count:
            # ê°€ì¥ ê¸´ êµ¬ê°„ ì°¾ê¸°
            max_length = 0
            max_idx = 0
            
            for i in range(len(result) - 1):
                length = result[i + 1] - result[i]
                if length > max_length:
                    max_length = length
                    max_idx = i
            
            # ì¤‘ê°„ì  ì¶”ê°€
            mid_point = (result[max_idx] + result[max_idx + 1]) / 2
            result.insert(max_idx + 1, mid_point)
        
        return sorted(result)
    
    def _equal_division_fallback(self, start: float, end: float, target_count: int) -> List[float]:
        """í´ë°±: ê· ë“± ë¶„í• """
        result = []
        for i in range(target_count + 1):
            result.append(start + (end - start) * i / target_count)
        return result

class PreciseSyllableSegmenter:
    """
    ì •ë°€ ìŒì ˆ ë¶„ì ˆ ë©”ì¸ í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        segmenter = PreciseSyllableSegmenter()
        segments = segmenter.segment(sound, syllable_labels)
    """
    
    def __init__(self, **kwargs):
        self.feature_extractor = AudioFeatureExtractor(**kwargs)
        self.boundary_detector = SyllableBoundaryDetector(**kwargs)
    
    def segment(self, sound: pm.Sound, syllable_labels: List[str]) -> List[SyllableSegment]:
        """ìŒì„±ì„ ì •ë°€í•˜ê²Œ ìŒì ˆë³„ë¡œ ë¶„ì ˆ"""
        try:
            print("ğŸ”¬ ì •ë°€ ìŒì„±í•™ì  ë¶„ì ˆ ì‹œì‘")
            
            # 1. ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            features = self.feature_extractor.extract(sound)
            print(f"ğŸ”‡ ë¬´ìŒ ì œê±°: {features.valid_speech_start:.3f}s ~ {features.valid_speech_end:.3f}s")
            
            # 2. ìŒì ˆ ê²½ê³„ íƒì§€
            boundaries = self.boundary_detector.detect(features, len(syllable_labels))
            print(f"ğŸ¯ ê²½ê³„ì  íƒì§€: {len(boundaries)-1}ê°œ êµ¬ê°„")
            
            # 3. ìŒì ˆ êµ¬ê°„ ìƒì„±
            segments = []
            for i, label in enumerate(syllable_labels):
                segment = SyllableSegment(
                    label=label,
                    start=boundaries[i],
                    end=boundaries[i + 1],
                    duration=boundaries[i + 1] - boundaries[i]
                )
                segments.append(segment)
                print(f"   ğŸ¯ '{label}': {segment.start:.3f}s ~ {segment.end:.3f}s")
            
            print(f"âœ… ì •ë°€ ë¶„ì ˆ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
            return segments
            
        except Exception as e:
            print(f"âŒ ì •ë°€ ë¶„ì ˆ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì ˆë¡œ í´ë°±: {e}")
            return self._fallback_equal_segmentation(sound, syllable_labels)
    
    def _fallback_equal_segmentation(self, sound: pm.Sound, syllable_labels: List[str]) -> List[SyllableSegment]:
        """í´ë°±: ê¸°ë³¸ ê· ë“± ë¶„í• """
        duration = sound.get_total_duration()
        syllable_duration = duration / len(syllable_labels)
        
        segments = []
        for i, label in enumerate(syllable_labels):
            start_time = i * syllable_duration
            end_time = (i + 1) * syllable_duration
            
            if i == len(syllable_labels) - 1:
                end_time = duration
            
            segment = SyllableSegment(
                label=label,
                start=start_time,
                end=end_time,
                duration=end_time - start_time
            )
            segments.append(segment)
        
        return segments

class TextGridGenerator:
    """
    TextGrid íŒŒì¼ ìƒì„± ì „ìš© í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        generator = TextGridGenerator()
        generator.save(segments, output_path, total_duration)
    """
    
    def save(self, segments: List[SyllableSegment], output_path: str, total_duration: float):
        """ìŒì ˆ ì •ë³´ë¥¼ TextGrid íŒŒì¼ë¡œ ì €ì¥"""
        try:
            print(f"ğŸ’¾ TextGrid ì €ì¥: {output_path}")
            
            # TextGrid ë¬¸ìì—´ ìƒì„±
            textgrid_content = f'''File type = "ooTextFile"
Object class = "TextGrid"

xmin = 0 
xmax = {total_duration} 
tiers? <exists> 
size = 1 
item []: 
    item [1]:
        class = "IntervalTier" 
        name = "syllables" 
        xmin = 0 
        xmax = {total_duration} 
        intervals: size = {len(segments)} 
'''
            
            # ê° ìŒì ˆ êµ¬ê°„ ì¶”ê°€
            for i, segment in enumerate(segments):
                textgrid_content += f'''        intervals [{i+1}]:
            xmin = {segment.start} 
            xmax = {segment.end} 
            text = "{segment.label}" 
'''
            
            # íŒŒì¼ ì €ì¥
            with open(output_path, 'w', encoding='utf-16') as f:
                f.write(textgrid_content)
            
            print(f"âœ… TextGrid ì €ì¥ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
            
        except Exception as e:
            raise Exception(f"TextGrid ì €ì¥ ì‹¤íŒ¨: {e}")

def split_korean_sentence(sentence: str) -> List[str]:
    """í•œêµ­ì–´ ë¬¸ì¥ì„ ìŒì ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬"""
    return [char for char in sentence.strip() if char.strip()]

# í¸ì˜ í•¨ìˆ˜ë“¤
def analyze_audio_file(audio_path: str, syllable_text: str, **kwargs) -> List[SyllableSegment]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì •ë°€í•œ ìŒì ˆ ë¶„ì ˆ ìˆ˜í–‰
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        syllable_text: ëª©í‘œ ë¬¸ì¥ (ì˜ˆ: "ë°˜ê°€ì›Œìš”")
        **kwargs: ë¶„ì„ íŒŒë¼ë©”í„° (pitch_floor, pitch_ceiling ë“±)
    
    Returns:
        ìŒì ˆ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
    """
    try:
        sound = pm.Sound(audio_path)
        syllable_labels = split_korean_sentence(syllable_text)
        
        segmenter = PreciseSyllableSegmenter(**kwargs)
        return segmenter.segment(sound, syllable_labels)
        
    except Exception as e:
        raise Exception(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {e}")

def create_textgrid_from_audio(audio_path: str, syllable_text: str, 
                              output_path: Optional[str] = None, **kwargs) -> str:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ TextGrid ìƒì„±
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        syllable_text: ëª©í‘œ ë¬¸ì¥
        output_path: TextGrid ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        **kwargs: ë¶„ì„ íŒŒë¼ë©”í„°
    
    Returns:
        ìƒì„±ëœ TextGrid íŒŒì¼ ê²½ë¡œ
    """
    try:
        # ìŒì ˆ ë¶„ì ˆ ìˆ˜í–‰
        segments = analyze_audio_file(audio_path, syllable_text, **kwargs)
        
        # ì¶œë ¥ ê²½ë¡œ ìƒì„±
        if output_path is None:
            base_name = os.path.splitext(audio_path)[0]
            output_path = f"{base_name}.TextGrid"
        
        # ìŒì„± ê¸¸ì´ ê³„ì‚°
        sound = pm.Sound(audio_path)
        total_duration = sound.get_total_duration()
        
        # TextGrid ì €ì¥
        generator = TextGridGenerator()
        generator.save(segments, output_path, total_duration)
        
        return output_path
        
    except Exception as e:
        raise Exception(f"TextGrid ìƒì„± ì‹¤íŒ¨: {e}")