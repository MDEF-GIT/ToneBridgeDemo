"""
ToneBridge ìŒì„± ë¶„ì„ í•µì‹¬ ëª¨ë“ˆ

ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ë¶„ì„ ë„êµ¬ë“¤:
- STT ê¸°ë°˜ ì •ë°€ ë¶„ì ˆ (STTBasedSegmenter)
- ìŒì„±í•™ì  ë¶„ì ˆ í´ë°± (FallbackSyllableSegmenter)
- ìŒì„± íŠ¹ì§• ì¶”ì¶œ (AudioFeatureExtractor) 
- ìŒì ˆ ê²½ê³„ íƒì§€ (SyllableBoundaryDetector)
- TextGrid ìƒì„± (TextGridGenerator)

ì˜ì¡´ì„± ì—†ì´ ì–´ë””ì„œë“  importí•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥
"""

import numpy as np
import parselmouth as pm
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import tempfile
import os

# STT ê¸°ë°˜ ì •í™•í•œ ë¶„ì ˆì„ ìœ„í•œ ëª¨ë“ˆ
try:
    from advanced_stt_processor import AdvancedSTTProcessor
    STT_AVAILABLE = True
except ImportError:
    STT_AVAILABLE = False
    print("âš ï¸ STT ëª¨ë“ˆ ë¯¸ì„¤ì¹˜ - í´ë°± ë¶„ì ˆ ì‚¬ìš©")

@dataclass
class SyllableSegment:
    """ìŒì ˆ êµ¬ê°„ ì •ë³´"""
    label: str
    start: float
    end: float
    duration: float
    confidence: float = 1.0

@dataclass
class AudioFeatures:
    """ìŒì„± íŠ¹ì§• ë°ì´í„°"""
    intensity_times: np.ndarray
    intensity_values: np.ndarray
    pitch_times: np.ndarray
    pitch_values: np.ndarray
    duration: float
    valid_speech_start: float
    valid_speech_end: float

class HighPrecisionAudioAnalyzer:
    """
    ê³ ì •ë°€ ìŒì„±í•™ì  ë¶„ì„ í´ë˜ìŠ¤
    - ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
    - í¬ë¨¼íŠ¸ ë¶„ì„  
    - ì—ë„ˆì§€/í”¼ì¹˜ ì •ë°€ ë¶„ì„
    - ìŒì„±í•™ì  ê²½ê³„ íƒì§€
    
    ì‚¬ìš©ë²•:
        analyzer = HighPrecisionAudioAnalyzer()
        segments = analyzer.analyze_and_segment(audio_file, sentence)
    """
    
    def __init__(self, 
                 pitch_floor: float = 75.0, 
                 pitch_ceiling: float = 600.0,
                 formant_max_freq: float = 5500.0,
                 window_length: float = 0.025,
                 time_step: float = 0.01):
        self.pitch_floor = pitch_floor
        self.pitch_ceiling = pitch_ceiling
        self.formant_max_freq = formant_max_freq
        self.window_length = window_length
        self.time_step = time_step
        
    def analyze_and_segment(self, audio_file: str, sentence: str) -> List[SyllableSegment]:
        """
        WAV íŒŒì¼ì„ ì •ë°€ ë¶„ì„í•˜ì—¬ ê³ ì •ë°€ ìŒì ˆ ë¶„ì ˆ ìˆ˜í–‰
        
        Args:
            audio_file: WAV íŒŒì¼ ê²½ë¡œ
            sentence: ëª©í‘œ ë¬¸ì¥
            
        Returns:
            ê³ ì •ë°€ ìŒì ˆ ë¶„ì ˆ ê²°ê³¼
        """
        try:
            print(f"ğŸ”¬ ê³ ì •ë°€ ìŒì„±í•™ì  ë¶„ì„ ì‹œì‘: {sentence}")
            
            # 1. ìŒì„± ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´
            sound = pm.Sound(audio_file)
            syllables = list(sentence.replace(' ', ''))
            duration = sound.get_total_duration()
            
            print(f"ğŸ“Š ìŒì„± ê¸¸ì´: {duration:.3f}ì´ˆ, ëª©í‘œ ìŒì ˆ: {len(syllables)}ê°œ")
            
            # 2. ë‹¤ì°¨ì› ìŒì„±í•™ì  ë¶„ì„
            audio_features = self._extract_comprehensive_features(sound)
            
            # 3. ì •ë°€ ìŒì ˆ ê²½ê³„ íƒì§€
            boundaries = self._detect_precise_syllable_boundaries(
                audio_features, len(syllables)
            )
            
            # 4. ìŒì ˆ ë¶„ì ˆ ê²°ê³¼ ìƒì„±
            segments = []
            for i, syllable in enumerate(syllables):
                start = boundaries[i]
                end = boundaries[i + 1] if i + 1 < len(boundaries) else duration
                
                # ìŒì ˆë³„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                quality_score = self._calculate_segment_quality(
                    audio_features, start, end
                )
                
                segments.append(SyllableSegment(
                    label=syllable,
                    start=start,
                    end=end,
                    duration=end - start,
                    confidence=quality_score
                ))
                
                print(f"   ğŸ¯ '{syllable}': {start:.3f}s ~ {end:.3f}s (í’ˆì§ˆ: {quality_score:.2f})")
            
            print(f"âœ… ê³ ì •ë°€ ë¶„ì ˆ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
            return segments
            
        except Exception as e:
            print(f"âŒ ê³ ì •ë°€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def _extract_comprehensive_features(self, sound: pm.Sound) -> Dict[str, Any]:
        """ìŒì„±ì˜ ì¢…í•©ì  íŠ¹ì§• ì¶”ì¶œ"""
        try:
            print("ğŸ“ˆ ì¢…í•© ìŒì„±í•™ì  íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
            
            # 1. ê¸°ë³¸ í”¼ì¹˜/ê°•ë„ ë¶„ì„
            pitch = sound.to_pitch(
                pitch_floor=self.pitch_floor, 
                pitch_ceiling=self.pitch_ceiling,
                time_step=self.time_step
            )
            intensity = sound.to_intensity(time_step=self.time_step)
            
            # 2. í¬ë¨¼íŠ¸ ë¶„ì„
            formant = sound.to_formant_burg(
                time_step=self.time_step,
                max_formant=self.formant_max_freq
            )
            
            # 3. ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„
            spectrogram = sound.to_spectrogram(
                window_length=self.window_length,
                time_step=self.time_step
            )
            
            # 4. ì‹œê°„ ì¶• ì •ë ¬
            times = pitch.xs()
            
            # 5. íŠ¹ì§• ë°ì´í„° ì¶”ì¶œ
            features = {
                'times': times,
                'pitch_values': pitch.selected_array['frequency'],
                'intensity_values': intensity.values.T.flatten(),
                'formant_data': self._extract_formant_features(formant),
                'spectral_data': self._extract_spectral_features(spectrogram, times),
                'energy_change': self._calculate_energy_changes(intensity),
                'pitch_change': self._calculate_pitch_changes(pitch),
                'duration': sound.get_total_duration()
            }
            
            print(f"âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {len(times)}ê°œ ì‹œê°„ í”„ë ˆì„")
            return features
            
        except Exception as e:
            print(f"âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _extract_formant_features(self, formant) -> Dict[str, np.ndarray]:
        """í¬ë¨¼íŠ¸ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            times = formant.xs()
            
            # F1, F2, F3 ì¶”ì¶œ
            f1_values = []
            f2_values = []
            f3_values = []
            
            for t in times:
                try:
                    f1 = formant.get_value_at_time(1, t)
                    f2 = formant.get_value_at_time(2, t) 
                    f3 = formant.get_value_at_time(3, t)
                    
                    f1_values.append(f1 if f1 != None else 0)
                    f2_values.append(f2 if f2 != None else 0)
                    f3_values.append(f3 if f3 != None else 0)
                except:
                    f1_values.append(0)
                    f2_values.append(0)
                    f3_values.append(0)
            
            return {
                'f1': np.array(f1_values),
                'f2': np.array(f2_values),
                'f3': np.array(f3_values),
                'times': times
            }
            
        except Exception as e:
            print(f"âš ï¸ í¬ë¨¼íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {'f1': np.array([]), 'f2': np.array([]), 'f3': np.array([])}
    
    def _extract_spectral_features(self, spectrogram, times) -> Dict[str, np.ndarray]:
        """ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬, ë¡¤ì˜¤í”„, í”ŒëŸ­ìŠ¤ ë“± ê³„ì‚°
            spectral_centroid = []
            spectral_rolloff = []
            spectral_flux = []
            
            n_frames = len(times)
            freq_resolution = spectrogram.get_frequency_from_bin_number(1)
            
            for i in range(n_frames):
                try:
                    # í•´ë‹¹ ì‹œê°„ í”„ë ˆì„ì˜ ìŠ¤í™íŠ¸ëŸ¼
                    spectrum = spectrogram.values[:, i] if i < spectrogram.values.shape[1] else np.zeros(spectrogram.values.shape[0])
                    
                    # ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬
                    freqs = np.arange(len(spectrum)) * freq_resolution
                    if np.sum(spectrum) > 0:
                        centroid = np.sum(freqs * spectrum) / np.sum(spectrum)
                    else:
                        centroid = 0
                    spectral_centroid.append(centroid)
                    
                    # ìŠ¤í™íŠ¸ëŸ´ ë¡¤ì˜¤í”„ (85% ì—ë„ˆì§€ ì§€ì )
                    cumsum = np.cumsum(spectrum)
                    total_energy = cumsum[-1]
                    if total_energy > 0:
                        rolloff_idx = np.where(cumsum >= 0.85 * total_energy)[0]
                        rolloff = rolloff_idx[0] * freq_resolution if len(rolloff_idx) > 0 else 0
                    else:
                        rolloff = 0
                    spectral_rolloff.append(rolloff)
                    
                    # ìŠ¤í™íŠ¸ëŸ´ í”ŒëŸ­ìŠ¤ (ì´ì „ í”„ë ˆì„ê³¼ì˜ ì°¨ì´)
                    if i > 0:
                        prev_spectrum = spectrogram.values[:, i-1] if i-1 < spectrogram.values.shape[1] else np.zeros_like(spectrum)
                        flux = np.sum((spectrum - prev_spectrum) ** 2)
                    else:
                        flux = 0
                    spectral_flux.append(flux)
                    
                except:
                    spectral_centroid.append(0)
                    spectral_rolloff.append(0)
                    spectral_flux.append(0)
            
            return {
                'centroid': np.array(spectral_centroid),
                'rolloff': np.array(spectral_rolloff),
                'flux': np.array(spectral_flux)
            }
            
        except Exception as e:
            print(f"âš ï¸ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'centroid': np.array([]), 'rolloff': np.array([]), 'flux': np.array([])}
    
    def _calculate_energy_changes(self, intensity) -> np.ndarray:
        """ì—ë„ˆì§€ ë³€í™”ìœ¨ ê³„ì‚°"""
        try:
            values = intensity.values.T.flatten()
            # 1ì°¨ ë¯¸ë¶„ (ë³€í™”ìœ¨)
            energy_diff = np.abs(np.diff(values))
            # íŒ¨ë”©ìœ¼ë¡œ ê¸¸ì´ ë§ì¶¤
            energy_changes = np.pad(energy_diff, (1, 0), mode='constant', constant_values=0)
            return energy_changes
        except:
            return np.array([])
    
    def _calculate_pitch_changes(self, pitch) -> np.ndarray:
        """í”¼ì¹˜ ë³€í™”ìœ¨ ê³„ì‚° (ì„¸ë¯¸í†¤ ë‹¨ìœ„)"""
        try:
            values = pitch.selected_array['frequency']
            valid_mask = values > 0
            
            if np.sum(valid_mask) < 2:
                return np.zeros_like(values)
            
            # ì„¸ë¯¸í†¤ ë³€í™˜
            semitones = np.zeros_like(values)
            semitones[valid_mask] = 12 * np.log2(values[valid_mask] / 440) + 69
            
            # ë³€í™”ìœ¨ ê³„ì‚°
            pitch_diff = np.abs(np.diff(semitones))
            pitch_changes = np.pad(pitch_diff, (1, 0), mode='constant', constant_values=0)
            
            return pitch_changes
        except:
            return np.array([])
    
    def _detect_precise_syllable_boundaries(self, features: Dict[str, Any], num_syllables: int) -> List[float]:
        """
        ë‹¤ì°¨ì› ìŒì„±í•™ì  íŠ¹ì§•ì„ ì¢…í•©í•œ ì •ë°€ ìŒì ˆ ê²½ê³„ íƒì§€
        """
        try:
            print("ğŸ¯ ì •ë°€ ê²½ê³„ íƒì§€ ì¤‘...")
            
            times = features['times']
            duration = features['duration']
            
            # 1. ìœ íš¨ ìŒì„± êµ¬ê°„ íƒì§€ (ë¬´ìŒ ì œê±°)
            speech_start, speech_end = self._detect_speech_region(features)
            print(f"ğŸ”‡ ìŒì„± êµ¬ê°„: {speech_start:.3f}s ~ {speech_end:.3f}s")
            
            # 2. ë‹¤ì°¨ì› ê²½ê³„ ì ìˆ˜ ê³„ì‚°
            boundary_scores = self._calculate_boundary_scores(features, speech_start, speech_end)
            
            # 3. í”¼í¬ íƒì§€ë¡œ í›„ë³´ ê²½ê³„ì  ì¶”ì¶œ
            candidate_boundaries = self._find_boundary_candidates(boundary_scores, times, speech_start, speech_end)
            
            # 4. ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ê²Œ ìµœì í™”
            optimized_boundaries = self._optimize_boundaries_for_syllables(
                candidate_boundaries, num_syllables, speech_start, speech_end
            )
            
            print(f"âœ… ê²½ê³„ íƒì§€ ì™„ë£Œ: {len(optimized_boundaries)-1}ê°œ êµ¬ê°„")
            return optimized_boundaries
            
        except Exception as e:
            print(f"âŒ ê²½ê³„ íƒì§€ ì‹¤íŒ¨, ê· ë“± ë¶„í•  ì‚¬ìš©: {e}")
            # í´ë°±: ê· ë“± ë¶„í• 
            boundaries = []
            for i in range(num_syllables + 1):
                boundaries.append(i * duration / num_syllables)
            return boundaries
    
    def _detect_speech_region(self, features: Dict[str, Any]) -> Tuple[float, float]:
        """ìœ íš¨ ìŒì„± êµ¬ê°„ íƒì§€"""
        try:
            times = features['times']
            intensity_values = features['intensity_values']
            
            # ê°•ë„ ê¸°ë°˜ ë¬´ìŒ ì„ê³„ê°’ ì„¤ì •
            valid_intensity = intensity_values[intensity_values > 0]
            if len(valid_intensity) == 0:
                return 0.0, features['duration']
            
            mean_intensity = np.mean(valid_intensity)
            silence_threshold = mean_intensity * 0.3  # 30% ì´í•˜ë¥¼ ë¬´ìŒìœ¼ë¡œ íŒì •
            
            # ì—°ì†ëœ ìŒì„± êµ¬ê°„ ì°¾ê¸°
            speech_mask = intensity_values > silence_threshold
            
            if not np.any(speech_mask):
                return 0.0, features['duration']
            
            # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ìŒì„± í”„ë ˆì„ ì°¾ê¸°
            speech_indices = np.where(speech_mask)[0]
            start_idx = speech_indices[0]
            end_idx = speech_indices[-1]
            
            # ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (ì•½ê°„ì˜ ë§ˆì§„ ì¶”ê°€)
            start_time = max(0, times[start_idx] - 0.05)
            end_time = min(features['duration'], times[end_idx] + 0.05)
            
            return start_time, end_time
            
        except Exception as e:
            print(f"âš ï¸ ìŒì„± êµ¬ê°„ íƒì§€ ì‹¤íŒ¨: {e}")
            return 0.0, features['duration']
    
    def _calculate_boundary_scores(self, features: Dict[str, Any], start_time: float, end_time: float) -> np.ndarray:
        """ë‹¤ì°¨ì› íŠ¹ì§•ì„ ì¢…í•©í•œ ê²½ê³„ ì ìˆ˜ ê³„ì‚°"""
        try:
            times = features['times']
            
            # ê´€ì‹¬ êµ¬ê°„ ë§ˆìŠ¤í¬
            time_mask = (times >= start_time) & (times <= end_time)
            
            if not np.any(time_mask):
                return np.zeros(len(times))
            
            # ê° íŠ¹ì§•ë³„ ê²½ê³„ ì ìˆ˜ ê³„ì‚°
            scores = np.zeros(len(times))
            
            # 1. ì—ë„ˆì§€ ë³€í™” ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.3)
            energy_scores = self._normalize_array(features['energy_change'])
            scores += 0.3 * energy_scores
            
            # 2. í”¼ì¹˜ ë³€í™” ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.25)
            pitch_scores = self._normalize_array(features['pitch_change'])
            scores += 0.25 * pitch_scores
            
            # 3. ìŠ¤í™íŠ¸ëŸ´ í”ŒëŸ­ìŠ¤ ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.2)
            if 'spectral_data' in features and 'flux' in features['spectral_data']:
                flux_scores = self._normalize_array(features['spectral_data']['flux'])
                if len(flux_scores) == len(scores):
                    scores += 0.2 * flux_scores
            
            # 4. í¬ë¨¼íŠ¸ ë³€í™” ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.15)
            if 'formant_data' in features:
                formant_scores = self._calculate_formant_change_scores(features['formant_data'])
                if len(formant_scores) == len(scores):
                    scores += 0.15 * formant_scores
            
            # 5. ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬ ë³€í™” ì ìˆ˜ (ê°€ì¤‘ì¹˜: 0.1)
            if 'spectral_data' in features and 'centroid' in features['spectral_data']:
                centroid_change = np.abs(np.diff(features['spectral_data']['centroid']))
                centroid_scores = np.pad(centroid_change, (1, 0), mode='constant', constant_values=0)
                centroid_scores = self._normalize_array(centroid_scores)
                if len(centroid_scores) == len(scores):
                    scores += 0.1 * centroid_scores
            
            # ê´€ì‹¬ êµ¬ê°„ ì™¸ë¶€ëŠ” 0ìœ¼ë¡œ ì„¤ì •
            scores[~time_mask] = 0
            
            return scores
            
        except Exception as e:
            print(f"âš ï¸ ê²½ê³„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.zeros(len(features['times']))
    
    def _normalize_array(self, arr: np.ndarray) -> np.ndarray:
        """ë°°ì—´ ì •ê·œí™” (0~1 ë²”ìœ„)"""
        try:
            if len(arr) == 0:
                return arr
            
            arr_min, arr_max = np.min(arr), np.max(arr)
            if arr_max == arr_min:
                return np.zeros_like(arr)
            
            return (arr - arr_min) / (arr_max - arr_min)
        except:
            return np.zeros_like(arr)
    
    def _calculate_formant_change_scores(self, formant_data: Dict[str, np.ndarray]) -> np.ndarray:
        """í¬ë¨¼íŠ¸ ë³€í™” ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        try:
            f1, f2 = formant_data['f1'], formant_data['f2']
            
            if len(f1) == 0 or len(f2) == 0:
                return np.array([])
            
            # F1, F2 ë³€í™”ìœ¨ ê³„ì‚°
            f1_change = np.abs(np.diff(f1))
            f2_change = np.abs(np.diff(f2))
            
            # ì¡°í•©ëœ í¬ë¨¼íŠ¸ ë³€í™” ì ìˆ˜
            formant_change = np.sqrt(f1_change**2 + f2_change**2)
            formant_scores = np.pad(formant_change, (1, 0), mode='constant', constant_values=0)
            
            return self._normalize_array(formant_scores)
            
        except Exception as e:
            return np.array([])
    
    def _find_boundary_candidates(self, boundary_scores: np.ndarray, times: np.ndarray, 
                                  start_time: float, end_time: float) -> List[float]:
        """ê²½ê³„ ì ìˆ˜ì—ì„œ í›„ë³´ ê²½ê³„ì  ì¶”ì¶œ"""
        try:
            if len(boundary_scores) == 0:
                return [start_time, end_time]
            
            # ì ì‘ì  ì„ê³„ê°’ ì„¤ì •
            score_mean = np.mean(boundary_scores[boundary_scores > 0])
            score_std = np.std(boundary_scores[boundary_scores > 0])
            threshold = score_mean + 0.5 * score_std
            
            # í”¼í¬ íƒì§€ (local maxima)
            candidates = []
            window_size = max(3, len(boundary_scores) // 50)  # ì ì‘ì  ìœˆë„ìš° í¬ê¸°
            
            for i in range(window_size, len(boundary_scores) - window_size):
                if boundary_scores[i] > threshold:
                    # ì§€ì—­ ìµœëŒ€ê°’ í™•ì¸
                    local_region = boundary_scores[i-window_size:i+window_size+1]
                    if boundary_scores[i] == np.max(local_region):
                        candidates.append(times[i])
            
            # ì‹œì‘ì ê³¼ ëì  ì¶”ê°€
            candidates = [start_time] + [c for c in candidates if start_time < c < end_time] + [end_time]
            
            return sorted(list(set(candidates)))
            
        except Exception as e:
            print(f"âš ï¸ í›„ë³´ ê²½ê³„ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return [start_time, end_time]
    
    def _optimize_boundaries_for_syllables(self, candidates: List[float], target_syllables: int,
                                           start_time: float, end_time: float) -> List[float]:
        """ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ê²Œ ê²½ê³„ì  ìµœì í™”"""
        try:
            current_segments = len(candidates) - 1
            
            if current_segments == target_syllables:
                return candidates
            elif current_segments > target_syllables:
                # ë„ˆë¬´ ë§ì€ ê²½ê³„ - ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë“¤ë§Œ ì„ íƒ
                return self._select_best_boundaries(candidates, target_syllables)
            else:
                # ë¶€ì¡±í•œ ê²½ê³„ - ì¶”ê°€ ë¶„í• 
                return self._add_boundaries(candidates, target_syllables, start_time, end_time)
                
        except Exception as e:
            print(f"âš ï¸ ê²½ê³„ ìµœì í™” ì‹¤íŒ¨: {e}")
            # í´ë°±: ê· ë“± ë¶„í• 
            boundaries = []
            for i in range(target_syllables + 1):
                boundaries.append(start_time + (end_time - start_time) * i / target_syllables)
            return boundaries
    
    def _select_best_boundaries(self, candidates: List[float], target_syllables: int) -> List[float]:
        """ê°€ì¥ ì ì ˆí•œ ê²½ê³„ì ë“¤ ì„ íƒ"""
        if len(candidates) <= target_syllables + 1:
            return candidates
        
        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ì€ í•­ìƒ ìœ ì§€
        result = [candidates[0]]
        
        # ì¤‘ê°„ ê²½ê³„ë“¤ì„ ê· ë“±í•˜ê²Œ ì„ íƒ
        middle_candidates = candidates[1:-1]
        if middle_candidates and target_syllables > 1:
            indices = np.linspace(0, len(middle_candidates)-1, target_syllables-1, dtype=int)
            for idx in indices:
                result.append(middle_candidates[idx])
        
        result.append(candidates[-1])
        return sorted(result)
    
    def _add_boundaries(self, candidates: List[float], target_syllables: int,
                       start_time: float, end_time: float) -> List[float]:
        """ë¶€ì¡±í•œ ê²½ê³„ì  ì¶”ê°€"""
        result = candidates[:]
        
        while len(result) - 1 < target_syllables:
            # ê°€ì¥ ê¸´ êµ¬ê°„ ì°¾ê¸°
            max_length = 0
            max_idx = 0
            
            for i in range(len(result) - 1):
                length = result[i + 1] - result[i]
                if length > max_length:
                    max_length = length
                    max_idx = i
            
            # ì¤‘ê°„ì  ì¶”ê°€
            mid_point = (result[max_idx] + result[max_idx + 1]) / 2
            result.insert(max_idx + 1, mid_point)
        
        return sorted(result)
    
    def _calculate_segment_quality(self, features: Dict[str, Any], start: float, end: float) -> float:
        """ìŒì ˆ êµ¬ê°„ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            times = features['times']
            
            # êµ¬ê°„ ë§ˆìŠ¤í¬
            segment_mask = (times >= start) & (times <= end)
            
            if not np.any(segment_mask):
                return 0.5  # ê¸°ë³¸ ì ìˆ˜
            
            quality_scores = []
            
            # 1. ê°•ë„ ì¼ê´€ì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            segment_intensity = features['intensity_values'][segment_mask]
            if len(segment_intensity) > 1:
                intensity_consistency = 1.0 - (np.std(segment_intensity) / (np.mean(segment_intensity) + 1e-6))
                quality_scores.append(max(0, min(1, intensity_consistency)))
            
            # 2. í”¼ì¹˜ ì•ˆì •ì„±
            segment_pitch = features['pitch_values'][segment_mask]
            valid_pitch = segment_pitch[segment_pitch > 0]
            if len(valid_pitch) > 1:
                pitch_stability = 1.0 - (np.std(valid_pitch) / (np.mean(valid_pitch) + 1e-6))
                quality_scores.append(max(0, min(1, pitch_stability)))
            
            # 3. êµ¬ê°„ ê¸¸ì´ ì ì ˆì„± (0.1~0.8ì´ˆê°€ ì ì ˆ)
            duration = end - start
            if 0.1 <= duration <= 0.8:
                duration_score = 1.0
            elif duration < 0.1:
                duration_score = duration / 0.1
            else:
                duration_score = max(0.3, 0.8 / duration)
            quality_scores.append(duration_score)
            
            # 4. ìŠ¤í™íŠ¸ëŸ¼ ì¼ê´€ì„±
            if 'spectral_data' in features and 'centroid' in features['spectral_data']:
                segment_centroid = features['spectral_data']['centroid'][segment_mask]
                if len(segment_centroid) > 1:
                    centroid_consistency = 1.0 - (np.std(segment_centroid) / (np.mean(segment_centroid) + 1e-6))
                    quality_scores.append(max(0, min(1, centroid_consistency)))
            
            # í‰ê·  í’ˆì§ˆ ì ìˆ˜
            if quality_scores:
                return np.mean(quality_scores)
            else:
                return 0.5
                
        except Exception as e:
            print(f"âš ï¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

class AudioFeatureExtractor:
    """
    ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì „ìš© í´ë˜ìŠ¤ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    
    ì‚¬ìš©ë²•:
        extractor = AudioFeatureExtractor()
        features = extractor.extract(sound)
    """
    
    def __init__(self, 
                 pitch_floor: float = 75.0, 
                 pitch_ceiling: float = 600.0,
                 silence_threshold_ratio: float = 0.25):
        self.pitch_floor = pitch_floor
        self.pitch_ceiling = pitch_ceiling
        self.silence_threshold_ratio = silence_threshold_ratio
    
    def extract(self, sound: pm.Sound) -> AudioFeatures:
        """ìŒì„±ì—ì„œ í•µì‹¬ íŠ¹ì§•ë“¤ ì¶”ì¶œ"""
        try:
            # ê¸°ë³¸ ì •ë³´
            duration = sound.get_total_duration()
            start_time = sound.xmin
            end_time = sound.xmax
            
            # ê°•ë„(ì—ë„ˆì§€) ë¶„ì„
            intensity = sound.to_intensity(minimum_pitch=self.pitch_floor)
            intensity_times = intensity.xs()
            intensity_values = intensity.values.T.flatten()
            
            # í”¼ì¹˜ ë¶„ì„
            pitch = sound.to_pitch(
                pitch_floor=self.pitch_floor, 
                pitch_ceiling=self.pitch_ceiling
            )
            pitch_times = pitch.xs()
            pitch_values = pitch.selected_array['frequency']
            
            # ìœ íš¨í•œ ìŒì„± êµ¬ê°„ íƒì§€
            valid_start, valid_end = self._find_valid_speech_region(
                intensity_times, intensity_values, start_time, end_time
            )
            
            return AudioFeatures(
                intensity_times=intensity_times,
                intensity_values=intensity_values,
                pitch_times=pitch_times,
                pitch_values=pitch_values,
                duration=duration,
                valid_speech_start=valid_start,
                valid_speech_end=valid_end
            )
            
        except Exception as e:
            raise Exception(f"ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    def _find_valid_speech_region(self, times: np.ndarray, values: np.ndarray, 
                                  start_time: float, end_time: float) -> Tuple[float, float]:
        """ìœ íš¨í•œ ìŒì„± êµ¬ê°„ íƒì§€ (ë¬´ìŒ ì œê±°)"""
        try:
            # ë¬´ìŒ ì„ê³„ê°’ ê³„ì‚°
            mean_intensity = np.mean(values[values > 0])
            silence_threshold = mean_intensity * self.silence_threshold_ratio
            
            # ìœ íš¨í•œ ìŒì„± êµ¬ê°„ ì°¾ê¸°
            valid_regions = []
            in_speech = False
            speech_start = None
            
            for t, intensity_val in zip(times, values):
                if intensity_val > silence_threshold and not in_speech:
                    speech_start = t
                    in_speech = True
                elif intensity_val <= silence_threshold and in_speech:
                    if speech_start is not None:
                        valid_regions.append((speech_start, t))
                    in_speech = False
                    speech_start = None
            
            # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
            if in_speech and speech_start is not None:
                valid_regions.append((speech_start, end_time))
            
            if not valid_regions:
                return start_time, end_time
            
            # ì „ì²´ ìŒì„± êµ¬ê°„ ë³‘í•©
            speech_start_time = min(r[0] for r in valid_regions)
            speech_end_time = max(r[1] for r in valid_regions)
            
            return speech_start_time, speech_end_time
            
        except Exception as e:
            print(f"âš ï¸ ìŒì„± êµ¬ê°„ íƒì§€ ì‹¤íŒ¨: {e}")
            return start_time, end_time

class SyllableBoundaryDetector:
    """
    ìŒì ˆ ê²½ê³„ íƒì§€ ì „ìš© í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        detector = SyllableBoundaryDetector()
        boundaries = detector.detect(features, target_syllable_count)
    """
    
    def __init__(self, 
                 energy_percentile: float = 70.0,
                 pitch_threshold_semitones: float = 1.0):
        self.energy_percentile = energy_percentile
        self.pitch_threshold_semitones = pitch_threshold_semitones
    
    def detect(self, features: AudioFeatures, target_count: int) -> List[float]:
        """ìŒì„±í•™ì  íŠ¹ì§•ì„ ì¢…í•©í•œ ìŒì ˆ ê²½ê³„ íƒì§€"""
        try:
            # 1. ì—ë„ˆì§€ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€
            energy_boundaries = self._find_energy_boundaries(
                features.intensity_times, features.intensity_values,
                features.valid_speech_start, features.valid_speech_end
            )
            
            # 2. í”¼ì¹˜ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€
            pitch_boundaries = self._find_pitch_boundaries(
                features.pitch_times, features.pitch_values,
                features.valid_speech_start, features.valid_speech_end
            )
            
            # 3. ê²½ê³„ì  í†µí•© ë° ìµœì í™”
            all_boundaries = sorted(set(energy_boundaries + pitch_boundaries))
            
            # ì‹œì‘/ë ë³´ì¥
            boundaries = [features.valid_speech_start]
            for b in all_boundaries:
                if features.valid_speech_start < b < features.valid_speech_end:
                    boundaries.append(b)
            boundaries.append(features.valid_speech_end)
            
            # 4. ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ì¶¤
            optimized_boundaries = self._optimize_boundaries(boundaries, target_count)
            
            return optimized_boundaries
            
        except Exception as e:
            print(f"âŒ ê²½ê³„ íƒì§€ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê· ë“± ë¶„í• 
            return self._equal_division_fallback(
                features.valid_speech_start, features.valid_speech_end, target_count
            )
    
    def _find_energy_boundaries(self, times: np.ndarray, values: np.ndarray, 
                               start_time: float, end_time: float) -> List[float]:
        """ì—ë„ˆì§€ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€"""
        try:
            # ê´€ì‹¬ êµ¬ê°„ë§Œ ì¶”ì¶œ
            mask = (times >= start_time) & (times <= end_time)
            region_times = times[mask]
            region_values = values[mask]
            
            if len(region_values) < 10:
                return []
            
            # 1ì°¨ ë¯¸ë¶„ìœ¼ë¡œ ë³€í™”ìœ¨ ê³„ì‚°
            energy_diff = np.abs(np.diff(region_values))
            
            # ë³€í™”ê°€ í° ì§€ì  íƒì§€
            threshold = np.percentile(energy_diff, self.energy_percentile)
            peak_indices = []
            
            for i in range(1, len(energy_diff) - 1):
                if (energy_diff[i] > threshold and 
                    energy_diff[i] > energy_diff[i-1] and 
                    energy_diff[i] > energy_diff[i+1]):
                    peak_indices.append(i)
            
            # ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            boundaries = [float(region_times[idx]) for idx in peak_indices 
                         if idx < len(region_times)]
            
            return boundaries
            
        except Exception as e:
            print(f"âŒ ì—ë„ˆì§€ ê²½ê³„ íƒì§€ ì‹¤íŒ¨: {e}")
            return []
    
    def _find_pitch_boundaries(self, times: np.ndarray, values: np.ndarray,
                              start_time: float, end_time: float) -> List[float]:
        """í”¼ì¹˜ ë³€í™” ê¸°ë°˜ ê²½ê³„ íƒì§€"""
        try:
            # ê´€ì‹¬ êµ¬ê°„ë§Œ ì¶”ì¶œ (ìœ íš¨í•œ í”¼ì¹˜ë§Œ)
            mask = (times >= start_time) & (times <= end_time) & (values > 0)
            region_times = times[mask]
            region_values = values[mask]
            
            if len(region_values) < 5:
                return []
            
            # í”¼ì¹˜ ë³€í™”ìœ¨ ê³„ì‚° (ì„¸ë¯¸í†¤ ë‹¨ìœ„)
            pitch_semitones = 12 * np.log2(region_values / 440) + 69
            pitch_diff = np.abs(np.diff(pitch_semitones))
            
            # í° í”¼ì¹˜ ë³€í™” ì§€ì  íƒì§€
            boundary_indices = []
            for i in range(len(pitch_diff)):
                if pitch_diff[i] > self.pitch_threshold_semitones:
                    boundary_indices.append(i)
            
            # ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            boundaries = [float(region_times[idx]) for idx in boundary_indices 
                         if idx < len(region_times)]
            
            return boundaries
            
        except Exception as e:
            print(f"âŒ í”¼ì¹˜ ê²½ê³„ íƒì§€ ì‹¤íŒ¨: {e}")
            return []
    
    def _optimize_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ê²½ê³„ì ì„ ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ê²Œ ìµœì í™”"""
        try:
            if len(boundaries) <= 2:
                return self._equal_division_fallback(
                    boundaries[0], boundaries[-1], target_count
                )
            
            current_segments = len(boundaries) - 1
            
            if current_segments == target_count:
                return boundaries
            elif current_segments > target_count:
                # ë„ˆë¬´ ë§ì€ ê²½ê³„ - ê°€ì¥ ê°•í•œ ê²ƒë“¤ë§Œ ì„ íƒ
                return self._select_strongest_boundaries(boundaries, target_count)
            else:
                # ë¶€ì¡±í•œ ê²½ê³„ - ê¸´ êµ¬ê°„ì„ ë¶„í• 
                return self._add_missing_boundaries(boundaries, target_count)
                
        except Exception as e:
            print(f"âŒ ê²½ê³„ ìµœì í™” ì‹¤íŒ¨: {e}")
            return self._equal_division_fallback(
                boundaries[0], boundaries[-1], target_count
            )
    
    def _select_strongest_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ê°€ì¥ ê°•í•œ ê²½ê³„ì ë“¤ë§Œ ì„ íƒ"""
        if len(boundaries) <= target_count + 1:
            return boundaries
            
        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ì€ í•­ìƒ ìœ ì§€
        result = [boundaries[0]]
        
        # ì¤‘ê°„ ê²½ê³„ë“¤ ì¤‘ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
        middle = boundaries[1:-1]
        if middle and target_count > 1:
            step = len(middle) / (target_count - 1)
            for i in range(target_count - 1):
                idx = int(i * step)
                if idx < len(middle):
                    result.append(middle[idx])
        
        result.append(boundaries[-1])
        return sorted(result)
    
    def _add_missing_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ë¶€ì¡±í•œ ê²½ê³„ì  ì¶”ê°€"""
        result = boundaries[:]
        
        while len(result) - 1 < target_count:
            # ê°€ì¥ ê¸´ êµ¬ê°„ ì°¾ê¸°
            max_length = 0
            max_idx = 0
            
            for i in range(len(result) - 1):
                length = result[i + 1] - result[i]
                if length > max_length:
                    max_length = length
                    max_idx = i
            
            # ì¤‘ê°„ì  ì¶”ê°€
            mid_point = (result[max_idx] + result[max_idx + 1]) / 2
            result.insert(max_idx + 1, mid_point)
        
        return sorted(result)
    
    def _equal_division_fallback(self, start: float, end: float, target_count: int) -> List[float]:
        """í´ë°±: ê· ë“± ë¶„í• """
        result = []
        for i in range(target_count + 1):
            result.append(start + (end - start) * i / target_count)
        return result

class STTBasedSegmenter:
    """
    STT ì—”ì§„ ê¸°ë°˜ ì •í™•í•œ ìŒì ˆ ë¶„ì ˆ í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        segmenter = STTBasedSegmenter()
        segments = segmenter.segment_from_audio_file("audio.wav", "ë°˜ê°€ì›Œìš”")
    """
    
    def __init__(self):
        if STT_AVAILABLE:
            try:
                self.stt_processor = AdvancedSTTProcessor()
                print("ğŸ¯ STT ê¸°ë°˜ ì •ë°€ ë¶„ì ˆ í™œì„±í™”")
            except Exception as e:
                print(f"âŒ STT í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.stt_processor = None
        else:
            self.stt_processor = None
        
        # í´ë°±ì„ ìœ„í•œ ê¸°ì¡´ ë¶„ì ˆê¸°
        self.fallback_segmenter = FallbackSyllableSegmenter()
    
    def segment_from_audio_file(self, audio_file: str, sentence: str) -> List[SyllableSegment]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ STT ê¸°ë°˜ ì •í™•í•œ ìŒì ˆ ë¶„ì ˆ
        
        Args:
            audio_file: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            sentence: ì˜ˆìƒ ë¬¸ì¥ (ì˜ˆ: "ë°˜ê°€ì›Œìš”")
            
        Returns:
            List[SyllableSegment]: ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ìŒì ˆ ë¶„ì ˆ
        """
        if not self.stt_processor:
            print("âš ï¸ STT ë¹„í™œì„± - í´ë°± ë¶„ì ˆ ì‚¬ìš©")
            sound = pm.Sound(audio_file)
            syllables_text = list(sentence.replace(' ', ''))
            return self.fallback_segmenter.segment(sound, syllables_text)
        
        try:
            print(f"ğŸ¤ STT ê¸°ë°˜ ì •ë°€ ë¶„ì ˆ ì‹œì‘: {sentence}")
            
            # 1. STTë¡œ ìŒì„± ì „ì‚¬ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            transcription_result = self.stt_processor.stt.transcribe(
                audio_file, language='ko', return_timestamps=True
            )
            
            print(f"ğŸ¯ STT ê²°ê³¼: '{transcription_result.text}'")
            print(f"ğŸ¯ ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„: {len(transcription_result.words)}ê°œ")
            
            # 2. ìŒì ˆ ì •ë ¬ (STT íƒ€ì„ìŠ¤íƒ¬í”„ í™œìš©)
            syllable_alignments = self.stt_processor.syllable_aligner.align_syllables_with_timestamps(
                transcription_result, audio_file
            )
            
            # 3. SyllableSegment í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            segments = []
            for alignment in syllable_alignments:
                segments.append(SyllableSegment(
                    label=alignment.syllable,
                    start=alignment.start_time,
                    end=alignment.end_time,
                    duration=alignment.end_time - alignment.start_time,
                    confidence=alignment.confidence
                ))
                
                print(f"   ğŸ¯ '{alignment.syllable}': {alignment.start_time:.3f}s ~ {alignment.end_time:.3f}s (ì‹ ë¢°ë„: {alignment.confidence:.2f})")
            
            print(f"âœ… STT ê¸°ë°˜ ë¶„ì ˆ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
            return segments
            
        except Exception as e:
            print(f"âŒ STT ë¶„ì ˆ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
            sound = pm.Sound(audio_file)
            syllables_text = list(sentence.replace(' ', ''))
            return self.fallback_segmenter.segment(sound, syllables_text)

class FallbackSyllableSegmenter:
    """
    ì •ë°€ ìŒì ˆ ë¶„ì ˆ ë©”ì¸ í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        segmenter = FallbackSyllableSegmenter()
        segments = segmenter.segment(sound, syllable_labels)
    """
    
    def __init__(self, **kwargs):
        self.feature_extractor = AudioFeatureExtractor(**kwargs)
        self.boundary_detector = SyllableBoundaryDetector(**kwargs)
    
    def segment(self, sound: pm.Sound, syllable_labels: List[str]) -> List[SyllableSegment]:
        """ìŒì„±ì„ ì •ë°€í•˜ê²Œ ìŒì ˆë³„ë¡œ ë¶„ì ˆ"""
        try:
            print("ğŸ”¬ ì •ë°€ ìŒì„±í•™ì  ë¶„ì ˆ ì‹œì‘")
            
            # 1. ìŒì„± íŠ¹ì§• ì¶”ì¶œ
            features = self.feature_extractor.extract(sound)
            print(f"ğŸ”‡ ë¬´ìŒ ì œê±°: {features.valid_speech_start:.3f}s ~ {features.valid_speech_end:.3f}s")
            
            # 2. ìŒì ˆ ê²½ê³„ íƒì§€
            boundaries = self.boundary_detector.detect(features, len(syllable_labels))
            print(f"ğŸ¯ ê²½ê³„ì  íƒì§€: {len(boundaries)-1}ê°œ êµ¬ê°„")
            
            # 3. ìŒì ˆ êµ¬ê°„ ìƒì„±
            segments = []
            for i, label in enumerate(syllable_labels):
                segment = SyllableSegment(
                    label=label,
                    start=boundaries[i],
                    end=boundaries[i + 1],
                    duration=boundaries[i + 1] - boundaries[i]
                )
                segments.append(segment)
                print(f"   ğŸ¯ '{label}': {segment.start:.3f}s ~ {segment.end:.3f}s")
            
            print(f"âœ… ì •ë°€ ë¶„ì ˆ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
            return segments
            
        except Exception as e:
            print(f"âŒ ì •ë°€ ë¶„ì ˆ ì‹¤íŒ¨, ê¸°ë³¸ ë¶„ì ˆë¡œ í´ë°±: {e}")
            return self._fallback_equal_segmentation(sound, syllable_labels)
    
    def _fallback_equal_segmentation(self, sound: pm.Sound, syllable_labels: List[str]) -> List[SyllableSegment]:
        """í´ë°±: ê¸°ë³¸ ê· ë“± ë¶„í• """
        duration = sound.get_total_duration()
        syllable_duration = duration / len(syllable_labels)
        
        segments = []
        for i, label in enumerate(syllable_labels):
            start_time = i * syllable_duration
            end_time = (i + 1) * syllable_duration
            
            if i == len(syllable_labels) - 1:
                end_time = duration
            
            segment = SyllableSegment(
                label=label,
                start=start_time,
                end=end_time,
                duration=end_time - start_time
            )
            segments.append(segment)
        
        return segments

class TextGridGenerator:
    """
    TextGrid íŒŒì¼ ìƒì„± ì „ìš© í´ë˜ìŠ¤
    
    ì‚¬ìš©ë²•:
        generator = TextGridGenerator()
        generator.save(segments, output_path, total_duration)
    """
    
    def save(self, segments: List[SyllableSegment], output_path: str, total_duration: float):
        """ìŒì ˆ ì •ë³´ë¥¼ TextGrid íŒŒì¼ë¡œ ì €ì¥"""
        try:
            print(f"ğŸ’¾ TextGrid ì €ì¥: {output_path}")
            
            # TextGrid ë¬¸ìì—´ ìƒì„±
            textgrid_content = f'''File type = "ooTextFile"
Object class = "TextGrid"

xmin = 0 
xmax = {total_duration} 
tiers? <exists> 
size = 1 
item []: 
    item [1]:
        class = "IntervalTier" 
        name = "syllables" 
        xmin = 0 
        xmax = {total_duration} 
        intervals: size = {len(segments)} 
'''
            
            # ê° ìŒì ˆ êµ¬ê°„ ì¶”ê°€
            for i, segment in enumerate(segments):
                textgrid_content += f'''        intervals [{i+1}]:
            xmin = {segment.start} 
            xmax = {segment.end} 
            text = "{segment.label}" 
'''
            
            # íŒŒì¼ ì €ì¥
            with open(output_path, 'w', encoding='utf-16') as f:
                f.write(textgrid_content)
            
            print(f"âœ… TextGrid ì €ì¥ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
            
        except Exception as e:
            raise Exception(f"TextGrid ì €ì¥ ì‹¤íŒ¨: {e}")

def split_korean_sentence(sentence: str) -> List[str]:
    """í•œêµ­ì–´ ë¬¸ì¥ì„ ìŒì ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬"""
    return [char for char in sentence.strip() if char.strip()]

# í¸ì˜ í•¨ìˆ˜ë“¤
def analyze_audio_file(audio_path: str, syllable_text: str, **kwargs) -> List[SyllableSegment]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì •ë°€í•œ ìŒì ˆ ë¶„ì ˆ ìˆ˜í–‰
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        syllable_text: ëª©í‘œ ë¬¸ì¥ (ì˜ˆ: "ë°˜ê°€ì›Œìš”")
        **kwargs: ë¶„ì„ íŒŒë¼ë©”í„° (pitch_floor, pitch_ceiling ë“±)
    
    Returns:
        ìŒì ˆ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
    """
    try:
        print(f"ğŸ¯ ê³ ì •ë°€ ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘: {syllable_text}")
        
        # 1. ìµœìš°ì„ : STT ê¸°ë°˜ ë¶„ì ˆ ì‹œë„
        try:
            stt_segmenter = STTBasedSegmenter()
            segments = stt_segmenter.segment_from_audio_file(audio_path, syllable_text)
            print("âœ… STT ê¸°ë°˜ ë¶„ì ˆ ì„±ê³µ")
            return segments
        except Exception as stt_error:
            print(f"âš ï¸ STT ë¶„ì ˆ ì‹¤íŒ¨: {stt_error}, ê³ ì •ë°€ ë¶„ì„ìœ¼ë¡œ ì „í™˜")
        
        # 2. í´ë°±: ê³ ì •ë°€ ìŒì„±í•™ì  ë¶„ì„
        analyzer = HighPrecisionAudioAnalyzer(**kwargs)
        segments = analyzer.analyze_and_segment(audio_path, syllable_text)
        
        print("âœ… ê³ ì •ë°€ ìŒì„±í•™ì  ë¶„ì ˆ ì™„ë£Œ")
        return segments
        
    except Exception as e:
        raise Exception(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {e}")

def create_textgrid_from_audio(audio_path: str, syllable_text: str, 
                              output_path: Optional[str] = None, **kwargs) -> str:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ TextGrid ìƒì„±
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        syllable_text: ëª©í‘œ ë¬¸ì¥
        output_path: TextGrid ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        **kwargs: ë¶„ì„ íŒŒë¼ë©”í„°
    
    Returns:
        ìƒì„±ëœ TextGrid íŒŒì¼ ê²½ë¡œ
    """
    try:
        # ìŒì ˆ ë¶„ì ˆ ìˆ˜í–‰
        segments = analyze_audio_file(audio_path, syllable_text, **kwargs)
        
        # ì¶œë ¥ ê²½ë¡œ ìƒì„±
        if output_path is None:
            base_name = os.path.splitext(audio_path)[0]
            output_path = f"{base_name}.TextGrid"
        
        # ìŒì„± ê¸¸ì´ ê³„ì‚°
        sound = pm.Sound(audio_path)
        total_duration = sound.get_total_duration()
        
        # TextGrid ì €ì¥
        generator = TextGridGenerator()
        generator.save(segments, output_path, total_duration)
        
        return output_path
        
    except Exception as e:
        raise Exception(f"TextGrid ìƒì„± ì‹¤íŒ¨: {e}")