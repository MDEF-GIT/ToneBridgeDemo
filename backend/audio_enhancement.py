"""
ToneBridge ê³ ê¸‰ ìŒì„± ì²˜ë¦¬ ëª¨ë“ˆ
ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜(STT)ì™€ ìë™ ìŒì ˆ ë¶„ì ˆì„ í†µí•œ TextGrid ìµœì í™”
"""

import numpy as np
import parselmouth as pm
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import tempfile
import json
import subprocess  # Used for FFmpeg calls
import sys  # Used for path operations
import os  # Used for file operations

class STTProcessor:
    """
    ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ STT ë˜í¼ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        # ìƒˆë¡œìš´ ê³ ê¸‰ STT ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            from advanced_stt_processor import AdvancedSTTProcessor
            self.advanced_stt = AdvancedSTTProcessor(preferred_engine='whisper')
            self.whisper_available = 'whisper' in self.advanced_stt.stt.available_engines
            print(f"ğŸ¯ ê³ ê¸‰ STT ì‹œìŠ¤í…œ í™œì„±í™”: {self.advanced_stt.stt.engine}")
        except Exception as e:
            print(f"âš ï¸ ê³ ê¸‰ STT ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œ ì‚¬ìš©: {e}")
            self.advanced_stt = None
            self.whisper_available = self._check_whisper()
    
    def _check_whisper(self) -> bool:
        """Whisper ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        try:
            import whisper
            return True
        except ImportError:
            print("âš ï¸ Whisper ë¯¸ì„¤ì¹˜ - STT ê¸°ëŠ¥ ì œí•œë¨")
            return False
    
    def transcribe_audio(self, audio_file: str, language: str = 'ko') -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê³ ê¸‰ STT ë˜ëŠ” ê¸°ë³¸ STT)
        """
        if self.advanced_stt:
            # ê³ ê¸‰ STT ì‚¬ìš©
            try:
                result = self.advanced_stt.stt.transcribe(audio_file, language=language)
                korean_text = self._filter_korean_text(result.text)
                print(f"ğŸ¤ ê³ ê¸‰ STT ê²°ê³¼ ({result.engine}): {korean_text}")
                return korean_text
            except Exception as e:
                print(f"âŒ ê³ ê¸‰ STT ì˜¤ë¥˜: {e}")
                raise Exception(f"ê³ ê¸‰ STT ì²˜ë¦¬ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ì „ì‚¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ")
        
        # ê¸°ë³¸ STT ì‚¬ìš©
        if not self.whisper_available:
            raise Exception("Whisper ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ì „ì‚¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ")
        
        try:
            import whisper
            model = whisper.load_model("base")
            result = model.transcribe(audio_file, language=language)
            
            # í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            text = result["text"].strip()
            korean_text = self._filter_korean_text(text)
            
            print(f"ğŸ¤ ê¸°ë³¸ STT ê²°ê³¼: {korean_text}")
            return korean_text
            
        except Exception as e:
            print(f"âŒ STT ì˜¤ë¥˜: {e}")
            raise Exception(f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {e} - ê¸°ë³¸ ì „ì‚¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ")
    
    def _filter_korean_text(self, text: str) -> str:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§"""
        korean_text = ''.join(c for c in text if self._is_korean(c) or c.isspace())
        return korean_text.strip()
    
    def _is_korean(self, char: str) -> bool:
        """í•œêµ­ì–´ ë¬¸ìì¸ì§€ í™•ì¸"""
        return 0xAC00 <= ord(char) <= 0xD7A3 if len(char) == 1 else False
    


class AudioSegmenter:
    """
    ê³ ê¸‰ ìŒì„± ë¶„ì ˆ ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        self.sound = None
        
    def segment_by_energy(self, audio_file: str, target_syllables: str = "") -> List[Dict]:
        """
        ì—ë„ˆì§€ ê¸°ë°˜ ìŒì ˆ ë¶„ì ˆ
        """
        self.sound = pm.Sound(audio_file)
        
        print(f"ğŸ¯ ìŒì„± ê¸¸ì´: {self.sound.duration:.3f}ì´ˆ")
        
        # Intensity ê³„ì‚°
        intensity = self.sound.to_intensity(time_step=0.01)
        times = intensity.xs()
        values = intensity.values[0]
        
        # ê¸°ë³¸ ë¬´ìŒ êµ¬ê°„ ì œê±°
        self._remove_silence_boundaries(times, values)
        
        # ëª©í‘œ ìŒì ˆì´ ìˆìœ¼ë©´ ê·¸ì— ë§ì¶° ë¶„ì ˆ
        if target_syllables:
            syllable_list = list(target_syllables.replace(' ', ''))
            return self._segment_to_target(times, values, syllable_list)
        
        # ìë™ ë¶„ì ˆ
        return self._auto_segment(times, values)
    
    def _remove_silence_boundaries(self, times, values):
        """ë¬´ìŒ êµ¬ê°„ ê²½ê³„ ì œê±°"""
        # í‰ê·  ê°•ë„ì˜ 30% ì´í•˜ë¥¼ ë¬´ìŒìœ¼ë¡œ íŒì •
        threshold = np.mean(values) * 0.3
        
        # ì²˜ìŒê³¼ ëì˜ ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°
        start_idx = 0
        end_idx = len(values) - 1
        
        # ì‹œì‘ ë¬´ìŒ êµ¬ê°„
        for i, val in enumerate(values):
            if val > threshold:
                start_idx = max(0, i - 5)  # 5í”„ë ˆì„ ì—¬ìœ 
                break
        
        # ë ë¬´ìŒ êµ¬ê°„
        for i in range(len(values) - 1, -1, -1):
            if values[i] > threshold:
                end_idx = min(len(values) - 1, i + 5)
                break
        
        print(f"ğŸ”‡ ë¬´ìŒ ì œê±°: {times[start_idx]:.3f}s ~ {times[end_idx]:.3f}s")
        
        return times[start_idx:end_idx], values[start_idx:end_idx]
    
    def _segment_to_target(self, times, values, syllable_list: List[str]) -> List[Dict]:
        """ëª©í‘œ ìŒì ˆ ìˆ˜ì— ë§ì¶° ë¶„ì ˆ"""
        num_syllables = len(syllable_list)
        total_duration = times[-1] - times[0]
        
        print(f"ğŸ¯ ëª©í‘œ: {num_syllables}ê°œ ìŒì ˆ - {syllable_list}")
        
        # ì—ë„ˆì§€ ê¸°ë°˜ í›„ë³´ ê²½ê³„ ì°¾ê¸°
        boundaries = self._find_energy_boundaries(times, values, num_syllables)
        
        # ìŒì ˆ ì •ë³´ ìƒì„±
        syllables = []
        for i in range(len(boundaries) - 1):
            syllables.append({
                'label': syllable_list[i] if i < len(syllable_list) else '',
                'start': boundaries[i],
                'end': boundaries[i + 1],
                'confidence': 0.8
            })
        
        return syllables
    
    def _find_energy_boundaries(self, times, values, target_count: int) -> List[float]:
        """ì—ë„ˆì§€ ë³€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²½ê³„ ì°¾ê¸°"""
        # ìŠ¤ë¬´ë”©
        from scipy.signal import savgol_filter
        try:
            smoothed = savgol_filter(values, 11, 3)
        except:
            # scipy ì—†ìœ¼ë©´ ë‹¨ìˆœ ì´ë™í‰ê· 
            window = 5
            smoothed = np.convolve(values, np.ones(window)/window, mode='same')
        
        # ì—ë„ˆì§€ ë³€í™”ìœ¨ ê³„ì‚°
        energy_diff = np.abs(np.diff(smoothed))
        
        # ë³€í™”ê°€ í° ì§€ì ë“¤ ì°¾ê¸°
        from scipy.signal import find_peaks
        try:
            peaks, _ = find_peaks(energy_diff, 
                                  prominence=np.std(energy_diff) * 0.5,
                                  distance=10)
        except:
            # scipy ì—†ìœ¼ë©´ ë‹¨ìˆœ ë°©ë²•
            peaks = []
            threshold = np.mean(energy_diff) + np.std(energy_diff)
            for i in range(1, len(energy_diff) - 1):
                if (energy_diff[i] > threshold and 
                    energy_diff[i] > energy_diff[i-1] and 
                    energy_diff[i] > energy_diff[i+1]):
                    peaks.append(i)
        
        # ê²½ê³„ ì‹œê°„ ë³€í™˜
        peak_times = [times[p] for p in peaks if p < len(times)]
        
        # ì‹œì‘ê³¼ ë ì¶”ê°€
        boundaries = [times[0]] + peak_times + [times[-1]]
        boundaries.sort()
        
        # ëª©í‘œ ê°œìˆ˜ì— ë§ì¶° ì¡°ì •
        if len(boundaries) - 1 > target_count:
            # ë„ˆë¬´ ë§ìœ¼ë©´ ì¤‘ìš”í•œ ê²ƒë§Œ ì„ íƒ
            boundaries = self._select_best_boundaries(boundaries, target_count)
        elif len(boundaries) - 1 < target_count:
            # ë¶€ì¡±í•˜ë©´ ê· ë“± ë¶„í• ë¡œ ë³´ì™„
            boundaries = self._add_boundaries(boundaries, target_count)
        
        return boundaries
    
    def _select_best_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ê°€ì¥ ì ì ˆí•œ ê²½ê³„ ì„ íƒ"""
        if len(boundaries) <= target_count + 1:
            return boundaries
        
        # ì‹œì‘ê³¼ ëì€ ê³ ì •
        result = [boundaries[0]]
        
        # ì¤‘ê°„ ê²½ê³„ë“¤ ì¤‘ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
        middle_boundaries = boundaries[1:-1]
        if middle_boundaries:
            step = len(middle_boundaries) / (target_count - 1)
            for i in range(target_count - 1):
                idx = int(i * step)
                if idx < len(middle_boundaries):
                    result.append(middle_boundaries[idx])
        
        result.append(boundaries[-1])
        return sorted(result)
    
    def _add_boundaries(self, boundaries: List[float], target_count: int) -> List[float]:
        """ë¶€ì¡±í•œ ê²½ê³„ ì¶”ê°€"""
        result = boundaries[:]
        
        while len(result) - 1 < target_count:
            # ê°€ì¥ ê¸´ êµ¬ê°„ì„ ë°˜ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
            max_gap = 0
            max_idx = 0
            
            for i in range(len(result) - 1):
                gap = result[i + 1] - result[i]
                if gap > max_gap:
                    max_gap = gap
                    max_idx = i
            
            # ì¤‘ê°„ì  ì¶”ê°€
            mid_point = (result[max_idx] + result[max_idx + 1]) / 2
            result.insert(max_idx + 1, mid_point)
        
        return sorted(result)
    
    def _auto_segment(self, times, values) -> List[Dict]:
        """ìë™ ë¶„ì ˆ (ëª©í‘œ ìŒì ˆ ì—†ì„ ë•Œ)"""
        # í”¼í¬ ê¸°ë°˜ ë¶„ì ˆ
        peaks = self._find_intensity_peaks(values)
        
        boundaries = [times[0]]
        for peak in peaks:
            if peak < len(times):
                boundaries.append(times[peak])
        boundaries.append(times[-1])
        
        # ìŒì ˆ ìƒì„±
        syllables = []
        for i in range(len(boundaries) - 1):
            syllables.append({
                'label': f'ìŒì ˆ{i+1}',
                'start': boundaries[i],
                'end': boundaries[i + 1],
                'confidence': 0.6
            })
        
        return syllables
    
    def _find_intensity_peaks(self, values):
        """ê°•ë„ í”¼í¬ ì°¾ê¸°"""
        # ë‹¨ìˆœí•œ í”¼í¬ ì°¾ê¸° (scipy ì—†ì´)
        peaks = []
        threshold = np.mean(values) + np.std(values) * 0.5
        
        for i in range(1, len(values) - 1):
            if (values[i] > threshold and 
                values[i] > values[i-1] and 
                values[i] > values[i+1]):
                # ìµœì†Œ ê°„ê²© ìœ ì§€ (50ms = 5í”„ë ˆì„)
                if not peaks or i - peaks[-1] > 5:
                    peaks.append(i)
        
        return peaks


class TextGridOptimizer:
    """
    TextGrid ìë™ ìƒì„± ë° ìµœì í™”
    """
    
    def __init__(self):
        pass
    
    def create_optimized_textgrid(self, syllables: List[Dict], duration: float, 
                                  output_path: str) -> bool:
        """
        ìµœì í™”ëœ TextGrid ìƒì„±
        """
        try:
            content = self._generate_textgrid_content(syllables, duration)
            
            # UTF-16ìœ¼ë¡œ ì €ì¥
            with open(output_path, 'w', encoding='utf-16') as f:
                f.write(content)
            
            print(f"âœ… TextGrid ì €ì¥ ì™„ë£Œ: {output_path}")
            print(f"   ğŸ“Š ìŒì ˆ ìˆ˜: {len(syllables)}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ TextGrid ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def _generate_textgrid_content(self, syllables: List[Dict], duration: float) -> str:
        """
        TextGrid ë‚´ìš© ìƒì„±
        """
        content = f'''File type = "ooTextFile"
Object class = "TextGrid"

xmin = 0 
xmax = {duration} 
tiers? <exists> 
size = 1 
item []: 
    item [1]:
        class = "IntervalTier" 
        name = "syllables" 
        xmin = 0 
        xmax = {duration} 
        intervals: size = {len(syllables)} 
'''
        
        for i, syllable in enumerate(syllables):
            content += f'''        intervals [{i+1}]:
            xmin = {syllable['start']} 
            xmax = {syllable['end']} 
            text = "{syllable['label']}" 
'''
        
        return content


class AutomatedProcessor:
    """
    ì™„ì „ ìë™í™”ëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        self.stt = STTProcessor()
        self.segmenter = AudioSegmenter()
        self.textgrid_optimizer = TextGridOptimizer()
    
    def process_audio_completely(self, audio_file: str, 
                               sentence_hint: str = "") -> Dict:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ì™„ì „ ìë™ ì²˜ë¦¬ (ë¬´ìŒ ì œê±° ì‹œê°„ ë™ê¸°í™” í¬í•¨)
        
        Args:
            audio_file: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            sentence_hint: ë¬¸ì¥ íŒíŠ¸ (ì„ íƒì‚¬í•­)
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print(f"ğŸ¤–ğŸ¤–ğŸ¤– ìë™ ì²˜ë¦¬ ì‹œì‘: {Path(audio_file).name} ğŸ¤–ğŸ¤–ğŸ¤–")
        
        try:
            # 1. ìŒì„± ì¸ì‹
            if sentence_hint:
                transcription = sentence_hint
                engine_name = getattr(self.stt, 'engine', 'whisper')
                print(f"ğŸ¤ {engine_name} ì—”ì§„ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹œì‘...")
                print(f"ğŸ¤ ê³ ê¸‰ STT ê²°ê³¼ ({engine_name}): {transcription}")
            else:
                engine_name = getattr(self.stt, 'engine', 'whisper')
                print(f"ğŸ¤ {engine_name} ì—”ì§„ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹œì‘...")
                transcription = self.stt.transcribe_audio(audio_file)
                print(f"ğŸ¤ ê³ ê¸‰ STT ê²°ê³¼ ({engine_name}): {transcription}")
            
            if not transcription:
                transcription = "ë°˜ê°€ì›Œìš”"  # ê¸°ë³¸ê°’
                print("âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ - ê¸°ë³¸ ë¶„ì ˆ ì§„í–‰")
            
            # 2. ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì‹¤ì œ ìŒì„± êµ¬ê°„ íƒì§€
            sound = pm.Sound(audio_file)
            original_duration = sound.duration
            print(f"ğŸ¯ ìŒì„± ê¸¸ì´: {original_duration:.3f}ì´ˆ")
            
            # í”¼ì¹˜ ë¶„ì„ì„ í†µí•´ ì‹¤ì œ ìŒì„± êµ¬ê°„ íƒì§€ (ë¬´ìŒ ì œê±° ì‹œë®¬ë ˆì´ì…˜)
            pitch = sound.to_pitch_ac(
                time_step=0.01,
                pitch_floor=75.0,
                pitch_ceiling=600.0,
                very_accurate=False
            )
            
            # ìœ íš¨í•œ í”¼ì¹˜ êµ¬ê°„ ì°¾ê¸°
            times = pitch.xs()
            valid_pitch_times = []
            for t in times:
                f0 = pitch.get_value_at_time(t)
                if f0 is not None and not np.isnan(f0):
                    valid_pitch_times.append(t)
            
            if valid_pitch_times and len(valid_pitch_times) > 1:
                voice_start = valid_pitch_times[0]
                voice_end = valid_pitch_times[-1]
                voice_duration = voice_end - voice_start
                print(f"ğŸ”‡ ë¬´ìŒ ì œê±°: {voice_start:.3f}s ~ {voice_end:.3f}s")
            else:
                # ë°±ì—…: ì›ë³¸ ì „ì²´ ì‚¬ìš©
                voice_start = 0.0
                voice_end = original_duration
                voice_duration = original_duration
                print("âš ï¸ ìœ íš¨í•œ í”¼ì¹˜ êµ¬ê°„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ì›ë³¸ ì „ì²´ ì‚¬ìš©")
            
            # 3. ëª©í‘œ ìŒì ˆ ìˆ˜ ê³„ì‚°
            syllable_list = list(transcription.replace(' ', ''))
            num_syllables = len(syllable_list)
            print(f"ğŸ¯ ëª©í‘œ: {num_syllables}ê°œ ìŒì ˆ - {syllable_list}")
            
            # 4. ğŸš€ğŸš€ğŸš€ í•œêµ­ì–´ ì–¸ì–´í•™ì  ì •ë°€ ë¶„ì ˆ ì‹œìŠ¤í…œ ì‚¬ìš© ğŸš€ğŸš€ğŸš€
            print(f"ğŸ¯ğŸ¯ğŸ¯ KOREAN LINGUISTIC SEGMENTATION: ìë™ ë¶„ì ˆ ì‹œì‘ ğŸ¯ğŸ¯ğŸ¯")
            
            try:
                # STT ê¸°ë°˜ ì •ë°€ ë¶„ì ˆ ì‹œìŠ¤í…œ ì‚¬ìš©
                from audio_analysis import STTBasedSegmenter
                stt_segmenter = STTBasedSegmenter()
                segments = stt_segmenter.segment_from_audio_file(audio_file, transcription)
                
                print(f"âœ… STT ê¸°ë°˜ í•œêµ­ì–´ ì •ë°€ ë¶„ì ˆ ì™„ë£Œ: {len(segments)}ê°œ ìŒì ˆ")
                
                # SyllableSegmentë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                syllables = []
                for segment in segments:
                    syllables.append({
                        'label': segment.label,
                        'start': segment.start,
                        'end': segment.end
                    })
                    print(f"   ğŸ¯ '{segment.label}': {segment.start:.3f}s ~ {segment.end:.3f}s")
                
            except Exception as e:
                print(f"âŒ STT ê¸°ë°˜ ë¶„ì ˆ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
                # í´ë°±: ê¸°ì¡´ ê· ë“± ë¶„ë°° ë°©ì‹
                syllables = []
                for i, syllable_text in enumerate(syllable_list):
                    # ì‹¤ì œ ìŒì„± êµ¬ê°„ ë‚´ì—ì„œ ê· ë“± ë¶„ë°°
                    relative_start = (i / num_syllables) * voice_duration
                    relative_end = ((i + 1) / num_syllables) * voice_duration
                    
                    syllable_start = voice_start + relative_start
                    syllable_end = voice_start + relative_end
                    
                    syllables.append({
                        'label': syllable_text,
                        'start': syllable_start,
                        'end': syllable_end
                    })
                
                print(f"   ğŸ¯ '{syllable_text}': {syllable_start:.3f}s ~ {syllable_end:.3f}s")
            
            # 5. TextGrid ìƒì„± (ì›ë³¸ duration ì‚¬ìš©)
            output_path = str(Path(audio_file).with_suffix('.TextGrid'))
            success = self.textgrid_optimizer.create_optimized_textgrid(
                syllables, original_duration, output_path
            )
            
            print(f"âœ… TextGrid ì €ì¥ ì™„ë£Œ: {num_syllables}ê°œ ìŒì ˆ")
            print(f"ğŸ‰ ìë™ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ğŸ“„ í…ìŠ¤íŠ¸: {transcription}")
            print(f"   ğŸ”¢ ìŒì ˆ: {num_syllables}ê°œ")
            print(f"   ğŸ“‹ TextGrid: {output_path}")
            
            return {
                'success': success,
                'transcription': transcription,
                'syllables': syllables,
                'textgrid_path': output_path,
                'duration': original_duration
            }
            
        except Exception as e:
            print(f"âŒ ìë™ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e)
            }


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    processor = AutomatedProcessor()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
    test_file = "static/reference_files/ë‚­ë…ë¬¸ì¥.wav"
    if Path(test_file).exists():
        result = processor.process_audio_completely(test_file)
        print(f"ì²˜ë¦¬ ê²°ê³¼: {result}")