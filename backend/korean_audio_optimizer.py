"""
ToneBridge í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ìµœì í™” ì‹œìŠ¤í…œ
STT ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ í•œêµ­ì–´ ìŒì„±í•™ì  ì „ì²˜ë¦¬
"""

import numpy as np
import librosa
import soundfile as sf
import parselmouth as pm
from scipy import signal, ndimage
from scipy.fft import fft, ifft
from typing import Tuple, Dict, List, Optional
import logging
from pathlib import Path
import tempfile
import os

logger = logging.getLogger(__name__)

class KoreanAudioOptimizer:
    """
    í•œêµ­ì–´ STT ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ì „ë¬¸ ì˜¤ë””ì˜¤ ìµœì í™”ê¸°
    
    í•µì‹¬ ê¸°ëŠ¥:
    1. í•œêµ­ì–´ ììŒ ëª…ë£Œë„ ê°•í™” (ã„±,ã„·,ã…‚,ã……,ã…ˆ,ã…Š,ã…‹,ã…Œ,ã…,ã…)
    2. í•œêµ­ì–´ ëª¨ìŒ ì•ˆì •í™” (ã…,ã…“,ã…—,ã…œ,ã…¡,ã…£)
    3. ìš´ìœ¨ íŒ¨í„´ ì •ê·œí™” (í•œêµ­ì–´ ì–µì–‘ íŠ¹ì„±)
    4. ì§€ëŠ¥í˜• ë¬´ìŒ ì²˜ë¦¬ (í•œêµ­ì–´ ë¦¬ë“¬ ë³´ì¡´)
    5. SNR ìµœì í™” (í•œêµ­ì–´ ìŒì†Œë³„)
    """
    
    def __init__(self, 
                 target_sr: int = 16000,
                 target_db: float = -16.0,  # STT ìµœì í™”ëœ ë³¼ë¥¨
                 korean_boost: bool = True):
        """
        Parameters:
        -----------
        target_sr : int
            ëª©í‘œ ìƒ˜í”Œë ˆì´íŠ¸ (Whisper ìµœì í™”)
        target_db : float  
            ëª©í‘œ dB (-16dBëŠ” STT ìµœì ê°’)
        korean_boost : bool
            í•œêµ­ì–´ íŠ¹í™” ê°•í™” ì‚¬ìš© ì—¬ë¶€
        """
        self.target_sr = target_sr
        self.target_db = target_db
        self.korean_boost = korean_boost
        
        # í•œêµ­ì–´ ìŒì†Œë³„ ì£¼íŒŒìˆ˜ íŠ¹ì„± ì •ì˜
        self.korean_phoneme_profiles = self._init_korean_phoneme_profiles()
        
        # STT ìµœì í™” í•„í„° ê³„ìˆ˜
        self.stt_filter_coeffs = self._init_stt_filters()
        
        logger.info(f"ğŸ¯ í•œêµ­ì–´ ì˜¤ë””ì˜¤ ìµœì í™”ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ëª©í‘œ ìƒ˜í”Œë ˆì´íŠ¸: {target_sr}Hz")
        logger.info(f"   ëª©í‘œ ë³¼ë¥¨: {target_db}dB")
        logger.info(f"   í•œêµ­ì–´ íŠ¹í™”: {'í™œì„±í™”' if korean_boost else 'ë¹„í™œì„±í™”'}")
    
    def _init_korean_phoneme_profiles(self) -> Dict:
        """í•œêµ­ì–´ ìŒì†Œë³„ ì£¼íŒŒìˆ˜ í”„ë¡œíŒŒì¼ ì •ì˜"""
        return {
            # í•œêµ­ì–´ ììŒ íŠ¹ì„± (ëª…ë£Œë„ ì¤‘ìš”)
            'consonants': {
                'stops': {  # ã„±,ã„·,ã…‚,ã…‹,ã…Œ,ã…
                    'freq_ranges': [(500, 1500), (1500, 4000)],  # F2, F3 ì˜ì—­
                    'boost_db': [3, 4],  # ê° ì˜ì—­ë³„ ë¶€ìŠ¤íŠ¸
                    'clarity_freq': 2500  # ëª…ë£Œë„ í•µì‹¬ ì£¼íŒŒìˆ˜
                },
                'fricatives': {  # ã……,ã…†,ã…ˆ,ã…Š,ã…
                    'freq_ranges': [(3000, 8000)],  # ê³ ì£¼íŒŒ ë§ˆì°°ìŒ
                    'boost_db': [5],
                    'clarity_freq': 5000
                },
                'nasals': {  # ã…,ã„´,ã…‡
                    'freq_ranges': [(200, 800)],  # ì €ì£¼íŒŒ ê³µëª…
                    'boost_db': [2],
                    'clarity_freq': 500
                },
                'liquids': {  # ã„¹
                    'freq_ranges': [(800, 2000)],  # ì¤‘ê°„ ì£¼íŒŒìˆ˜
                    'boost_db': [3],
                    'clarity_freq': 1200
                }
            },
            
            # í•œêµ­ì–´ ëª¨ìŒ íŠ¹ì„± (ì•ˆì •ì„± ì¤‘ìš”)
            'vowels': {
                'front': {  # ã…£,ã…”,ã…
                    'f1_range': (200, 500),   # ì œ1í¬ë¨¼íŠ¸
                    'f2_range': (1800, 2500), # ì œ2í¬ë¨¼íŠ¸
                    'stabilization_factor': 0.8
                },
                'back': {  # ã…œ,ã…—
                    'f1_range': (200, 600),
                    'f2_range': (800, 1200),
                    'stabilization_factor': 0.9
                },
                'central': {  # ã…“,ã…,ã…¡
                    'f1_range': (400, 800),
                    'f2_range': (1200, 1800),
                    'stabilization_factor': 0.85
                }
            }
        }
    
    def _init_stt_filters(self) -> Dict:
        """STT ì—”ì§„ë³„ ìµœì í™” í•„í„° ê³„ìˆ˜"""
        return {
            'whisper': {
                'preemphasis': 0.97,      # ê³ ì£¼íŒŒ ê°•ì¡°
                'spectral_gate_db': -30,  # ìŠ¤í™íŠ¸ëŸ´ ê²Œì´íŠ¸
                'dynamic_range_db': 40,   # ë‹¤ì´ë‚˜ë¯¹ ë ˆì¸ì§€
            },
            'google': {
                'preemphasis': 0.95,
                'spectral_gate_db': -25,
                'dynamic_range_db': 45,
            }
        }
    
    def optimize_for_korean_stt(self, 
                               audio_file: str, 
                               output_file: str = None,
                               stt_engine: str = 'whisper') -> str:
        """
        í•œêµ­ì–´ STT ìµœì í™” ë©”ì¸ í•¨ìˆ˜
        
        Parameters:
        -----------
        audio_file : str
            ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼
        output_file : str, optional
            ì¶œë ¥ íŒŒì¼ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
        stt_engine : str
            ëª©í‘œ STT ì—”ì§„ ('whisper', 'google', 'azure')
            
        Returns:
        --------
        str : ìµœì í™”ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        try:
            print(f"ğŸ¯ í•œêµ­ì–´ STT ìµœì í™” ì‹œì‘: {Path(audio_file).name}")
            print(f"   ëª©í‘œ ì—”ì§„: {stt_engine}")
            
            # ì¶œë ¥ íŒŒì¼ëª… ê²°ì •
            if not output_file:
                input_path = Path(audio_file)
                output_file = str(input_path.parent / f"{input_path.stem}_korean_optimized{input_path.suffix}")
            
            # 1ë‹¨ê³„: ì˜¤ë””ì˜¤ ë¡œë“œ ë° ê¸°ë³¸ ì •ê·œí™”
            audio, sr = self._load_and_normalize(audio_file)
            print(f"ğŸ“Š ì›ë³¸: {len(audio)/sr:.2f}ì´ˆ, {sr}Hz")
            
            # 2ë‹¨ê³„: í•œêµ­ì–´ íŠ¹í™” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
            if self.korean_boost:
                # 2-1. í•œêµ­ì–´ ììŒ ëª…ë£Œë„ ê°•í™”
                audio = self._enhance_korean_consonants(audio, sr)
                print("âœ… í•œêµ­ì–´ ììŒ ëª…ë£Œë„ ê°•í™” ì™„ë£Œ")
                
                # 2-2. í•œêµ­ì–´ ëª¨ìŒ ì•ˆì •í™”
                audio = self._stabilize_korean_vowels(audio, sr)
                print("âœ… í•œêµ­ì–´ ëª¨ìŒ ì•ˆì •í™” ì™„ë£Œ")
                
                # 2-3. ìš´ìœ¨ íŒ¨í„´ ì •ê·œí™”
                audio = self._normalize_korean_prosody(audio, sr)
                print("âœ… í•œêµ­ì–´ ìš´ìœ¨ ì •ê·œí™” ì™„ë£Œ")
            
            # 3ë‹¨ê³„: STT ì—”ì§„ë³„ ìµœì í™”
            audio = self._apply_stt_optimization(audio, sr, stt_engine)
            print(f"âœ… {stt_engine} ì—”ì§„ ìµœì í™” ì™„ë£Œ")
            
            # 4ë‹¨ê³„: ì§€ëŠ¥í˜• ë¬´ìŒ ì²˜ë¦¬
            audio = self._intelligent_silence_processing(audio, sr)
            print("âœ… ì§€ëŠ¥í˜• ë¬´ìŒ ì²˜ë¦¬ ì™„ë£Œ")
            
            # 5ë‹¨ê³„: ìµœì¢… í’ˆì§ˆ ê²€ì¦ ë° ì €ì¥
            final_audio = self._final_quality_control(audio, sr)
            sf.write(output_file, final_audio, self.target_sr)
            
            # ê²°ê³¼ ë¶„ì„
            quality_metrics = self._analyze_optimization_quality(audio_file, output_file)
            self._print_optimization_report(quality_metrics)
            
            print(f"ğŸ¯ ìµœì í™” ì™„ë£Œ: {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"í•œêµ­ì–´ ì˜¤ë””ì˜¤ ìµœì í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _load_and_normalize(self, audio_file: str) -> Tuple[np.ndarray, int]:
        """ì˜¤ë””ì˜¤ ë¡œë“œ ë° ê¸°ë³¸ ì •ê·œí™”"""
        # librosaë¡œ ë¡œë“œ (ìë™ ì •ê·œí™”)
        audio, sr = librosa.load(audio_file, sr=None)
        
        # ìƒ˜í”Œë ˆì´íŠ¸ ì¡°ì •
        if sr != self.target_sr:
            audio = librosa.resample(audio, orig_sr=sr, target_sr=self.target_sr)
            sr = self.target_sr
        
        # ê¸°ë³¸ ë³¼ë¥¨ ì •ê·œí™”
        audio = librosa.util.normalize(audio) * 0.8  # í´ë¦¬í•‘ ë°©ì§€
        
        return audio, sr
    
    def _enhance_korean_consonants(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """í•œêµ­ì–´ ììŒ ëª…ë£Œë„ ê°•í™”"""
        consonant_profile = self.korean_phoneme_profiles['consonants']
        
        # STFT ë³€í™˜
        stft = librosa.stft(audio, hop_length=512, win_length=2048)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # ì£¼íŒŒìˆ˜ ë¹ˆ ê³„ì‚°
        freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)
        
        # ììŒë³„ ì£¼íŒŒìˆ˜ ê°•í™”
        enhanced_magnitude = magnitude.copy()
        
        # íì‡„ìŒ ê°•í™” (ã„±,ã„·,ã…‚,ã…‹,ã…Œ,ã…)
        for freq_range, boost_db in zip(consonant_profile['stops']['freq_ranges'], 
                                       consonant_profile['stops']['boost_db']):
            freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])
            boost_factor = 10 ** (boost_db / 20)  # dB to linear
            enhanced_magnitude[freq_mask] *= boost_factor
        
        # ë§ˆì°°ìŒ ê°•í™” (ã……,ã…†,ã…ˆ,ã…Š,ã…)
        for freq_range, boost_db in zip(consonant_profile['fricatives']['freq_ranges'],
                                       consonant_profile['fricatives']['boost_db']):
            freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])
            boost_factor = 10 ** (boost_db / 20)
            enhanced_magnitude[freq_mask] *= boost_factor
        
        # ISTFT ì—­ë³€í™˜
        enhanced_stft = enhanced_magnitude * np.exp(1j * phase)
        enhanced_audio = librosa.istft(enhanced_stft, hop_length=512, win_length=2048)
        
        return enhanced_audio
    
    def _stabilize_korean_vowels(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """í•œêµ­ì–´ ëª¨ìŒ ì•ˆì •í™” (í¬ë¨¼íŠ¸ ì•ˆì •í™”)"""
        # Parselmouthë¥¼ ì‚¬ìš©í•œ í¬ë¨¼íŠ¸ ë¶„ì„
        try:
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                sf.write(tmp.name, audio, sr)
                
                # Praatìœ¼ë¡œ í¬ë¨¼íŠ¸ ë¶„ì„
                sound = pm.Sound(tmp.name)
                formants = sound.to_formant_burg(maximum_formant=5500)
                
                # í¬ë¨¼íŠ¸ ì•ˆì •í™” (ìŠ¤ë¬´ë”©)
                stabilized_audio = self._apply_formant_stabilization(audio, sr, formants)
                
                os.unlink(tmp.name)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                return stabilized_audio
                
        except Exception as e:
            logger.warning(f"í¬ë¨¼íŠ¸ ì•ˆì •í™” ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
            return audio
    
    def _apply_formant_stabilization(self, audio: np.ndarray, sr: int, formants) -> np.ndarray:
        """í¬ë¨¼íŠ¸ ê¸°ë°˜ ëª¨ìŒ ì•ˆì •í™”"""
        # ê°„ë‹¨í•œ ìŠ¤í™íŠ¸ëŸ´ ìŠ¤ë¬´ë”©ìœ¼ë¡œ êµ¬í˜„
        stft = librosa.stft(audio, hop_length=512)
        magnitude = np.abs(stft)
        
        # ì‹œê°„ì¶• ìŠ¤ë¬´ë”© (í¬ë¨¼íŠ¸ ë³€í™” ì•ˆì •í™”)
        from scipy.ndimage import uniform_filter1d
        stabilized_magnitude = uniform_filter1d(magnitude, size=3, axis=1)
        
        # ì¬êµ¬ì„±
        phase = np.angle(stft)
        stabilized_stft = stabilized_magnitude * np.exp(1j * phase)
        stabilized_audio = librosa.istft(stabilized_stft, hop_length=512)
        
        return stabilized_audio
    
    def _normalize_korean_prosody(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """í•œêµ­ì–´ ìš´ìœ¨ íŒ¨í„´ ì •ê·œí™”"""
        # í”¼ì¹˜ ì¶”ì  ë° ì •ê·œí™”
        try:
            f0, voiced_flag, voiced_probs = librosa.pyin(
                audio, fmin=80, fmax=400, sr=sr, frame_length=2048
            )
            
            # í”¼ì¹˜ ìŠ¤ë¬´ë”© (í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘)
            f0_smoothed = self._smooth_pitch_contour(f0, voiced_flag)
            
            # ì–µì–‘ ì •ê·œí™”ëœ ì˜¤ë””ì˜¤ ìƒì„± (PSOLA ê¸°ë°˜ ë‹¨ìˆœí™”)
            normalized_audio = self._apply_prosody_normalization(audio, sr, f0_smoothed)
            
            return normalized_audio
            
        except Exception as e:
            logger.warning(f"ìš´ìœ¨ ì •ê·œí™” ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
            return audio
    
    def _smooth_pitch_contour(self, f0: np.ndarray, voiced_flag: np.ndarray) -> np.ndarray:
        """í”¼ì¹˜ ìœ¤ê³½ ìŠ¤ë¬´ë”©"""
        # NaN ê°’ ì²˜ë¦¬
        f0_clean = f0.copy()
        f0_clean[~voiced_flag] = np.nan
        
        # ì„ í˜• ë³´ê°„ìœ¼ë¡œ ë¹ˆ êµ¬ê°„ ì±„ìš°ê¸°
        mask = ~np.isnan(f0_clean)
        if np.sum(mask) > 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ ìœ íš¨í•œ ê°’ì´ ìˆì–´ì•¼ ë³´ê°„ ê°€ëŠ¥
            indices = np.arange(len(f0_clean))
            f0_interpolated = np.interp(indices, indices[mask], f0_clean[mask])
            
            # ê°€ìš°ì‹œì•ˆ ìŠ¤ë¬´ë”©
            from scipy.ndimage import gaussian_filter1d
            f0_smoothed = gaussian_filter1d(f0_interpolated, sigma=2.0)
            
            return f0_smoothed
        else:
            return f0_clean
    
    def _apply_prosody_normalization(self, audio: np.ndarray, sr: int, f0: np.ndarray) -> np.ndarray:
        """ìš´ìœ¨ ì •ê·œí™” ì ìš© (ë‹¨ìˆœí™”ëœ êµ¬í˜„)"""
        # í˜„ì¬ëŠ” ë‹¤ì´ë‚˜ë¯¹ ë ˆì¸ì§€ ì••ì¶•ìœ¼ë¡œ ëŒ€ì²´
        # ì‹¤ì œë¡œëŠ” PSOLAë‚˜ WORLD vocoder ì‚¬ìš©ì´ ì´ìƒì 
        
        # ë‹¤ì´ë‚˜ë¯¹ ë ˆì¸ì§€ ì••ì¶• (í•œêµ­ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨ ë³€í™”)
        from scipy.signal import hilbert
        
        # í¬ë½ì„  ì¶”ì¶œ
        analytic_signal = hilbert(audio)
        envelope = np.abs(analytic_signal)
        
        # ë¶€ë“œëŸ¬ìš´ ì••ì¶• ì ìš©
        compressed_envelope = np.tanh(envelope * 2.0) / 2.0
        
        # ì••ì¶•ëœ í¬ë½ì„  ì ìš©
        normalized_audio = audio * (compressed_envelope / (envelope + 1e-8))
        
        return normalized_audio
    
    def _apply_stt_optimization(self, audio: np.ndarray, sr: int, engine: str) -> np.ndarray:
        """STT ì—”ì§„ë³„ ìµœì í™”"""
        filter_config = self.stt_filter_coeffs.get(engine, self.stt_filter_coeffs['whisper'])
        
        # Pre-emphasis í•„í„° (ê³ ì£¼íŒŒ ê°•ì¡°)
        preemph = filter_config['preemphasis']
        audio_preemph = np.append(audio[0], audio[1:] - preemph * audio[:-1])
        
        # ìŠ¤í™íŠ¸ëŸ´ ê²Œì´íŠ¸ (ë…¸ì´ì¦ˆ ì–µì œ)
        stft = librosa.stft(audio_preemph, hop_length=512)
        magnitude = np.abs(stft)
        
        # ë™ì  ìŠ¤í™íŠ¸ëŸ´ ê²Œì´íŠ¸
        gate_threshold = np.percentile(magnitude, 10)  # í•˜ìœ„ 10% ì œê±°
        gate_mask = magnitude > gate_threshold
        gated_magnitude = magnitude * gate_mask
        
        # ì¬êµ¬ì„±
        phase = np.angle(stft)
        gated_stft = gated_magnitude * np.exp(1j * phase)
        optimized_audio = librosa.istft(gated_stft, hop_length=512)
        
        return optimized_audio
    
    def _intelligent_silence_processing(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """ì§€ëŠ¥í˜• ë¬´ìŒ ì²˜ë¦¬ (í•œêµ­ì–´ ë¦¬ë“¬ ë³´ì¡´)"""
        # ìŒì„± í™œë™ ê²€ì¶œ
        intervals = librosa.effects.split(audio, top_db=20, frame_length=2048, hop_length=512)
        
        if len(intervals) == 0:
            return audio
        
        # ìŒì„± êµ¬ê°„ë§Œ ì¶”ì¶œí•˜ë˜ ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆì§„ ìœ ì§€
        start_margin = int(0.1 * sr)  # 0.1ì´ˆ ë§ˆì§„
        end_margin = int(0.1 * sr)
        
        start_sample = max(0, intervals[0][0] - start_margin)
        end_sample = min(len(audio), intervals[-1][1] + end_margin)
        
        trimmed_audio = audio[start_sample:end_sample]
        
        return trimmed_audio
    
    def _final_quality_control(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """ìµœì¢… í’ˆì§ˆ ì œì–´"""
        # 1. ë³¼ë¥¨ ìµœì í™” (ëª©í‘œ dBë¡œ)
        rms = np.sqrt(np.mean(audio**2))
        current_db = 20 * np.log10(rms + 1e-8)
        
        if current_db != self.target_db:
            gain_db = self.target_db - current_db
            gain_linear = 10 ** (gain_db / 20)
            audio = audio * gain_linear
        
        # 2. í´ë¦¬í•‘ ë°©ì§€
        audio = np.clip(audio, -0.95, 0.95)
        
        # 3. DC ì„±ë¶„ ì œê±°
        audio = audio - np.mean(audio)
        
        return audio
    
    def _analyze_optimization_quality(self, original_file: str, optimized_file: str) -> Dict:
        """ìµœì í™” í’ˆì§ˆ ë¶„ì„"""
        try:
            # ì›ë³¸ê³¼ ìµœì í™” íŒŒì¼ ë¡œë“œ
            orig_audio, orig_sr = librosa.load(original_file, sr=self.target_sr)
            opt_audio, opt_sr = librosa.load(optimized_file, sr=self.target_sr)
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = {
                'duration_change': len(opt_audio) / len(orig_audio),
                'rms_change': np.sqrt(np.mean(opt_audio**2)) / np.sqrt(np.mean(orig_audio**2)),
                'spectral_centroid_change': np.mean(librosa.feature.spectral_centroid(y=opt_audio, sr=opt_sr)) / 
                                          np.mean(librosa.feature.spectral_centroid(y=orig_audio, sr=orig_sr)),
                'snr_improvement': self._estimate_snr_improvement(orig_audio, opt_audio)
            }
            
            return metrics
            
        except Exception as e:
            logger.warning(f"í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _estimate_snr_improvement(self, original: np.ndarray, optimized: np.ndarray) -> float:
        """SNR ê°œì„ ë„ ì¶”ì •"""
        try:
            # ì‹ í˜¸ ì—ë„ˆì§€ (ìƒìœ„ 80% ì—ë„ˆì§€)
            orig_energy = np.percentile(original**2, 80)
            opt_energy = np.percentile(optimized**2, 80)
            
            # ë…¸ì´ì¦ˆ ì—ë„ˆì§€ (í•˜ìœ„ 20% ì—ë„ˆì§€)
            orig_noise = np.percentile(original**2, 20)
            opt_noise = np.percentile(optimized**2, 20)
            
            # SNR ê³„ì‚°
            orig_snr = 10 * np.log10(orig_energy / (orig_noise + 1e-8))
            opt_snr = 10 * np.log10(opt_energy / (opt_noise + 1e-8))
            
            return opt_snr - orig_snr
            
        except:
            return 0.0
    
    def _print_optimization_report(self, metrics: Dict):
        """ìµœì í™” ë³´ê³ ì„œ ì¶œë ¥"""
        if not metrics:
            return
            
        print("\nğŸ“Š í•œêµ­ì–´ ìµœì í™” í’ˆì§ˆ ë³´ê³ ì„œ:")
        print(f"   ì§€ì†ì‹œê°„ ë³€í™”: {metrics.get('duration_change', 1.0):.3f}x")
        print(f"   ë³¼ë¥¨ ë³€í™”: {metrics.get('rms_change', 1.0):.3f}x")
        print(f"   ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ ë³€í™”: {metrics.get('spectral_centroid_change', 1.0):.3f}x")
        print(f"   SNR ê°œì„ : {metrics.get('snr_improvement', 0.0):.1f}dB")
        print("âœ… í•œêµ­ì–´ STT ìµœì í™” ì™„ë£Œ\n")

def quick_optimize_for_korean(audio_file: str, output_file: str = None) -> str:
    """
    ë¹ ë¥¸ í•œêµ­ì–´ ìµœì í™” (í¸ì˜ í•¨ìˆ˜)
    
    Parameters:
    -----------
    audio_file : str
        ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼
    output_file : str, optional
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
    --------
    str : ìµœì í™”ëœ íŒŒì¼ ê²½ë¡œ
    """
    optimizer = KoreanAudioOptimizer()
    return optimizer.optimize_for_korean_stt(audio_file, output_file)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš©
    import sys
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
        output_file = quick_optimize_for_korean(input_file)
        print(f"ìµœì í™” ì™„ë£Œ: {output_file}")