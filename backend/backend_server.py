"""
ToneBridge FastAPI backend - PRAAT ALGORITHM IMPLEMENTATION
Implements authentic Praat pitch extraction with real-time analysis
"""
import io
import os
import sys
import tempfile
import subprocess
import shutil
import uuid
from pathlib import Path
from typing import List, Optional

import numpy as np
from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from models import ReferenceFile, Base

try:
    import parselmouth as pm
    print("ğŸ¯ Parselmouth (Praat Python) imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import parselmouth: {e}")
    sys.exit(1)

app = FastAPI(title="ToneBridge Praat Analysis API")

# ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜: ë°±ì—”ë“œëŠ” ìˆœìˆ˜ APIë§Œ ì œê³µ
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# Database setup
DATABASE_URL = os.environ.get("DATABASE_URL", "sqlite:///tonebridge.db")
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create tables
Base.metadata.create_all(bind=engine)

# File upload directory
UPLOAD_DIR = Path("static/uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Static files and templates (remove duplicate)
# Duplicate mount removed - already defined above

# Pydantic models
class RefPoint(BaseModel):
    t: float
    f0: float
    dB: float
    semitone: float

class Syllable(BaseModel):
    label: str
    start: float
    end: float

class SyllableAnalysis(BaseModel):
    label: str  # 'syllable' â†’ 'label'
    start: float
    end: float
    duration: float  # str â†’ float
    f0: float  # 'pitch_mean' â†’ 'f0'
    semitone: float
    qtone: float
    intensity: float  # str â†’ float

class RefAnalysis(BaseModel):
    curve: List[RefPoint]
    syllables: List[Syllable]
    syllable_analysis: List[SyllableAnalysis]
    stats: dict

def split_korean_sentence(sentence: str) -> List[str]:
    """Split Korean sentence into individual syllables"""
    return [char for char in sentence.strip() if char.strip()]

def praat_script_textgrid_parser(tg: pm.TextGrid) -> List[dict]:
    """
    Praat Call ê¸°ë°˜ TextGrid parser - í‘œì¤€ Parselmouth ë°©ì‹
    """
    print("ğŸ¯ğŸ¯ğŸ¯ PRAAT CALL TEXTGRID PARSER ì‹œì‘ ğŸ¯ğŸ¯ğŸ¯")
    
    if not tg:
        print("âŒ TextGrid object is None")
        return []
    
    try:
        from parselmouth.praat import call
        
        # Praat callë¡œ tier ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        n_tiers = call(tg, "Get number of tiers")
        print(f"ğŸ¯ Found {n_tiers} tiers via Praat call")
        
        # ëª¨ë“  tierì—ì„œ interval ìˆ˜ì§‘
        table_rows = []
        
        for tier_num in range(1, n_tiers + 1):  # Praatì€ 1-based indexing
            try:
                tier_name = call(tg, "Get tier name", tier_num)
                is_interval_tier = call(tg, "Is interval tier", tier_num)
                
                print(f"ğŸ¯ Tier {tier_num}: '{tier_name}' (interval={is_interval_tier})")
                
                if is_interval_tier:
                    n_intervals = call(tg, "Get number of intervals", tier_num)
                    print(f"    ğŸ¯ Found {n_intervals} intervals")
                    
                    for interval_num in range(1, n_intervals + 1):  # 1-based
                        start_time = call(tg, "Get starting point", tier_num, interval_num)
                        end_time = call(tg, "Get end point", tier_num, interval_num)
                        label = call(tg, "Get label of interval", tier_num, interval_num).strip()
                        
                        if label:  # ë¹ˆ ë¼ë²¨ ì œì™¸
                            table_rows.append({
                                "tier": tier_name.lower(),
                                "tier_idx": tier_num - 1,  # 0-basedë¡œ ë³€í™˜
                                "text": label,
                                "tmin": float(start_time),
                                "tmax": float(end_time),
                                "duration": float(end_time - start_time)
                            })
                            print(f"      ğŸ¯ Interval {interval_num}: '{label}' ({start_time:.3f}s-{end_time:.3f}s)")
                
            except Exception as e:
                print(f"âŒ Error processing tier {tier_num}: {e}")
                continue
        
        print(f"ğŸ¯ Table created with {len(table_rows)} rows")
        
        # ìŒì ˆ tier ì°¾ê¸° (ìˆ«ì tierë„ í¬í•¨)
        target_tier_names = ["syllable", "syllables", "ìŒì ˆ", "syl", "word", "words", "phones", "phone", "1", "2", "3", "intervals", "segment", "segments", "tier", "tier1", "tier2", "tier3"]
        extracted_rows = []
        
        for tier_name in target_tier_names:
            matches = [row for row in table_rows 
                      if row["tier"] == tier_name and row["text"] and row["duration"] > 0.001]
            if matches:
                extracted_rows = matches
                print(f"ğŸ¯âœ… Found {len(matches)} syllables in tier '{tier_name}'")
                break
        
        # íŠ¹ì • tierë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ê°€ì¥ ë§ì€ intervalì„ ê°€ì§„ tier ì‚¬ìš©
        if not extracted_rows and table_rows:
            tier_counts = {}
            for row in table_rows:
                if row["text"] and row["duration"] > 0.001:
                    tier_name = row["tier"]
                    tier_counts[tier_name] = tier_counts.get(tier_name, 0) + 1
            
            if tier_counts:
                best_tier = max(tier_counts.keys(), key=lambda k: tier_counts[k])
                extracted_rows = [row for row in table_rows 
                                if row["tier"] == best_tier and row["text"] and row["duration"] > 0.001]
                print(f"ğŸ¯âœ… Using tier with most intervals: '{best_tier}' ({len(extracted_rows)} syllables)")
        
        # ğŸš¨ CRITICAL FIX: ì—¬ì „íˆ ìŒì ˆì´ ì—†ìœ¼ë©´ ëª¨ë“  tierì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ê°•ì œë¡œ ì‚¬ìš©
        if not extracted_rows and table_rows:
            print("ğŸ¯ğŸš¨ FALLBACK: ëª¨ë“  tier ë°ì´í„°ë¥¼ ìŒì ˆë¡œ ê°•ì œ ì‚¬ìš©")
            extracted_rows = [row for row in table_rows if row["text"] and row["duration"] > 0.001]
            extracted_rows.sort(key=lambda x: x["tmin"])  # ì‹œê°„ìˆœ ì •ë ¬
            print(f"ğŸ¯âœ… Forced extraction: {len(extracted_rows)} syllables from all tiers")
        
        # ìŒì ˆì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not extracted_rows:
            print("ğŸ¯âŒ COMPLETE FAILURE: No syllable data found at all")
            return []
        
        # ì‹œê°„ìˆœ ì •ë ¬
        extracted_rows.sort(key=lambda x: x["tmin"])
        
        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        syllables = []
        for row in extracted_rows:
            syllables.append({
                "label": row["text"],
                "start": row["tmin"],
                "end": row["tmax"]
            })
        
        print(f"ğŸ¯âœ… Successfully parsed {len(syllables)} syllables from TextGrid")
        for syl in syllables:
            print(f"    - '{syl['label']}': {syl['start']:.3f}s-{syl['end']:.3f}s")
        
        return syllables
        
    except Exception as e:
        print(f"âŒ Praat call parsing failed: {e}")
        return []

def apply_gender_normalization(analysis_result: dict, target_gender: str, learner_gender: str) -> dict:
    """
    í•™ìŠµì ì„±ë³„ì— ë”°ë¼ ì°¸ì¡° ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # ì„±ë³„ë³„ í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ (Hz) - ì—°êµ¬ ê¸°ë°˜ ë°ì´í„°
        gender_f0_base = {
            "male": 120.0,    # ë‚¨ì„± í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜
            "female": 220.0   # ì—¬ì„± í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜
        }
        
        if target_gender == "auto":
            target_gender = "female"  # autoì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            print(f"ğŸ¯ ì°¸ì¡° ì„±ë³„ì„ ìë™ìœ¼ë¡œ femaleë¡œ ì„¤ì •")
            
        if target_gender not in gender_f0_base or learner_gender not in gender_f0_base:
            print(f"ğŸ¯ ì •ê·œí™” ìƒëµ: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„±ë³„ ({target_gender} -> {learner_gender})")
            return analysis_result
        
        # ì •ê·œí™” ë¹„ìœ¨ ê³„ì‚°
        source_base = gender_f0_base[target_gender]  # ì°¸ì¡° ìŒì„±ì˜ ì„±ë³„ ê¸°ì¤€
        target_base = gender_f0_base[learner_gender]  # í•™ìŠµì ì„±ë³„ ê¸°ì¤€
        normalization_ratio = target_base / source_base
        
        print(f"ğŸ¯ ì •ê·œí™” ë¹„ìœ¨: {source_base}Hz({target_gender}) -> {target_base}Hz({learner_gender}) = {normalization_ratio:.3f}")
        print(f"ğŸ¯ Semitone ê¸°ì¤€ ì£¼íŒŒìˆ˜: {target_base}Hz (í•™ìŠµì: {learner_gender})")
        print(f"ğŸ¯ ì»¨íˆ¬ì–´ ì¼ì¹˜ì„±: ëŒ€í‘œ í”¼ì¹˜ê°€ ì‹¤ì œ ê³¡ì„ ì—ì„œ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ë³´ì • ì ìš©")
        
        # ê³¡ì„  ë°ì´í„° ì •ê·œí™” (dict í˜•íƒœ ì²˜ë¦¬)
        normalized_curve = []
        for point in analysis_result.get('curve', []):
            if isinstance(point, dict):
                # dict í˜•íƒœì˜ í¬ì¸íŠ¸ (t, f0, dB, semitone)
                normalized_point = point.copy()
                if 'f0' in normalized_point:
                    normalized_f0 = normalized_point['f0'] * normalization_ratio
                    normalized_point['f0'] = normalized_f0
                    # semitone ì¬ê³„ì‚° (ì •ê·œí™”ëœ f0 ê¸°ì¤€)
                    if normalized_f0 > 0 and target_base > 0:
                        semitone_val = 12 * np.log2(normalized_f0 / target_base)
                        normalized_point['semitone'] = semitone_val
                        # ì²« ë²ˆì§¸ í¬ì¸íŠ¸ë§Œ ë””ë²„ê¹… ì¶œë ¥
                        if len(normalized_curve) == 0:
                            print(f"ğŸ¯ ì²« í¬ì¸íŠ¸ semitone ê³„ì‚°: f0={normalized_f0:.1f}Hz, base={target_base}Hz â†’ {semitone_val:.2f}st")
                    else:
                        normalized_point['semitone'] = 0.0
                normalized_curve.append(normalized_point)
            elif len(point) >= 2:
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ í¬ì¸íŠ¸ [time, freq]
                time_val = point[0]
                freq_val = point[1] * normalization_ratio
                normalized_curve.append([time_val, freq_val])
            else:
                normalized_curve.append(point)
        
        # ìŒì ˆ ë°ì´í„° ì •ê·œí™”
        normalized_syllables = []
        for syl in analysis_result.get('syllables', []):
            normalized_syl = syl.copy()
            
            # ğŸ¯ ëª¨ë“  í•™ìŠµìì—ê²Œ ì •ê·œí™”ëœ ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ í‘œì‹œ
            if True:  # ë‚¨ì„±/ì—¬ì„± ëª¨ë‘ ì •ê·œí™”ëœ ë°ì´í„° í‘œì‹œ
                # ğŸ¯ ëª¨ë“  ì„±ë³„ì—ê²Œ f0 ê´€ë ¨ í•„ë“œ ì •ê·œí™”
                f0_fields = ['f0', 'median_f0', 'representative_f0', 'center_f0']
                for field in f0_fields:
                    if field in normalized_syl and normalized_syl[field] is not None:
                        original_f0 = normalized_syl[field]
                        normalized_f0 = original_f0 * normalization_ratio
                        normalized_syl[field] = normalized_f0
                        
                        # ëŒ€í‘œ f0 í•„ë“œì˜ ê²½ìš° semitoneë„ ì—…ë°ì´íŠ¸
                        if field == 'f0' and normalized_f0 > 0 and target_base > 0:
                            normalized_semitone = 12 * np.log2(normalized_f0 / target_base)
                            normalized_syl['semitone'] = normalized_semitone
                            # ğŸ¯ ì˜¬ë°”ë¥¸ Q-tone ê³µì‹: 5 * log2(f0/130)
                            normalized_syl['qtone'] = 5 * np.log2(normalized_f0 / 130) if normalized_f0 > 0 else 0.0
                            normalized_syl['semitone_median'] = normalized_semitone  # í˜¸í™˜ì„±
                            
                            print(f"ğŸ¯ ìŒì ˆ '{normalized_syl.get('label', '?')}': {original_f0:.1f}Hz â†’ {normalized_f0:.1f}Hz ({normalized_semitone:.2f}st)")
                            
                            # ğŸ¯ CRITICAL DEBUG: ì •ê·œí™”ëœ syllable_analysisì—ë„ ë°˜ì˜í•´ì•¼í•¨!
                            if 'syllable_analysis' in analysis_result:
                                for syl_analysis in analysis_result['syllable_analysis']:
                                    if syl_analysis.get('label') == normalized_syl.get('label'):
                                        syl_analysis['f0'] = normalized_f0
                                        syl_analysis['semitone'] = normalized_semitone
                                        syl_analysis['semitone_median'] = normalized_semitone
                                        # ğŸ¯ ì˜¬ë°”ë¥¸ Q-tone ê³µì‹: 5 * log2(f0/130)  
                                        syl_analysis['qtone'] = 5 * np.log2(normalized_f0 / 130) if normalized_f0 > 0 else 0.0
                                        print(f"ğŸ¯ syllable_analysis ì—…ë°ì´íŠ¸: {syl_analysis['label']} = {normalized_semitone:.2f}st")
                normalized_syl['show_syllable_pitch'] = True
                    
            # ë¹ˆ f0 í•„ë“œ ì²˜ë¦¬
            if 'f0' not in normalized_syl or normalized_syl['f0'] is None or normalized_syl['f0'] <= 0:
                normalized_syl['semitone'] = 0.0
                normalized_syl['qtone'] = 0.0
                normalized_syl['semitone_median'] = 0.0
                
            normalized_syllables.append(normalized_syl)
        
        # í†µê³„ ë°ì´í„° ì •ê·œí™”
        normalized_stats = analysis_result.get('stats', {}).copy()
        if 'mean_f0' in normalized_stats:
            normalized_stats['mean_f0'] = normalized_stats['mean_f0'] * normalization_ratio
        if 'median_f0' in normalized_stats:
            normalized_stats['median_f0'] = normalized_stats['median_f0'] * normalization_ratio
        if 'max_f0' in normalized_stats:
            normalized_stats['max_f0'] = normalized_stats['max_f0'] * normalization_ratio
        if 'min_f0' in normalized_stats:
            normalized_stats['min_f0'] = normalized_stats['min_f0'] * normalization_ratio
        
        # ì •ê·œí™”ëœ ê²°ê³¼ ë°˜í™˜
        normalized_result = analysis_result.copy()
        normalized_result['curve'] = normalized_curve
        normalized_result['syllables'] = normalized_syllables
        normalized_result['stats'] = normalized_stats
        
        print(f"ğŸ¯ ì •ê·œí™” ì™„ë£Œ: {len(normalized_curve)}ê°œ í¬ì¸íŠ¸, {len(normalized_syllables)}ê°œ ìŒì ˆ")
        return normalized_result
        
    except Exception as e:
        print(f"ğŸš¨ ì •ê·œí™” ì˜¤ë¥˜: {e}")
        return analysis_result

def detect_reference_gender(analysis_result: dict) -> str:
    """
    ì°¸ì¡° ìŒì„±ì˜ ì„±ë³„ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ë³„ì„ ì¶”ì •
    """
    try:
        # ê³¡ì„  ë°ì´í„°ì—ì„œ í‰ê·  ì£¼íŒŒìˆ˜ ê³„ì‚°
        curve_data = analysis_result.get('curve', [])
        if not curve_data:
            return "female"  # ê¸°ë³¸ê°’ì„ femaleë¡œ ì„¤ì •
        
        # ì£¼íŒŒìˆ˜ ê°’ë“¤ ì¶”ì¶œ (dict í˜•íƒœì™€ list í˜•íƒœ ëª¨ë‘ ì²˜ë¦¬)
        frequencies = []
        for point in curve_data:
            if isinstance(point, dict) and 'f0' in point:
                frequencies.append(point['f0'])
            elif isinstance(point, (list, tuple)) and len(point) >= 2 and isinstance(point[1], (int, float)):
                frequencies.append(point[1])
        
        if not frequencies:
            return "female"  # ê¸°ë³¸ê°’
        
        # í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ ê³„ì‚°
        mean_f0 = sum(frequencies) / len(frequencies)
        
        # ì„±ë³„ ë¶„ë¥˜ ê¸°ì¤€ (ì¼ë°˜ì ì¸ ìŒì„±í•™ ê¸°ì¤€)
        gender_threshold = 165.0  # Hz - ë‚¨ì„±ê³¼ ì—¬ì„±ì„ êµ¬ë¶„í•˜ëŠ” ì„ê³„ê°’
        
        if mean_f0 < gender_threshold:
            detected_gender = "male"
        else:
            detected_gender = "female"
        
        print(f"ğŸ¯ ì°¸ì¡° ìŒì„± ë¶„ì„: í‰ê·  F0 = {mean_f0:.1f}Hz -> {detected_gender}")
        return detected_gender
        
    except Exception as e:
        print(f"ğŸš¨ ì„±ë³„ ê°ì§€ ì˜¤ë¥˜: {e}")
        return "female"  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’

def simple_pitch_analysis_implementation(sound: pm.Sound, syllables: List[dict]) -> tuple:
    """
    Simple pitch analysis implementation
    """
    try:
        duration = sound.get_total_duration()
        print(f"ğŸš€ AUDIO: {duration:.3f}s duration")
        
        # Basic pitch extraction
        pitch = sound.to_pitch(
            time_step=0.01,
            pitch_floor=75.0,
            pitch_ceiling=500.0
        )
        
        # Extract valid pitch points
        times = pitch.xs()
        valid_points = []
        
        for t in times:
            f0 = pitch.get_value_at_time(t)
            if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                valid_points.append((t, f0))
        
        print(f"ğŸš€ Found {len(valid_points)} valid pitch points")
        
        # Calculate sentence median
        all_f0_values = [f0 for t, f0 in valid_points]
        sentence_median = np.median(all_f0_values) if all_f0_values else 200.0
        
        # ğŸ¯ PERCEPTUAL PITCH CONTOUR: ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ë¡œ ë¶€ë“œëŸ¬ìš´ ê³¡ì„  ìƒì„±
        curve = []
        
        if len(syllables) > 0 and len(valid_points) > 0:
            # 1. ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚° (ì‚¬ëŒì´ ì¸ì§€í•˜ëŠ” ì–µì–‘ íŒ¨í„´)
            syllable_pitch_points = []
            
            for i, syl in enumerate(syllables):
                start_t = syl["start"]
                end_t = syl["end"]
                center_t = start_t + (end_t - start_t) / 2
                label = syl["label"]
                
                # ğŸ¯ ê°œì„ ëœ ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚°
                syllable_data = [(t, f0) for t, f0 in valid_points if start_t <= t <= end_t]
                
                if len(syllable_data) >= 2:
                    # ğŸ¯ ìŠ¤ë§ˆíŠ¸ ëŒ€í‘œê°’ ê³„ì‚°: ì´ìƒê°’ ì œê±° + ì¤‘ì‹¬ë¶€ ê°€ì¤‘í‰ê· 
                    times, pitches = zip(*syllable_data)
                    
                    # 1. ì´ìƒê°’ ì œê±° (IQR ë°©ì‹)
                    pitch_array = np.array(pitches)
                    Q1 = np.percentile(pitch_array, 25)
                    Q3 = np.percentile(pitch_array, 75)
                    IQR = Q3 - Q1
                    
                    # ì´ìƒê°’ ê¸°ì¤€: Q1 - 1.5*IQR ~ Q3 + 1.5*IQR
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    # ì •ìƒê°’ë§Œ í•„í„°ë§
                    filtered_data = [(t, f0) for t, f0 in syllable_data 
                                   if lower_bound <= f0 <= upper_bound]
                    
                    if len(filtered_data) >= 2:
                        times, pitches = zip(*filtered_data)
                        
                        # 2. ì¤‘ì‹¬ë¶€ ê°€ì¤‘í‰ê·  (ë” ì •êµí•œ ê°€ì¤‘ì¹˜)
                        weights = []
                        for t in times:
                            # ìŒì ˆ ì¤‘ì‹¬ì—ì„œì˜ ê±°ë¦¬ ë¹„ìœ¨ (0~1)
                            if (end_t - start_t) > 0:
                                distance_ratio = abs(t - center_t) / ((end_t - start_t) / 2)
                                distance_ratio = min(1.0, distance_ratio)  # 1.0 ì´ìƒ ì œí•œ
                            else:
                                distance_ratio = 0
                            
                            # ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜: ì¤‘ì‹¬ì—ì„œ ë©€ì–´ì§ˆìˆ˜ë¡ ê¸‰ê²©íˆ ê°ì†Œ
                            weight = np.exp(-2 * distance_ratio ** 2)  # e^(-2*d^2)
                            weights.append(weight)
                        
                        # ğŸ¯ ë” ì—„ê²©í•œ ì»¨íˆ¬ì–´ ì¼ì¹˜ ê²€ì¦
                        min_f0 = min(pitches)
                        max_f0 = max(pitches)
                        center_f0 = np.median(pitches)
                        q1_f0 = np.percentile(pitches, 25)
                        q3_f0 = np.percentile(pitches, 75)
                        
                        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                        representative_f0 = np.average(pitches, weights=weights)
                        
                        # ğŸ¯ ë”ìš± ì—„ê²©í•œ ë³´ì •: ë‚¨ì„± ì„±ë³„ ë¬¸ì œ í•´ê²°
                        iqr_range = q3_f0 - q1_f0
                        acceptable_range = max(iqr_range * 0.3, 8.0)  # ë” ì—„ê²©í•˜ê²Œ: 30% ë²”ìœ„, ìµœì†Œ 8Hz
                        
                        # ê°€ì¤‘ í‰ê· ì´ ì¤‘ì•™ê°’ì—ì„œ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì§„ ê²½ìš°
                        if abs(representative_f0 - center_f0) > acceptable_range:
                            representative_f0 = center_f0
                            print(f"  ğŸ¯ '{label}': IQRë³´ì • {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì¤‘ì•™ê°’ì‚¬ìš©)")
                        else:
                            # ì¶”ê°€ ê²€ì¦: ìµœëŒ“ê°’/ìµœì†Ÿê°’ ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸
                            if representative_f0 < min_f0 or representative_f0 > max_f0:
                                representative_f0 = center_f0
                                print(f"  ğŸ¯ '{label}': ë²”ìœ„ë³´ì • {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì¤‘ì•™ê°’ì‚¬ìš©)")
                            else:
                                # ìµœì¢… ê²€ì¦: 25-75% ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸ (ë” ì—„ê²©)
                                if representative_f0 < q1_f0 or representative_f0 > q3_f0:
                                    representative_f0 = center_f0
                                    print(f"  ğŸ¯ '{label}': Që²”ìœ„ë³´ì • {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì¤‘ì•™ê°’ì‚¬ìš©)")
                                else:
                                    print(f"  ğŸ¯ '{label}': {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ê²€ì¦ì™„ë£Œ)")
                    else:
                        # í•„í„°ë§ í›„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì›ë³¸ median ì‚¬ìš©
                        representative_f0 = np.median([f0 for t, f0 in syllable_data])
                        print(f"  ğŸ¯ '{label}': {len(syllable_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì›ë³¸median)")
                elif len(syllable_data) == 1:
                    # ë°ì´í„°ê°€ 1ê°œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    representative_f0 = syllable_data[0][1]
                    print(f"  ğŸ¯ '{label}': 1ê°œ â†’ {representative_f0:.1f}Hz (ë‹¨ì¼ê°’)")
                else:
                    # ìŒì ˆ ë‚´ ë°ì´í„° ì—†ìŒ: ë” ë„“ì€ ë²”ìœ„ì—ì„œ ê²€ìƒ‰
                    margin = 0.1  # 100msë¡œ í™•ì¥
                    extended_data = [(t, f0) for t, f0 in valid_points 
                                   if (start_t - margin) <= t <= (end_t + margin)]
                    
                    if len(extended_data) >= 2:
                        # í™•ì¥ ë°ì´í„°ë¡œ ë™ì¼í•œ ìŠ¤ë§ˆíŠ¸ ê³„ì‚°
                        times, pitches = zip(*extended_data)
                        pitch_array = np.array(pitches)
                        representative_f0 = np.median(pitch_array)
                        print(f"  ğŸ¯ '{label}': í™•ì¥ê²€ìƒ‰ {len(extended_data)}ê°œ â†’ {representative_f0:.1f}Hz")
                    elif extended_data:
                        representative_f0 = extended_data[0][1]
                        print(f"  ğŸ¯ '{label}': í™•ì¥ê²€ìƒ‰ 1ê°œ â†’ {representative_f0:.1f}Hz")
                    elif valid_points:
                        # ê°€ì¥ ê°€ê¹Œìš´ 3ê°œ í”¼ì¹˜ì˜ median
                        distances = [(abs(t - center_t), f0) for t, f0 in valid_points]
                        distances.sort()
                        nearest_pitches = [f0 for _, f0 in distances[:3]]
                        representative_f0 = np.median(nearest_pitches)
                        print(f"  ğŸ¯ '{label}': ìµœê·¼ì ‘3ê°œ â†’ {representative_f0:.1f}Hz")
                    else:
                        representative_f0 = sentence_median
                        print(f"  ğŸ¯ '{label}': ê¸°ë³¸ê°’ â†’ {representative_f0:.1f}Hz")
                
                syllable_pitch_points.append((center_t, representative_f0))
            
            # 2. ìŒì ˆ ì‚¬ì´ë¥¼ ë¶€ë“œëŸ½ê²Œ ë³´ê°„ (ìŠ¤í”Œë¼ì¸ ê³¡ì„  ì‹œë®¬ë ˆì´ì…˜)
            if len(syllable_pitch_points) >= 2:
                # ì „ì²´ ì‹œê°„ ë²”ìœ„
                start_time = syllable_pitch_points[0][0]
                end_time = syllable_pitch_points[-1][0]
                total_duration = end_time - start_time
                
                # 0.02ì´ˆ ê°„ê²©ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ê³¡ì„  ìƒì„± (50Hz ìƒ˜í”Œë§)
                time_step = 0.02
                num_points = int(total_duration / time_step) + 1
                
                for i in range(num_points):
                    current_time = start_time + i * time_step
                    
                    # í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” í”¼ì¹˜ ë³´ê°„
                    if current_time <= syllable_pitch_points[0][0]:
                        # ì‹œì‘ ì „
                        interpolated_f0 = syllable_pitch_points[0][1]
                    elif current_time >= syllable_pitch_points[-1][0]:
                        # ë ì´í›„
                        interpolated_f0 = syllable_pitch_points[-1][1]
                    else:
                        # ì¤‘ê°„ êµ¬ê°„ - ì„ í˜• ë³´ê°„
                        for j in range(len(syllable_pitch_points) - 1):
                            t1, f0_1 = syllable_pitch_points[j]
                            t2, f0_2 = syllable_pitch_points[j + 1]
                            
                            if t1 <= current_time <= t2:
                                # ì„ í˜• ë³´ê°„ (ë¶€ë“œëŸ¬ìš´ ê³¡ì„ )
                                ratio = (current_time - t1) / (t2 - t1) if t2 != t1 else 0
                                interpolated_f0 = f0_1 + (f0_2 - f0_1) * ratio
                                break
                        else:
                            interpolated_f0 = syllable_pitch_points[0][1]
                    
                    # ê³¡ì„  ë°ì´í„° ì¶”ê°€
                    semitone = 12 * np.log2(interpolated_f0 / sentence_median) if sentence_median > 0 else 0.0
                    curve.append({
                        "t": float(current_time),
                        "f0": float(interpolated_f0),
                        "dB": -30.0,  # Default intensity
                        "semitone": float(semitone)
                    })
            
            elif len(syllable_pitch_points) == 1:
                # ìŒì ˆì´ í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ í”Œë« ë¼ì¸
                t, f0 = syllable_pitch_points[0]
                semitone = 12 * np.log2(f0 / sentence_median) if sentence_median > 0 else 0.0
                curve.append({
                    "t": float(t),
                    "f0": float(f0),
                    "dB": -30.0,
                    "semitone": float(semitone)
                })
        
        elif len(valid_points) > 0:
            # ìŒì ˆ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°± (í•˜ì§€ë§Œ ë” ê°„ì†Œí™”)
            # ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§ (0.1ì´ˆë§ˆë‹¤)
            time_step = 0.1
            start_time = valid_points[0][0]
            end_time = valid_points[-1][0]
            
            current_time = start_time
            while current_time <= end_time:
                # í˜„ì¬ ì‹œê°„ ê·¼ì²˜ì˜ í”¼ì¹˜ë“¤ í‰ê· 
                nearby_pitches = [f0 for t, f0 in valid_points if abs(t - current_time) <= time_step/2]
                
                if nearby_pitches:
                    representative_f0 = np.median(nearby_pitches)
                    semitone = 12 * np.log2(representative_f0 / sentence_median) if sentence_median > 0 else 0.0
                    curve.append({
                        "t": float(current_time),
                        "f0": float(representative_f0),
                        "dB": -30.0,
                        "semitone": float(semitone)
                    })
                
                current_time += time_step
        
        print(f"ğŸ¯ ì¸ì§€ì  í”¼ì¹˜ ê³¡ì„ : {len(valid_points)} raw â†’ {len(curve)} ë¶€ë“œëŸ¬ìš´ í¬ì¸íŠ¸")
        
        # Process syllables for analysis table (unchanged)
        syllable_analysis = []
        
        for i, syl in enumerate(syllables):
            start_t = syl["start"]
            end_t = syl["end"]
            center_t = start_t + (end_t - start_t) / 2
            label = syl["label"]
            
            # Find pitch in syllable range
            syllable_pitches = [f0 for t, f0 in valid_points if start_t <= t <= end_t]
            
            if syllable_pitches:
                f0_val = np.mean(syllable_pitches)  # Use average instead of max
            elif valid_points:
                # Find nearest pitch
                nearest = min(valid_points, key=lambda x: abs(x[0] - center_t))
                f0_val = nearest[1]
            else:
                f0_val = sentence_median
            
            # Calculate semitone
            semitone = 12 * np.log2(f0_val / sentence_median) if sentence_median > 0 else 0.0
            
            syllable_analysis.append({
                "label": label,
                "start": float(start_t),
                "end": float(end_t),
                "duration": float(end_t - start_t),
                "f0": float(f0_val),
                "representative_f0": float(f0_val),  # ëŒ€í‘œ f0 ì¶”ê°€
                "semitone": float(semitone),
                "semitone_median": float(semitone),  # í˜¸í™˜ì„±
                "qtone": float(5 * np.log2(f0_val / 130)) if f0_val > 0 else 0.0,
                "intensity": -30.0,
                # ğŸ¯ ìŒì ˆ ì¤‘ì‹¬ì  ë°ì´í„° ì¶”ê°€ (ì°¨íŠ¸ í‘œì‹œìš©)
                "center_time": float(center_t),
                "start_time": float(start_t),  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±
                "end_time": float(end_t),      # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±
                "start": float(start_t),       # ì¶”ê°€ í˜¸í™˜ì„±
                "end": float(end_t)            # ì¶”ê°€ í˜¸í™˜ì„±
            })
        
        print(f"ğŸ¯ Generated {len(curve)} time series points and {len(syllable_analysis)} syllable analyses")
        
        return curve, syllable_analysis, sentence_median
        
    except Exception as e:
        print(f"Simple pitch analysis error: {e}")
        # Return default values
        return [], [], 200.0

def praat_pitch_analysis(
    sound: pm.Sound,
    syllables: List[dict],
    pitch_floor: float = 75.0,
    pitch_ceiling: float = 500.0,   
    time_step: float = 0.01,
) -> tuple:
    """
    ğŸš€ NEW SIMPLE ENGINE: ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼
    """
    # Simple pitch analysis implementation
    return simple_pitch_analysis_implementation(sound, syllables)
    
    duration = sound.get_total_duration()
    print(f"ğŸš€ AUDIO: {duration:.3f}s duration")
    
    # ğŸ¯ STEP 1: ê¸°ë³¸ í”¼ì¹˜ ì¶”ì¶œ (í‘œì¤€ ì„¤ì •)
    pitch = sound.to_pitch(
        time_step=time_step,
        pitch_floor=pitch_floor,
        pitch_ceiling=pitch_ceiling
    )
    
    print(f"ğŸš€ PITCH TRACK: {pitch_floor}-{pitch_ceiling}Hz, step={time_step}s")
    
    # ğŸ¯ STEP 2: ìŒì„± êµ¬ê°„ ì°¾ê¸° (ì‹¬í”Œí•œ ë°©ë²•)
    times = pitch.xs()
    valid_points = []
    
    for t in times:
        f0 = pitch.get_value_at_time(t)
        if f0 and not np.isnan(f0) and f0 > pitch_floor and f0 < pitch_ceiling:
            valid_points.append((t, f0))
    
    print(f"ğŸš€ FOUND: {len(valid_points)} valid pitch points")
    
    # ì²˜ìŒ ëª‡ê°œ í¬ì¸íŠ¸ í™•ì¸
    if valid_points:
        print("ğŸš€ FIRST VALID POINTS:")
        for i in range(min(3, len(valid_points))):
            t, f0 = valid_points[i]
            print(f"ğŸš€   {t:.3f}s = {f0:.1f}Hz")
    else:
        print("ğŸš€ ERROR: NO VALID PITCH FOUND")
        # ë” ê´€ëŒ€í•œ ì¡°ê±´ìœ¼ë¡œ ì¬ì‹œë„
        print("ğŸš€ TRYING BROADER RANGE...")
        pitch = sound.to_pitch(pitch_floor=50, pitch_ceiling=800, time_step=0.01)
        times = pitch.xs()
        for t in times:
            f0 = pitch.get_value_at_time(t)
            if f0 and not np.isnan(f0) and f0 > 50:
                valid_points.append((t, f0))
        print(f"ğŸš€ BROADER SEARCH: {len(valid_points)} points")
    
    # ğŸ¯ STEP 3: ê°•ë„(intensity) ê³„ì‚°
    intensity = sound.to_intensity()
    
    # ğŸ¯ STEP 4: ì „ì²´ ë¬¸ì¥ì˜ ê¸°ì¤€ í”¼ì¹˜ ê³„ì‚°
    all_f0_values = [f0 for t, f0 in valid_points]
    sentence_median = np.median(all_f0_values) if all_f0_values else 200.0
    print(f"ğŸš€ SENTENCE MEDIAN: {sentence_median:.1f} Hz")
    
    # ğŸ¯ STEP 5: ê° ìŒì ˆë³„ í”¼ì¹˜ ë¶„ì„ (ì‹¬í”Œí•˜ê²Œ!)
    curve = []
    syllable_analysis = []
    
    # Process each syllable (equivalent to Praat script's for loop)
    for i, syl in enumerate(syllables):
        start_t = syl["start"]
        end_t = syl["end"]
        dur = end_t - start_t
        center_t = start_t + dur/2
        label = syl["label"]
        
        print(f"ğŸ¯ Processing syllable '{label}' ({start_t:.3f}s - {end_t:.3f}s)")
        
        # ğŸ¯ DEBUG: Check pitch values in syllable range
        print(f"   ğŸ¯ Checking pitch values from {start_t:.3f}s to {end_t:.3f}s...")
        
        # ë” ì¡°ë°€í•˜ê²Œ ìƒ˜í”Œë§ (20ê°œ í¬ì¸íŠ¸)
        sample_times = [start_t + (end_t - start_t) * i / 19 for i in range(20)]
        valid_f0_values = []
        
        for sample_t in sample_times:
            try:
                f0_at_t = pitch.get_value_at_time(sample_t)
                if f0_at_t is not None and not np.isnan(f0_at_t) and f0_at_t > pitch_floor * 0.8:  # ë” ê´€ëŒ€í•œ í•„í„°ë§
                    valid_f0_values.append(f0_at_t)
                    print(f"     ğŸ¯ t={sample_t:.3f}s: f0={f0_at_t:.1f}Hz")
            except Exception as e:
                print(f"     ğŸ¯ t={sample_t:.3f}s: Error - {e}")
        
        print(f"   ğŸ¯ Found {len(valid_f0_values)} valid F0 values in syllable")
        
        # ğŸ¯ CRITICAL FIX: ì „ì²´ í”¼ì¹˜ íŠ¸ë™ì—ì„œ í•´ë‹¹ ì‹œê°„ëŒ€ ë°ì´í„° ì§ì ‘ ì¶”ì¶œ
        pitch_times = pitch.xs()  # ëª¨ë“  ì‹œê°„ í¬ì¸íŠ¸
        pitch_values = []
        
        for t in pitch_times:
            if start_t <= t <= end_t:
                f0_val = pitch.get_value_at_time(t)
                if f0_val is not None and not np.isnan(f0_val) and f0_val > pitch_floor * 0.8:
                    pitch_values.append((t, f0_val))
        
        print(f"   ğŸ¯ Direct extraction found {len(pitch_values)} pitch points in syllable")
        
        if pitch_values:
            # ìœ íš¨í•œ í”¼ì¹˜ê°’ì´ ìˆìœ¼ë©´ ìµœëŒ€ê°’ ì‚¬ìš©
            max_pitch_point = max(pitch_values, key=lambda x: x[1])
            f0_max = max_pitch_point[1]
            time_of_max = max_pitch_point[0]
            f0_mean = np.mean([p[1] for p in pitch_values])
            print(f"   ğŸ¯ Direct extraction: max={f0_max:.1f}Hz at {time_of_max:.3f}s, mean={f0_mean:.1f}Hz")
        elif valid_f0_values:
            # ìƒ˜í”Œë§ì—ì„œ ì°¾ì€ ê°’ë“¤ ì‚¬ìš©
            f0_max = max(valid_f0_values)
            f0_mean = np.mean(valid_f0_values)
            time_of_max = center_t
            print(f"   ğŸ¯ Sampling fallback: max={f0_max:.1f}Hz, mean={f0_mean:.1f}Hz")
        else:
            # ë§ˆì§€ë§‰ ëŒ€ì•ˆ: ì¸ê·¼ ìœ íš¨í•œ í”¼ì¹˜ê°’ ì°¾ê¸°
            nearby_f0_values = []
            search_range = 0.1  # 100ms ë²”ìœ„ë¡œ í™•ì¥ ê²€ìƒ‰
            
            for t in pitch_times:
                if (start_t - search_range) <= t <= (end_t + search_range):
                    f0_val = pitch.get_value_at_time(t)
                    if f0_val is not None and not np.isnan(f0_val) and f0_val > pitch_floor * 0.8:
                        nearby_f0_values.append(f0_val)
            
            if nearby_f0_values:
                f0_max = np.median(nearby_f0_values)  # ì¤‘ê°„ê°’ ì‚¬ìš©
                time_of_max = center_t
                print(f"   ğŸ¯ Extended search found {len(nearby_f0_values)} nearby values, using median={f0_max:.1f}Hz")
            else:
                f0_max = None
                time_of_max = center_t
                print(f"   ğŸ¯ No pitch found even with extended search")
        
        # Get mean F0 as fallback (like Praat script: Get mean...)
        try:
            f0_mean = pitch.get_mean(start_t, end_t, "Hertz")
            print(f"   ğŸ¯ get_mean() returned: {f0_mean}")
        except Exception as e:
            print(f"   ğŸ¯ get_mean() failed: {e}")
            f0_mean = None
        
        # Manual calculation from valid samples
        if valid_f0_values:
            manual_max = max(valid_f0_values)
            manual_mean = np.mean(valid_f0_values)
            print(f"   ğŸ¯ Manual calculation: max={manual_max:.1f}Hz, mean={manual_mean:.1f}Hz")
            
            # Use manual values if official methods failed
            if f0_max is None or np.isnan(f0_max):
                f0_max = manual_max
                time_of_max = center_t
                print(f"   ğŸ¯ Using manual max: {f0_max:.1f}Hz")
            
            if f0_mean is None or np.isnan(f0_mean):
                f0_mean = manual_mean
                print(f"   ğŸ¯ Using manual mean: {f0_mean:.1f}Hz")
        
        # Choose F0 value (prefer max, fallback to mean)
        if f0_max is not None and not np.isnan(f0_max):
            f0_val = f0_max
            time_val = time_of_max
            print(f"   ğŸ¯ Max F0: {f0_val:.1f} Hz @ {time_val:.3f}s")
        elif f0_mean is not None and not np.isnan(f0_mean):
            f0_val = f0_mean
            time_val = center_t
            print(f"   ğŸ¯ Mean F0: {f0_val:.1f} Hz @ {time_val:.3f}s")
        else:
            f0_val = sentence_median  # fallback to sentence median
            time_val = center_t
            print(f"   ğŸ¯ Fallback to sentence median: {f0_val:.1f} Hz")
        
        # Get intensity
        try:
            db_val = intensity.get_value(time_val)
            if db_val is None or np.isnan(db_val):
                db_val = -40.0
        except:
            db_val = -40.0
        
        # Calculate semitone and quarter-tone (like Praat script)
        if f0_val and not np.isnan(f0_val):
            semi_tone = 12 * np.log2(f0_val / sentence_median)
            quarter_tone = 24 * np.log2(f0_val / sentence_median)
            print(f"   ğŸ¯ Semi-tone: {semi_tone:.1f}, Quarter-tone: {quarter_tone:.1f}")
        else:
            semi_tone = 0.0
            quarter_tone = 0.0
        
        curve.append({
            "t": time_val,
            "f0": float(f0_val),
            "dB": float(db_val),
            "semitone": float(semi_tone)
        })
        
        syllable_analysis.append({
            "label": label,  # ğŸ¯ "syllable" â†’ "label" ìˆ˜ì •
            "start": float(start_t),
            "end": float(end_t), 
            "duration": float(dur),
            "f0": float(f0_val),
            "representative_f0": float(f0_val),
            "semitone": float(semi_tone),  # ğŸ¯ ì¤‘ìš”! semitone ì¶”ê°€
            "semitone_median": float(semi_tone),
            "qtone": float(5 * np.log2(f0_val / 130)) if f0_val > 0 else 0.0,
            "intensity": float(db_val),
            "center_time": float(time_val),  # ğŸ¯ ì¤‘ì‹¬ ì‹œê°„ ì¶”ê°€
            "start_time": float(start_t),
            "end_time": float(end_t)
        })
        
        print(f"   ğŸ¯âœ… '{label}': {f0_val:.1f}Hz @ {time_val:.3f}s, {db_val:.1f}dB")
    
    print(f"ğŸ¯ğŸ¯ğŸ¯ PRAAT ANALYSIS ì™„ë£Œ: {len(curve)}ê°œ í¬ì¸íŠ¸ ğŸ¯ğŸ¯ğŸ¯")
    return curve, syllable_analysis, sentence_median

def extract_ref_praat_implementation(
    sound: pm.Sound,
    tg: pm.TextGrid,
    pitch_floor: float = 75.0,
    pitch_ceiling: float = 600.0,
    time_step: float = 0.01,
    sentence: str | None = None,
    extracted_syllables: Optional[list] = None,
    target_gender: str = 'auto',
):
    """
    Complete Praat-based reference extraction implementing Script_toneLabeler_cj.praat
    """
    print("ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ PRAAT IMPLEMENTATION ì‹œì‘!!! ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
    print("ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ PRAAT IMPLEMENTATION ì‹œì‘!!! ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
    print("ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ PRAAT IMPLEMENTATION ì‹œì‘!!! ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
    print(f"ğŸ¯ Parameters: pitch_floor={pitch_floor}, pitch_ceiling={pitch_ceiling}")
    print(f"ğŸ¯ Sound duration: {sound.xmax - sound.xmin:.3f}s")
    
    t_min, t_max = sound.xmin, sound.xmax
    
    # Step 1: Use extracted syllables from new TextGrid parser or fallback
    if extracted_syllables:
        print(f"ğŸ¯ Using extracted syllables: {len(extracted_syllables)} syllables")
        syllables = extracted_syllables
    else:
        print("ğŸ¯ Fallback: Using old TextGrid parser")
        syllables = praat_script_textgrid_parser(tg) if tg else []
    
    # Step 2: Fallback to sentence-based or time-based segmentation
    if not syllables:
        if sentence and sentence.strip():
            print(f"ğŸ¯ Sentence-based segmentation: '{sentence}'")
            syllable_labels = split_korean_sentence(sentence.strip())
            num_syllables = len(syllable_labels)
            segment_duration = float(t_max - t_min) / num_syllables
            
            for i, label in enumerate(syllable_labels):
                start_time = float(t_min + i * segment_duration)
                end_time = float(t_min + (i+1) * segment_duration)
                syllables.append({
                    "label": label,
                    "start": start_time,
                    "end": end_time,
                })
                print(f"   ğŸ¯ Sentence syllable: '{label}' ({start_time:.3f}s-{end_time:.3f}s)")
        else:
            print("ğŸ¯ Default 3-segment division")
            segment_duration = float(t_max - t_min) / 3
            for i in range(3):
                start_time = float(t_min + i * segment_duration)
                end_time = float(t_min + (i+1) * segment_duration)
                syllables.append({
                    "label": f"êµ¬ê°„{i+1}",
                    "start": start_time,
                    "end": end_time,
                })
    
    print(f"ğŸ¯ Final syllables: {len(syllables)} syllables")
    
    # Step 3: Praat pitch analysis
    curve, syllable_analysis, sentence_median = praat_pitch_analysis(
        sound, syllables, pitch_floor, pitch_ceiling, time_step
    )
    
    
    return {
        "curve": curve,
        "syllables": syllables,
        "syllable_analysis": syllable_analysis,
        "spectrogram": [],
        "stats": {
            "meanF0": sentence_median,
            "maxF0": max([p["f0"] for p in curve]) if curve else 180.0,
            "maxdB": max([p["dB"] for p in curve]) if curve else -40.0,
            "sentence_median": sentence_median,
            "duration": float(t_max - t_min),
        },
    }

@app.get("/", response_class=HTMLResponse)
async def get_index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/react-demo", response_class=HTMLResponse)
async def react_demo(request: Request):
    """React migration demo using voice-analysis-demo directory contents only"""
    # Use voice-analysis-demo directory templates and static files
    from fastapi.templating import Jinja2Templates
    demo_templates = Jinja2Templates(directory="voice-analysis-demo/templates")
    return demo_templates.TemplateResponse("index.html", {"request": request})

@app.post("/analyze_ref", response_model=RefAnalysis)
async def analyze_ref(
    wav: UploadFile = File(..., description="Reference WAV"),
    textgrid: UploadFile = File(..., description="Reference TextGrid"),
    sentence: str = Form(None, description="Sentence text for syllable labeling"),
    learner_gender: str = Form(..., description="Learner gender (male/female)"),
    learner_name: str = Form(None, description="Learner name (optional)"),
    learner_level: str = Form(None, description="Learner level (optional)"),
    pitch_floor: Optional[float] = Form(75.0),
    pitch_ceiling: Optional[float] = Form(600.0),
    time_step: Optional[float] = Form(0.01),
):
    try:
        print("ğŸ¯ğŸ¯ğŸ¯ PRAAT API ENDPOINT í˜¸ì¶œë¨!!! ğŸ¯ğŸ¯ğŸ¯")
        print(f"Received files: WAV={wav.filename}, TextGrid={textgrid.filename}")
        print(f"ğŸ¯ í•™ìŠµì ì •ë³´: ì„±ë³„={learner_gender}, ì´ë¦„={learner_name or 'ë¯¸ì…ë ¥'}, ìˆ˜ì¤€={learner_level or 'ë¯¸ì…ë ¥'}")
        if sentence:
            print(f"Received sentence: '{sentence}'")
        
        # Validate file types
        if wav.filename and not wav.filename.lower().endswith('.wav'):
            raise HTTPException(status_code=400, detail="WAV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        if textgrid.filename and not textgrid.filename.lower().endswith(('.textgrid', '.TextGrid')):
            raise HTTPException(status_code=400, detail="TextGrid íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        wav_bytes = await wav.read()
        tg_bytes = await textgrid.read()
        
        print(f"File sizes: WAV={len(wav_bytes)} bytes, TextGrid={len(tg_bytes)} bytes")

        # Create temporary files for parselmouth
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_temp:
            wav_temp.write(wav_bytes)
            wav_temp_path = wav_temp.name
            
        with tempfile.NamedTemporaryFile(suffix='.TextGrid', delete=False) as tg_temp:
            tg_temp.write(tg_bytes)
            tg_temp_path = tg_temp.name

        try:
            import parselmouth as pm
            snd = pm.Sound(wav_temp_path)
            
            # Try to read TextGrid file
            try:
                tg = pm.TextGrid.read(tg_temp_path)
                
                # ğŸ¯ COMPLETE TextGrid structure analysis
                print(f"ğŸ¯ğŸ” TextGrid ê°ì²´ ì™„ì „ ë¶„ì„:")
                print(f"    ğŸ¯ Type: {type(tg)}")
                print(f"    ğŸ¯ Dir: {[attr for attr in dir(tg) if not attr.startswith('_')]}")
                
                # Check all possible attributes AND methods
                attributes_to_check = [
                    'n_tiers', 'tiers', 'size', 'count', 'length',
                    'xmin', 'xmax', 'start_time', 'end_time', 'info'
                ]
                
                for attr in attributes_to_check:
                    if hasattr(tg, attr):
                        try:
                            if callable(getattr(tg, attr)):
                                if attr == 'info':
                                    value = getattr(tg, attr)()  # Call the method
                                else:
                                    value = f"<method {attr}>"
                            else:
                                value = getattr(tg, attr)
                            print(f"    ğŸ¯ {attr}: {value} (type: {type(value)})")
                        except Exception as e:
                            print(f"    ğŸ¯ {attr}: Error calling - {e}")
                
                # ğŸ¯ TRY DIFFERENT PARSELMOUTH METHODS
                print("ğŸ¯ Trying different Parselmouth access methods...")
                
                # Method: Try to find tier-related methods in dir
                all_methods = [attr for attr in dir(tg) if not attr.startswith('_')]
                tier_methods = [m for m in all_methods if 'tier' in m.lower()]
                if tier_methods:
                    print(f"    ğŸ¯ Found tier-related methods: {tier_methods}")
                
                # Method: Try to use info() method for structure
                try:
                    if hasattr(tg, 'info'):
                        info_result = tg.info()
                        print(f"    ğŸ¯ Info method result: {info_result}")
                except Exception as e:
                    print(f"    ğŸ¯ Info method failed: {e}")
                
                # ğŸ¯ CORRECT APPROACH: Use official Parselmouth TextGrid API
                tier_count = 0
                intervals = []
                
                # Method 1: Try TextGridTools (to_tgt) - OFFICIAL METHOD
                try:
                    print("ğŸ¯ Method 1: Using TextGridTools (.to_tgt())")
                    try:
                        import textgrid as tgt  # TextGrid parser
                    except ImportError:
                        print("ğŸš¨ textgrid ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                    
                    # Simple TextGrid parsing without external library
                    print("ğŸ¯ Using simple TextGrid parsing")
                    
                    # Read TextGrid file content
                    with open(tg_temp_path, 'r', encoding='utf-8') as f:
                        tg_content = f.read()
                    
                    tgt_grid = None
                    print(f"    ğŸ¯ TextGrid content read successful!")
                    print(f"    ğŸ¯ Content length: {len(tg_content)} characters")
                    
                    # Simple TextGrid parsing - extract intervals using regex
                    import re
                    
                    # Find intervals in TextGrid content
                    interval_pattern = r'intervals \[\d+\]:\s*xmin = ([\d.]+)\s*xmax = ([\d.]+)\s*text = "([^"]*)"'  
                    matches = re.findall(interval_pattern, tg_content)
                    
                    for start_str, end_str, text in matches:
                        if text.strip() and text.strip().lower() not in ['', 'p', 'sp']:
                            intervals.append({
                                "label": text.strip(),
                                "start": float(start_str),
                                "end": float(end_str)
                            })
                            print(f"      ğŸ¯ Parsed interval: '{text}' ({start_str}s-{end_str}s)")
                    
                    tier_count = 1 if intervals else 0
                    print(f"ğŸ¯âœ… Simple parsing method SUCCESS: {len(intervals)} intervals extracted")
                        
                except ImportError:
                    print("    ğŸ¯ TextGridTools not installed, trying Method 2...")
                except Exception as e:
                    print(f"    ğŸ¯ TextGridTools method failed: {e}")
                
                # Method 2: Direct Praat calls - OFFICIAL METHOD
                if tier_count == 0:
                    try:
                        print("ğŸ¯ Method 2: Using parselmouth.praat.call()")
                        import parselmouth as pm
                        
                        # Get basic tier information  
                        num_tiers = pm.praat.call(tg, "Get number of tiers")
                        print(f"    ğŸ¯ Number of tiers: {num_tiers}")
                        
                        if num_tiers > 0:
                            tier_count = num_tiers
                            
                            # Get first tier information (1-based indexing in Praat!)
                            tier_name = pm.praat.call(tg, "Get tier name", 1)
                            num_intervals = pm.praat.call(tg, "Get number of intervals", 1)
                            print(f"    ğŸ¯ Tier 1 name: '{tier_name}', intervals: {num_intervals}")
                            
                            # Extract all intervals from first tier
                            for i in range(1, num_intervals + 1):  # 1-based indexing!
                                start_time = pm.praat.call(tg, "Get start time of interval", 1, i)
                                end_time = pm.praat.call(tg, "Get end time of interval", 1, i)
                                label = pm.praat.call(tg, "Get label of interval", 1, i)
                                
                                intervals.append({
                                    'start': start_time,
                                    'end': end_time,
                                    'label': label.strip(),
                                    'index': i-1  # Convert to 0-based for consistency
                                })
                                print(f"        ğŸ¯ Interval {i}: '{label}' ({start_time:.3f}s - {end_time:.3f}s)")
                            
                            print(f"ğŸ¯âœ… Praat calls method SUCCESS: {len(intervals)} intervals extracted")
                            
                    except Exception as e:
                        print(f"    ğŸ¯ Praat calls method failed: {e}")
                
                # Filter out empty intervals and prepare syllable data
                syllables = []
                if intervals:
                    print(f"ğŸ¯ Processing {len(intervals)} intervals...")
                    
                    for interval in intervals:
                        # Only include non-empty intervals
                        if interval['label'] and interval['label'].strip():
                            syllables.append({
                                'label': interval['label'],
                                'start': interval['start'],
                                'end': interval['end']
                            })
                            print(f"    ğŸ¯ Valid syllable: '{interval['label']}' ({interval['start']:.3f}s - {interval['end']:.3f}s)")
                    
                    print(f"ğŸ¯âœ… Final syllable count: {len(syllables)} syllables")
                else:
                    print("ğŸ¯âš ï¸ No intervals extracted from TextGrid")
                
                # Use extracted syllables or fallback
                if syllables:
                    tier_count = len(syllables) 
                    print(f"ğŸ¯âœ… Successfully extracted {len(syllables)} syllables from TextGrid")
                else:
                    tier_count = 0
                    print("ğŸ¯âš ï¸ No syllables found - using fallback mode")
                    
            except Exception as e1:
                try:
                    # Alternative reading method
                    import subprocess
                    result = subprocess.run(['file', tg_temp_path], capture_output=True, text=True)
                    print(f"ğŸ¯ File type check: {result.stdout.strip()}")
                    
                    data_obj = pm.Data.read(tg_temp_path)
                    if hasattr(data_obj, 'n_tiers') or hasattr(data_obj, 'tiers'):
                        tg = data_obj
                        tier_count = getattr(data_obj, 'n_tiers', len(getattr(data_obj, 'tiers', [])))
                        print(f"ğŸ¯âœ… TextGrid ì½ê¸° ì„±ê³µ (Dataë¡œ): {tier_count}ê°œ tier")
                    else:
                        raise Exception("Read object is not a valid TextGrid")
                except Exception as e2:
                    print(f"ğŸ¯âŒ TextGrid ì½ê¸° ì‹¤íŒ¨: {e1}, {e2}")
                    print("ğŸ¯ğŸ”„ ìŒì„± ì „ìš© ë¶„ì„ ëª¨ë“œë¡œ ì§„í–‰ (TextGrid ì—†ì´)")
                    tg = None
                    tier_count = 0
            
            tg_info = f"Sound duration: {snd.duration:.2f}s"
            if tg is not None:
                tg_info += f", TextGrid tiers: {tier_count}"
            else:
                tg_info += ", TextGrid: fallback mode"
            print(tg_info)
            
            # ğŸ¯ ì„±ë³„ ë§¤ê°œë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸° 
            target_gender = 'auto'  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            print(f"ğŸ¯ Target gender: {target_gender}")
            
            # ğŸ¯ syllables ë³€ìˆ˜ ì´ˆê¸°í™” (í™•ì‹¤í•˜ê²Œ ì •ì˜)
            syllables = []
            if 'syllables' not in locals():
                syllables = []
            
            # ğŸ¯ í•™ìŠµì ì„±ë³„ì— ë”°ë¥¸ ìµœì í™”ëœ ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
            if learner_gender == "male":
                optimized_pitch_floor = 75.0
                optimized_pitch_ceiling = 300.0
                print(f"ğŸ¯ ë‚¨ì„± í•™ìŠµì - ìµœì í™”ëœ í”¼ì¹˜ ë²”ìœ„: {optimized_pitch_floor}-{optimized_pitch_ceiling}Hz")
            elif learner_gender == "female":
                optimized_pitch_floor = 100.0
                optimized_pitch_ceiling = 600.0
                print(f"ğŸ¯ ì—¬ì„± í•™ìŠµì - ìµœì í™”ëœ í”¼ì¹˜ ë²”ìœ„: {optimized_pitch_floor}-{optimized_pitch_ceiling}Hz")
            else:
                optimized_pitch_floor = pitch_floor or 75.0
                optimized_pitch_ceiling = pitch_ceiling or 600.0
                print(f"ğŸ¯ ê¸°ë³¸ í”¼ì¹˜ ë²”ìœ„ ì‚¬ìš©: {optimized_pitch_floor}-{optimized_pitch_ceiling}Hz")
            
            print("ğŸ¯ğŸ¯ğŸ¯ PRAAT extract_ref í•¨ìˆ˜ í˜¸ì¶œ ì§ì „!!! ğŸ¯ğŸ¯ğŸ¯")
            # Pass extracted syllables from TextGrid to the processing function with optimized parameters
            out = extract_ref_praat_implementation(
                snd, tg,
                pitch_floor=optimized_pitch_floor,
                pitch_ceiling=optimized_pitch_ceiling,
                time_step=time_step or 0.01,
                sentence=sentence,
                extracted_syllables=syllables if syllables and len(syllables) > 0 else None,
                target_gender=target_gender
            )
            print("ğŸ¯ğŸ¯ğŸ¯ PRAAT extract_ref í•¨ìˆ˜ í˜¸ì¶œ ì™„ë£Œ!!! ğŸ¯ğŸ¯ğŸ¯")
            
            # ğŸ¯ ì°¸ì¡° ìŒì„±ì˜ ì„±ë³„ ìë™ ê°ì§€
            reference_gender = detect_reference_gender(out)
            print(f"ğŸ¯ ì°¸ì¡° ìŒì„± ì„±ë³„ ê°ì§€: {reference_gender}")
            
            # ğŸ¯ í•™ìŠµì ì„±ë³„ì— ë”°ë¥¸ ì°¸ì¡° ë°ì´í„° ì •ê·œí™”
            if learner_gender == "male":
                print("ğŸ¯ ë‚¨ì„± í•™ìŠµì - ì°¸ì¡° ë°ì´í„°ë¥¼ ë‚¨ì„± ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” ì¤‘...")
                out = apply_gender_normalization(out, target_gender=reference_gender, learner_gender="male")
                print("ğŸ¯ ë‚¨ì„± í•™ìŠµì - ì •ê·œí™”ëœ ê³¡ì„ ì— ë§ëŠ” ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ í‘œì‹œ")
            elif learner_gender == "female":
                print("ğŸ¯ ì—¬ì„± í•™ìŠµì - ì°¸ì¡° ë°ì´í„°ë¥¼ ì—¬ì„± ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” ì¤‘...")
                out = apply_gender_normalization(out, target_gender=reference_gender, learner_gender="female")
            else:
                print("ğŸ¯ ì„±ë³„ ë¯¸ì§€ì • - ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
            
            print(f"Analysis complete: {len(out['curve'])} points, {len(out['syllables'])} syllables, {len(out.get('syllable_analysis', []))} syllable_analysis")
            print(f"ğŸ¯ CRITICAL DEBUG - out keys: {list(out.keys())}")
            if 'syllable_analysis' in out:
                print(f"ğŸ¯ syllable_analysis ìƒ˜í”Œ: {out['syllable_analysis'][:3] if len(out['syllable_analysis']) > 0 else 'EMPTY'}")
            
        finally:
            # Clean up temporary files
            try:
                os.unlink(wav_temp_path)
                os.unlink(tg_temp_path)
            except:
                pass
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"Analysis error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    curve = [RefPoint(**p) for p in out["curve"]]
    syll  = [Syllable(**s) for s in out["syllables"]]
    
    print(f"ğŸ¯ FINAL CHECK - syllable_analysis exists: {'syllable_analysis' in out}")
    if 'syllable_analysis' in out:
        print(f"ğŸ¯ FINAL CHECK - syllable_analysis length: {len(out['syllable_analysis'])}")
        print(f"ğŸ¯ FINAL CHECK - syllable_analysis sample: {out['syllable_analysis'][:2] if out['syllable_analysis'] else 'EMPTY'}")
    
    syllable_analysis = [SyllableAnalysis(**s) for s in out.get("syllable_analysis", [])]
    print(f"ğŸ¯ FINAL CHECK - Pydantic syllable_analysis length: {len(syllable_analysis)}")
    return RefAnalysis(
        curve=curve, 
        syllables=syll, 
        syllable_analysis=syllable_analysis,
        stats=out["stats"]
    )

@app.post("/api/save_session")
async def save_session(request: Request):
    """Save analysis session data"""
    try:
        data = await request.json()
        print(f"ğŸ¯ Saving session data: {len(data)} items")
        # Here you would typically save to database
        return JSONResponse({"status": "success", "message": "Session saved"})
    except Exception as e:
        print(f"Save session error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.post("/api/record_realtime")
async def record_realtime(
    audio_data: UploadFile = File(...),
    session_id: str = Form(None)
):
    """Real-time audio recording and analysis endpoint"""
    try:
        print("ğŸ¯ Real-time recording received")
        audio_bytes = await audio_data.read()
        
        # Process real-time audio with Praat algorithms
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
            temp_audio.write(audio_bytes)
            temp_audio_path = temp_audio.name
        
        try:
            snd = pm.Sound(temp_audio_path)
            
            # Quick pitch analysis for real-time
            pitch = snd.to_pitch_ac(
                time_step=0.01,
                pitch_floor=75.0,
                pitch_ceiling=600.0,
                very_accurate=False  # Faster for real-time
            )
            
            times = pitch.xs()
            f0_values = []
            for t in times:
                f0 = pitch.get_value_at_time(t)
                if f0 is not None and not np.isnan(f0):
                    f0_values.append({"t": t, "f0": f0})
            
            print(f"ğŸ¯ Real-time analysis: {len(f0_values)} pitch points")
            
        finally:
            os.unlink(temp_audio_path)
        
        return JSONResponse({
            "status": "success",
            "pitch_data": f0_values[-10:] if f0_values else [],  # Last 10 points
            "duration": snd.duration if 'snd' in locals() else 0
        })
        
    except Exception as e:
        print(f"Real-time analysis error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

# Database dependency
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.post("/api/save_reference")
async def save_reference_file(
    title: str = Form(...),
    description: str = Form(""),
    sentence_text: str = Form(""),
    wav_file: UploadFile = File(...),
    textgrid_file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """ì°¸ì¡° íŒŒì¼ì„ ì„œë²„ì— ì €ì¥"""
    try:
        # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        file_id = str(uuid.uuid4())
        wav_filename = f"{file_id}_{wav_file.filename}"
        textgrid_filename = f"{file_id}_{textgrid_file.filename}"
        
        # íŒŒì¼ ì €ì¥
        wav_path = UPLOAD_DIR / wav_filename
        textgrid_path = UPLOAD_DIR / textgrid_filename
        
        with open(wav_path, "wb") as f:
            shutil.copyfileobj(wav_file.file, f)
        
        with open(textgrid_path, "wb") as f:
            shutil.copyfileobj(textgrid_file.file, f)
        
        # íŒŒì¼ í¬ê¸° ê³„ì‚°
        file_size = wav_path.stat().st_size + textgrid_path.stat().st_size
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ ìŒì ˆ ìˆ˜ ë¶„ì„
        try:
            snd = pm.Sound(str(wav_path))
            duration = snd.duration
            
            # TextGridì—ì„œ ìŒì ˆ ìˆ˜ ì¶”ì¶œ
            tg = pm.TextGrid.read_from_file(str(textgrid_path))
            syllable_count = len([tier for tier in tg.tiers if tier.name == "syllables"])
            if syllable_count == 0:
                syllable_count = len(tg.tiers[0].intervals) if tg.tiers else 0
        except:
            duration = 0.0
            syllable_count = 0
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        ref_file = ReferenceFile(
            title=title,
            description=description,
            sentence_text=sentence_text,
            wav_filename=wav_filename,
            textgrid_filename=textgrid_filename,
            file_size=file_size,
            duration=duration,
            syllable_count=syllable_count,
            is_public=True
        )
        
        db.add(ref_file)
        db.commit()
        db.refresh(ref_file)
        
        return JSONResponse({
            "status": "success",
            "message": "ì°¸ì¡° íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "file_id": ref_file.id
        })
        
    except Exception as e:
        print(f"Save reference file error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.get("/api/reference_files")
async def get_reference_files():
    """ì €ì¥ëœ ì°¸ì¡° íŒŒì¼ ëª©ë¡ ì¡°íšŒ - íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜"""
    try:
        # ì§ì ‘ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì¡° ë°˜ì˜
        reference_dir = "static/reference_files"
        if not os.path.exists(reference_dir):
            return JSONResponse({"files": []})
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ WAV íŒŒì¼ë“¤ ì°¾ê¸°
        wav_files = []
        for filename in os.listdir(reference_dir):
            if filename.endswith('.wav'):
                base_name = filename[:-4]  # .wav ì œê±°
                textgrid_file = base_name + '.TextGrid'
                textgrid_path = os.path.join(reference_dir, textgrid_file)
                
                if os.path.exists(textgrid_path):
                    # íŒŒì¼ í¬ê¸° ë° ì§€ì†ì‹œê°„ ê³„ì‚°
                    wav_path = os.path.join(reference_dir, filename)
                    file_size = os.path.getsize(wav_path)
                    
                    # ğŸ¯ ì‹¤ì œ ì˜¤ë””ì˜¤ ì§€ì†ì‹œê°„ê³¼ ì„±ë³„ ë¶„ì„
                    duration = 0.0
                    detected_gender = "female"  # ê¸°ë³¸ê°’
                    average_f0 = 0.0
                    
                    try:
                        import parselmouth as pm
                        sound = pm.Sound(wav_path)
                        duration = sound.get_total_duration()
                        
                        # ì„±ë³„ ìë™ ê°ì§€ë¥¼ ìœ„í•œ í”¼ì¹˜ ë¶„ì„
                        pitch = sound.to_pitch()
                        f0_values = []
                        for i in range(pitch.get_number_of_frames()):
                            f0 = pitch.get_value_in_frame(i + 1)
                            if not np.isnan(f0) and f0 > 0:
                                f0_values.append(f0)
                        
                        if f0_values:
                            average_f0 = np.mean(f0_values)
                            # ì„±ë³„ ê°ì§€ (165Hz ê¸°ì¤€)
                            detected_gender = "male" if average_f0 < 165.0 else "female"
                        
                        print(f"ğŸ¯ {filename}: {duration:.2f}ì´ˆ, í‰ê· F0={average_f0:.1f}Hz, ì„±ë³„={detected_gender}")
                    except Exception as e:
                        print(f"ğŸ¯ {filename}: ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨ - {e}")
                        duration = 0.0
                    
                    # íŒŒì¼ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì œëª© ìƒì„±
                    title = base_name.replace('_', ' ').replace('-', ' ')
                    if base_name == "ì˜¬ë¼ê°€":
                        title = "ì–´ë””ê¹Œì§€ ì˜¬ë¼ê°€ëŠ” ê±°ì˜ˆìš”"
                    elif base_name == "ë‚´ë ¤ê°€":
                        title = "ì–´ë””ê¹Œì§€ ë‚´ë ¤ê°€ëŠ” ê±°ì˜ˆìš”"
                    elif base_name == "ë‚´ì¹œêµ¬":
                        title = "ë‚´ ì¹œêµ¬ê°€ ë©´ì ‘ì— í•©ê²©í–ˆëŒ€"
                    elif base_name == "friend_interview":
                        title = "ë‚´ ì¹œêµ¬ê°€ ë©´ì ‘ì— í•©ê²©í–ˆëŒ€ (ìƒˆë²„ì „)"
                    elif base_name == "ë­ë¼ê³ ê·¸ëŸ¬ì…¨ì†Œ":
                        title = "ë­ë¼ê³  ê·¸ëŸ¬ì…¨ì†Œ"
                    elif base_name == "ë‰´ìŠ¤ì½ê¸°":
                        title = "ë‰´ìŠ¤ ì½ê¸°"
                    elif base_name == "ë‚­ë…ë¬¸ì¥":
                        title = "ë‚­ë… ë¬¸ì¥"
                    
                    wav_files.append({
                        "id": base_name,
                        "title": title,
                        "description": f"{title} ì—°ìŠµìš© ì°¸ì¡° ìŒì„±",
                        "sentence_text": title,
                        "duration": duration,
                        "syllable_count": 0,
                        "file_size": file_size,
                        "detected_gender": detected_gender,
                        "average_f0": average_f0,
                        "created_at": "2025-01-01T00:00:00",
                        "wav": filename,
                        "textgrid": textgrid_file
                    })
        
        # ğŸ¯ ì‚¬ìš©ì ì§€ì • ìˆœì„œë¡œ ì •ë ¬
        custom_order = [
            "ì•ˆë…•í•˜ì„¸ìš”", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "ë°˜ê°€ì›Œìš”", "ì˜¬ë¼ê°€", "ë‚´ë ¤ê°€", 
            "ë­ë¼ê³ ê·¸ëŸ¬ì…¨ì†Œ", "ì•„ì£¼ì˜ë³´ì´ë„¤ìš”", "ë‚­ë…ë¬¸ì¥", "ë‰´ìŠ¤ì½ê¸°"
        ]
        
        # ìˆœì„œ ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë ¬
        def get_sort_key(file_item):
            base_name = file_item["id"]
            try:
                return custom_order.index(base_name)
            except ValueError:
                return len(custom_order)  # ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” íŒŒì¼ì€ ë§¨ ë’¤ë¡œ
        
        wav_files.sort(key=get_sort_key)
        
        print(f"ğŸ¯ Found {len(wav_files)} reference files")
        return JSONResponse({"files": wav_files})
        
    except Exception as e:
        print(f"Get reference files error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.get("/api/reference_files/{file_id}/wav")
async def get_reference_wav(file_id: str):
    """ì €ì¥ëœ WAV íŒŒì¼ ë‹¤ìš´ë¡œë“œ - íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜"""
    try:
        wav_path = f"static/reference_files/{file_id}.wav"
        if not os.path.exists(wav_path):
            raise HTTPException(status_code=404, detail="WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ¯ Serving WAV file: {wav_path}")
        return FileResponse(wav_path, media_type="audio/wav", filename=f"{file_id}.wav")
        
    except Exception as e:
        print(f"Get reference WAV error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analyze/{file_id}")
async def analyze_reference_file(file_id: str):
    """ì°¸ì¡° íŒŒì¼ ë¶„ì„ - ê¸°ì¡´ íŒŒì¼ë¡œë¶€í„° ë¶„ì„ ìˆ˜í–‰"""
    try:
        print(f"ğŸ¯ Analyzing reference file: {file_id}")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        wav_path = f"static/reference_files/{file_id}.wav"
        tg_path = f"static/reference_files/{file_id}.TextGrid"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(wav_path):
            raise HTTPException(status_code=404, detail=f"WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {wav_path}")
        if not os.path.exists(tg_path):
            raise HTTPException(status_code=404, detail=f"TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {tg_path}")
        
        # íŒŒì¼ ë¶„ì„ ìˆ˜í–‰ (ê¸°ì¡´ analyze_ref ë¡œì§ ì¬ì‚¬ìš©)
        import parselmouth as pm
        
        try:
            snd = pm.Sound(wav_path)
            tg = pm.TextGrid.read(tg_path)
            
            print(f"ğŸ¯ Successfully loaded: {wav_path} and {tg_path}")
            
            # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            duration = snd.get_total_duration()
            pitch = snd.to_pitch(time_step=0.01, pitch_floor=75.0, pitch_ceiling=500.0)
            
            # ê¸°ë³¸ í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
            times = pitch.xs()
            valid_points = []
            
            for t in times:
                f0 = pitch.get_value_at_time(t)
                if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                    valid_points.append({"time": float(t), "frequency": float(f0)})
            
            return {
                "success": True,
                "file_id": file_id,
                "duration": float(duration),
                "pitch_data": valid_points[:100],  # ì²˜ìŒ 100ê°œ í¬ì¸íŠ¸ë§Œ
                "total_points": len(valid_points),
                "message": f"ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤: {len(valid_points)}ê°œ í”¼ì¹˜ í¬ì¸íŠ¸"
            }
            
        except Exception as parse_error:
            print(f"âŒ Parselmouth parsing error: {parse_error}")
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(parse_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Analyze reference file error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/reference_files/{file_id}/pitch")
async def get_reference_pitch(file_id: str, syllable_only: bool = False):
    """ì°¸ì¡° íŒŒì¼ì˜ í”¼ì¹˜ ë°ì´í„° ë°˜í™˜ - Chart.jsì—ì„œ ì‚¬ìš©"""
    try:
        print(f"ğŸ¯ Getting pitch data for reference file: {file_id} (syllable_only={syllable_only})")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        wav_path = f"static/reference_files/{file_id}.wav"
        tg_path = f"static/reference_files/{file_id}.TextGrid"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(wav_path):
            raise HTTPException(status_code=404, detail=f"WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {wav_path}")
        
        # íŒŒì¼ ë¶„ì„ ìˆ˜í–‰
        import parselmouth as pm
        
        try:
            snd = pm.Sound(wav_path)
            print(f"ğŸ¯ Successfully loaded WAV: {wav_path}")
            
            # í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
            pitch = snd.to_pitch(time_step=0.01, pitch_floor=75.0, pitch_ceiling=500.0)
            times = pitch.xs()
            
            if syllable_only:
                # ğŸ¯ ìŒì ˆë³„ ëŒ€í‘œ í¬ì¸íŠ¸ë§Œ ë°˜í™˜
                return await get_syllable_representative_pitch(file_id, wav_path, tg_path, snd, pitch)
            else:
                # ğŸ¯ ëª¨ë“  í”¼ì¹˜ í¬ì¸íŠ¸ ë°˜í™˜ (ê¸°ì¡´ ë™ì‘)
                pitch_points = []
                for t in times:
                    f0 = pitch.get_value_at_time(t)
                    if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                        pitch_points.append({
                            "time": float(t), 
                            "frequency": float(f0)
                        })
                
                print(f"ğŸ¯ Extracted {len(pitch_points)} pitch points")
                return JSONResponse(pitch_points)
            
        except Exception as parse_error:
            print(f"âŒ Parselmouth parsing error: {parse_error}")
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(parse_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Get reference pitch error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def get_syllable_representative_pitch(file_id: str, wav_path: str, tg_path: str, snd, pitch):
    """ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ í¬ì¸íŠ¸ ê³„ì‚°"""
    try:
        # TextGrid íŒŒì¼ ë¡œë“œ
        if not os.path.exists(tg_path):
            print(f"ğŸ¯ No TextGrid file found: {tg_path}")
            return JSONResponse([])
        
        # TextGrid íŒŒì‹± (ê¸°ì¡´ ì •ê·œì‹ ë¡œì§ ì¬ì‚¬ìš©)
        syllables = []
        try:
            # UTF-16 ì¸ì½”ë”©ìœ¼ë¡œ TextGrid íŒŒì¼ ì½ê¸°
            encodings_to_try = ['utf-16', 'utf-16-le', 'utf-16-be', 'utf-8', 'cp949']
            content = None
            
            for encoding in encodings_to_try:
                try:
                    with open(tg_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    print(f"âœ… TextGrid íŒŒì¼ ì½ê¸° ì„±ê³µ: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print(f"âŒ TextGrid íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {tg_path}")
                return JSONResponse([])
                
            # ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ìŒì ˆ êµ¬ê°„ ì¶”ì¶œ
            import re
            interval_pattern = r'intervals\s*\[\s*(\d+)\s*\]:\s*\n\s*xmin\s*=\s*([0-9.]+)\s*\n\s*xmax\s*=\s*([0-9.]+)\s*\n\s*text\s*=\s*"([^"]*)"'
            
            matches = re.findall(interval_pattern, content, re.MULTILINE)
            print(f"ğŸ¯ ì •ê·œì‹ ë§¤ì¹­ ê²°ê³¼: {len(matches)}ê°œ êµ¬ê°„ ë°œê²¬")
            
            for i, (index, xmin, xmax, text) in enumerate(matches):
                if text.strip() and text.strip().lower() not in ['', 'sp', 'sil', '<p:>', 'p']:
                    syllables.append({
                        "label": text.strip(),
                        "start": float(xmin),
                        "end": float(xmax),
                        "duration": float(xmax) - float(xmin)
                    })
                    print(f"  ğŸ¯ ìŒì ˆ {i+1}: '{text}' ({xmin}s-{xmax}s)")
                    
        except Exception as e:
            print(f"ğŸš¨ TextGrid íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return JSONResponse([])
        
        if not syllables:
            print(f"ğŸ¯ No syllables found in TextGrid")
            return JSONResponse([])
        
        # í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
        times = pitch.xs()
        valid_points = []
        for t in times:
            f0 = pitch.get_value_at_time(t)
            if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                valid_points.append((float(t), float(f0)))
        
        print(f"ğŸ¯ Processing {len(syllables)} syllables with {len(valid_points)} pitch points")
        
        syllable_pitch_points = []
        
        # ê° ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚°
        for syl in syllables:
            start_t = syl['start']
            end_t = syl['end'] 
            center_t = (start_t + end_t) / 2
            label = syl['label']
            
            # ìŒì ˆ êµ¬ê°„ ë‚´ í”¼ì¹˜ ë°ì´í„° ì°¾ê¸°
            syllable_data = [(t, f0) for t, f0 in valid_points 
                           if start_t <= t <= end_t]
            
            if len(syllable_data) >= 2:
                # ì¤‘ì•™ê°’ ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
                pitches = [f0 for t, f0 in syllable_data]
                representative_f0 = float(np.median(pitches))
                print(f"  ğŸ¯ '{label}': {len(syllable_data)}ê°œ â†’ {representative_f0:.1f}Hz")
            elif len(syllable_data) == 1:
                representative_f0 = syllable_data[0][1]
                print(f"  ğŸ¯ '{label}': 1ê°œ â†’ {representative_f0:.1f}Hz")
            else:
                # ê°€ì¥ ê°€ê¹Œìš´ í”¼ì¹˜ í¬ì¸íŠ¸ ì‚¬ìš©
                if valid_points:
                    distances = [(abs(t - center_t), f0) for t, f0 in valid_points]
                    distances.sort()
                    representative_f0 = distances[0][1] if distances else 200.0
                    print(f"  ğŸ¯ '{label}': ìµœê·¼ì ‘ â†’ {representative_f0:.1f}Hz")
                else:
                    representative_f0 = 200.0
                    print(f"  ğŸ¯ '{label}': ê¸°ë³¸ê°’ â†’ {representative_f0:.1f}Hz")
            
            syllable_pitch_points.append({
                "time": float(center_t),  # ìŒì ˆ ì¤‘ì‹¬ ì‹œê°„
                "frequency": representative_f0,
                "syllable": label
            })
        
        print(f"ğŸ¯ Returning {len(syllable_pitch_points)} syllable representative points")
        return JSONResponse(syllable_pitch_points)
        
    except Exception as e:
        print(f"âŒ Syllable pitch calculation error: {e}")
        return JSONResponse([])

@app.get("/api/reference_files/{file_id}/textgrid")
async def get_reference_textgrid(file_id: str):
    """ì €ì¥ëœ TextGrid íŒŒì¼ ë‹¤ìš´ë¡œë“œ - íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜"""
    try:
        tg_path = f"static/reference_files/{file_id}.TextGrid"
        if not os.path.exists(tg_path):
            raise HTTPException(status_code=404, detail="TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ¯ Serving TextGrid file: {tg_path}")
        return FileResponse(tg_path, media_type="text/plain", filename=f"{file_id}.TextGrid")
        
    except Exception as e:
        print(f"Get reference TextGrid error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/syllable_pitch_analysis")
async def get_syllable_pitch_analysis():
    """ëª¨ë“  ì°¸ì¡° íŒŒì¼ì˜ ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ë¥¼ ë‚¨ì„±/ì—¬ì„± ë²„ì „ìœ¼ë¡œ ì¶”ì¶œ"""
    try:
        reference_dir = "static/reference_files"
        if not os.path.exists(reference_dir):
            return JSONResponse({"analysis": []})
        
        analysis_results = []
        
        # ëª¨ë“  WAV íŒŒì¼ì— ëŒ€í•´ ë¶„ì„
        for filename in os.listdir(reference_dir):
            if filename.endswith('.wav'):
                base_name = filename[:-4]
                textgrid_file = base_name + '.TextGrid'
                wav_path = os.path.join(reference_dir, filename)
                tg_path = os.path.join(reference_dir, textgrid_file)
                
                if os.path.exists(tg_path):
                    print(f"ğŸ¯ ìŒì ˆ í”¼ì¹˜ ë¶„ì„: {base_name}")
                    
                    # ë‚¨ì„±/ì—¬ì„± ë²„ì „ìœ¼ë¡œ ê°ê° ë¶„ì„ (Sound ê°ì²´ ìƒì„± í•„ìš”)
                    male_sound = pm.Sound(wav_path)
                    male_tg = pm.read(tg_path)
                    male_analysis = extract_ref_praat_implementation(
                        male_sound, male_tg, 75.0, 300.0, 0.01
                    )
                    
                    female_sound = pm.Sound(wav_path)
                    female_tg = pm.read(tg_path)
                    female_analysis = extract_ref_praat_implementation(
                        female_sound, female_tg, 100.0, 600.0, 0.01
                    )
                    
                    # ì°¸ì¡° ìŒì„± ì„±ë³„ ê°ì§€
                    ref_gender = detect_reference_gender(male_analysis['stats']['meanF0'])
                    
                    # ì„±ë³„ë³„ ì •ê·œí™” ì ìš©
                    male_normalized = apply_gender_normalization(
                        male_analysis, target_gender=ref_gender, learner_gender="male"
                    )
                    
                    female_normalized = apply_gender_normalization(
                        female_analysis, target_gender=ref_gender, learner_gender="female"
                    )
                    
                    # ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ ì¶”ì¶œ
                    male_syllables = []
                    female_syllables = []
                    
                    if 'syllable_analysis' in male_normalized:
                        for syl in male_normalized['syllable_analysis']:
                            male_syllables.append({
                                'label': syl['label'],
                                'start_time': syl['start_time'],
                                'end_time': syl['end_time'],
                                'duration': syl['duration'],
                                'f0_hz': syl['f0'],
                                'semitone': syl['semitone'],
                                'center_time': syl['center_time']
                            })
                    
                    if 'syllable_analysis' in female_normalized:
                        for syl in female_normalized['syllable_analysis']:
                            female_syllables.append({
                                'label': syl['label'],
                                'start_time': syl['start_time'],
                                'end_time': syl['end_time'],
                                'duration': syl['duration'],
                                'f0_hz': syl['f0'],
                                'semitone': syl['semitone'],
                                'center_time': syl['center_time']
                            })
                    
                    analysis_results.append({
                        'sentence_id': base_name,
                        'reference_gender': ref_gender,
                        'duration': male_analysis['stats']['duration'],
                        'male_version': {
                            'base_frequency': 120.0,  # ë‚¨ì„± ê¸°ì¤€ ì£¼íŒŒìˆ˜
                            'syllables': male_syllables
                        },
                        'female_version': {
                            'base_frequency': 220.0,  # ì—¬ì„± ê¸°ì¤€ ì£¼íŒŒìˆ˜
                            'syllables': female_syllables
                        }
                    })
                    
                    print(f"   âœ… {base_name}: {len(male_syllables)}ê°œ ìŒì ˆ, ì°¸ì¡°ì„±ë³„={ref_gender}")
        
        print(f"ğŸ¯ ì „ì²´ ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ ë¬¸ì¥")
        return JSONResponse({"analysis": analysis_results})
        
    except Exception as e:
        print(f"Syllable pitch analysis error: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.delete("/api/reference_files/{file_id}")
async def delete_reference_file(file_id: int, db: Session = Depends(get_db)):
    """ì €ì¥ëœ ì°¸ì¡° íŒŒì¼ ì‚­ì œ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ
        ref_file = db.query(ReferenceFile).filter(ReferenceFile.id == file_id).first()
        if not ref_file:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ íŒŒì¼ë“¤ ì‚­ì œ
        wav_path = UPLOAD_DIR / ref_file.wav_filename
        textgrid_path = UPLOAD_DIR / ref_file.textgrid_filename
        
        # WAV íŒŒì¼ ì‚­ì œ
        if wav_path.exists():
            wav_path.unlink()
            print(f"ğŸ—‘ï¸ Deleted WAV file: {wav_path}")
        else:
            print(f"âš ï¸ WAV file not found: {wav_path}")
        
        # TextGrid íŒŒì¼ ì‚­ì œ
        if textgrid_path.exists():
            textgrid_path.unlink()
            print(f"ğŸ—‘ï¸ Deleted TextGrid file: {textgrid_path}")
        else:
            print(f"âš ï¸ TextGrid file not found: {textgrid_path}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë ˆì½”ë“œ ì‚­ì œ
        db.delete(ref_file)
        db.commit()
        
        print(f"ğŸ—‘ï¸ Successfully deleted reference file {file_id}: {ref_file.title}")
        
        return JSONResponse({
            "status": "success", 
            "message": f"ì°¸ì¡° íŒŒì¼ '{ref_file.title}'ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
        
    except Exception as e:
        db.rollback()
        print(f"Delete reference file error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze_live_audio")
async def analyze_live_audio(audio: UploadFile = File(...)):
    """ğŸ¯ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Praat ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì •í™•í•œ í”¼ì¹˜ ë°ì´í„° ë°˜í™˜"""
    try:
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
        audio_data = await audio.read()
        
        # WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        audio_array = np.frombuffer(audio_data, dtype=np.float32)
        
        # ğŸ¯ Parselmouth(Praat) ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì •ë°€ í”¼ì¹˜ ë¶„ì„
        try:
            import soundfile as sf
        except ImportError:
            print("ğŸš¨ soundfile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            raise HTTPException(status_code=500, detail="soundfile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Parselmouthë¡œ ë¶„ì„
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            # NumPy ë°°ì—´ì„ WAV íŒŒì¼ë¡œ ì €ì¥ (16kHz ìƒ˜í”Œë§)
            sf.write(tmp_file.name, audio_array, 16000)
            
            # ğŸ¯ Praat ê³ ì •ë°€ í”¼ì¹˜ ë¶„ì„ ì„¤ì •
            sound = pm.Sound(tmp_file.name)
            pitch = sound.to_pitch(
                time_step=0.01,      # 10ms ê°„ê²©ìœ¼ë¡œ ë¶„ì„
                pitch_floor=75.0,    # ìµœì†Œ 75Hz (ë‚¨ì„± ì €ìŒ)
                pitch_ceiling=500.0, # ìµœëŒ€ 500Hz (ì—¬ì„± ê³ ìŒ)
                max_number_of_candidates=15,  # ì •í™•ë„ í–¥ìƒ
                silence_threshold=0.03,
                voicing_threshold=0.45,
                octave_cost=0.01,
                octave_jump_cost=0.35,
                voiced_unvoiced_cost=0.14
            )
            
            # ğŸ¯ í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ (Praat ê³ ì •ë°€ ë¶„ì„ ê²°ê³¼)
            pitch_values = []
            times = pitch.xs()
            
            for i, time in enumerate(times):
                f0 = pitch.get_value_at_time(time)
                if not np.isnan(f0) and f0 > 0:
                    pitch_values.append({
                        "time": float(time),
                        "f0": float(f0),
                        "semitone": float(12 * np.log2(f0 / 200)) if f0 > 0 else 0
                    })
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_file.name)
            
        print(f"ğŸ¯ Praat ë¶„ì„ ì™„ë£Œ: {len(pitch_values)}ê°œ í”¼ì¹˜ í¬ì¸íŠ¸ ì¶”ì¶œ")
        return {"success": True, "pitch_data": pitch_values}
        
    except Exception as e:
        print(f"ğŸ”¥ ì‹¤ì‹œê°„ Praat ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

# Flask-style routes for survey
@app.get("/survey", response_class=HTMLResponse)
async def survey_page(request: Request):
    """Survey selection page"""
    return templates.TemplateResponse("survey.html", {"request": request})

@app.get("/", response_class=HTMLResponse)
async def main_page(request: Request):
    """Main prosody analysis interface"""
    return templates.TemplateResponse("index.html", {"request": request})

# ğŸ¯ ìƒˆë¡œìš´ syllables API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/api/reference_files/{file_id}/syllables")
async def get_reference_file_syllables(file_id: str, db: Session = Depends(get_db)):
    """ğŸ¯ í•µì‹¬ ê¸°ëŠ¥: TextGrid íŒŒì¼ì—ì„œ ì‹¤ì œ ìŒì ˆ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # ğŸ¯ íŒŒì¼ëª…ìœ¼ë¡œ ì§ì ‘ TextGrid íŒŒì¼ ì°¾ê¸° (ë°ì´í„°ë² ì´ìŠ¤ ì˜ì¡´ì„± ì œê±°)
        reference_dir = "static/reference_files"
        textgrid_path = os.path.join(reference_dir, f"{file_id}.TextGrid")
        
        print(f"ğŸ¯ Looking for TextGrid: {textgrid_path}")
        
        if not os.path.exists(textgrid_path):
            print(f"ğŸš¨ TextGrid file not found: {textgrid_path}")
            return []
        
        # ğŸ¯ TextGrid íŒŒì¼ì—ì„œ ìŒì ˆ êµ¬ê°„ ì¶”ì¶œ - ì˜¤ë¦¬ì§€ë„ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        syllables = []
        try:
            # ğŸ¯ UTF-16 ì¸ì½”ë”©ìœ¼ë¡œ TextGrid íŒŒì¼ ì½ê¸° (Praat í‘œì¤€)
            encodings_to_try = ['utf-16', 'utf-16-le', 'utf-16-be', 'utf-8', 'cp949']
            content = None
            
            for encoding in encodings_to_try:
                try:
                    with open(textgrid_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    print(f"âœ… TextGrid íŒŒì¼ ì½ê¸° ì„±ê³µ: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print(f"âŒ TextGrid íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {textgrid_path}")
                return []
                
            # ğŸ¯ ì˜¤ë¦¬ì§€ë„ ì •ê·œì‹ íŒ¨í„´ ì‚¬ìš© (ToneBridge_Implementation_Guide.md)
            import re
            interval_pattern = r'intervals\s*\[\s*(\d+)\s*\]:\s*\n\s*xmin\s*=\s*([0-9.]+)\s*\n\s*xmax\s*=\s*([0-9.]+)\s*\n\s*text\s*=\s*"([^"]*)"'
            
            matches = re.findall(interval_pattern, content, re.MULTILINE)
            print(f"ğŸ¯ ì •ê·œì‹ ë§¤ì¹­ ê²°ê³¼: {len(matches)}ê°œ êµ¬ê°„ ë°œê²¬")
            
            for i, (index, xmin, xmax, text) in enumerate(matches):
                if text.strip() and text.strip().lower() not in ['', 'sp', 'sil', '<p:>', 'p']:  # ë¹ˆ í…ìŠ¤íŠ¸ì™€ ì¹¨ë¬µ êµ¬ê°„ ì œì™¸
                    syllable_data = {
                        "label": text.strip(),
                        "start": float(xmin),
                        "end": float(xmax),
                        "duration": float(xmax) - float(xmin)
                    }
                    syllables.append(syllable_data)
                    print(f"  ğŸ¯ ìŒì ˆ {i+1}: '{text}' ({xmin}s-{xmax}s)")
            
        except Exception as e:
            print(f"ğŸš¨ TextGrid íŒŒì‹± ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
            # Fallback: íŒŒì¼ ë‚´ìš© ìƒ˜í”Œ ì¶œë ¥ìœ¼ë¡œ ë””ë²„ê¹…
            try:
                with open(textgrid_path, 'rb') as f:
                    raw_content = f.read(100)
                print(f"ğŸ” íŒŒì¼ ì‹œì‘ ë°”ì´íŠ¸: {raw_content}")
            except:
                pass
            
        # ğŸ¯ íŒŒì¼ë³„ ê¸°ë³¸ ìŒì ˆ ì •ë³´ (TextGridê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ëŒ€ë¹„)
        if not syllables:
            print(f"ğŸ¯ Using default syllables for {file_id}")
            if file_id == "ë°˜ê°‘ìŠµë‹ˆë‹¤":
                syllables = [
                    {"label": "ë°˜", "start": 0.0, "end": 0.4},
                    {"label": "ê°‘", "start": 0.4, "end": 0.8},
                    {"label": "ìŠµ", "start": 0.8, "end": 1.1},
                    {"label": "ë‹ˆ", "start": 1.1, "end": 1.3},
                    {"label": "ë‹¤", "start": 1.3, "end": 1.4}
                ]
            elif file_id == "ì•ˆë…•í•˜ì„¸ìš”":
                syllables = [
                    {"label": "ì•ˆ", "start": 0.0, "end": 0.2},
                    {"label": "ë…•", "start": 0.2, "end": 0.4},
                    {"label": "í•˜", "start": 0.4, "end": 0.6},
                    {"label": "ì„¸", "start": 0.6, "end": 0.9},
                    {"label": "ìš”", "start": 0.9, "end": 1.1}
                ]
            else:
                # ê¸°ë³¸ ë”ë¯¸ ë°ì´í„°
                syllables = [{"label": "ìŒì ˆ", "start": 0.0, "end": 1.0}]
        
        print(f"ğŸ¯ Returning {len(syllables)} syllables for {file_id}: {[s['label'] for s in syllables]}")
        return syllables
        
    except Exception as e:
        print(f"ğŸš¨ Error in get_reference_file_syllables: {e}")
        return []

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)