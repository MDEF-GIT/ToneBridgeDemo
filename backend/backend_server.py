"""
ToneBridge FastAPI backend - PRAAT ALGORITHM IMPLEMENTATION
Implements authentic Praat pitch extraction with real-time analysis
"""
import io
import os
import sys
import tempfile
import subprocess
import shutil
import uuid
import math
import re
from pathlib import Path
from datetime import datetime
from typing import List, Optional

import numpy as np
from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from models import ReferenceFile, Base

try:
    import parselmouth as pm
    print("ğŸ¯ Parselmouth (Praat Python) imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import parselmouth: {e}")
    sys.exit(1)

# Import our enhanced automation systems
from audio_enhancement import AutomatedProcessor
from advanced_stt_processor import AdvancedSTTProcessor
from audio_analysis import (
    STTBasedSegmenter, 
    split_korean_sentence,
    analyze_audio_file,
    create_textgrid_from_audio,
    SyllableSegment
)

# ğŸš€ Import Ultimate STT System
try:
    from ultimate_stt_system import UltimateSTTSystem
    ULTIMATE_STT_AVAILABLE = True
    print("âœ… Ultimate STT System ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ Ultimate STT System ë¡œë“œ ì‹¤íŒ¨: {e}")
    ULTIMATE_STT_AVAILABLE = False

# ğŸš€ Import Korean Audio Optimizer
try:
    from korean_audio_optimizer import KoreanAudioOptimizer
    KOREAN_OPTIMIZER_AVAILABLE = True
    print("âœ… Korean Audio Optimizer ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ Korean Audio Optimizer ë¡œë“œ ì‹¤íŒ¨: {e}")
    KOREAN_OPTIMIZER_AVAILABLE = False

app = FastAPI(title="ToneBridge Praat Analysis API")

# ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜: ë°±ì—”ë“œëŠ” ìˆœìˆ˜ APIë§Œ ì œê³µ
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# Database setup
DATABASE_URL = os.environ.get("DATABASE_URL", "sqlite:///tonebridge.db")
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create tables
Base.metadata.create_all(bind=engine)

# File upload directory
UPLOAD_DIR = Path("static/uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸš€ ì „ì—­ AI ì¸ìŠ¤í„´ìŠ¤ë“¤ (ì„œë²„ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ë¡œë“œ)
print("ğŸ¯ ToneBridge AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
global_ai_instances = {}

# STT í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
try:
    print("ğŸ¤ ê³ ê¸‰ STT í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì¤‘...")
    global_ai_instances['advanced_stt'] = AdvancedSTTProcessor()
    print("âœ… ê³ ê¸‰ STT í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ê³ ê¸‰ STT ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    global_ai_instances['advanced_stt'] = None

# Ultimate STT ì‹œìŠ¤í…œ (ì§€ì—° ë¡œë”© - ì²« ì‚¬ìš© ì‹œì—ë§Œ ì´ˆê¸°í™”)
if ULTIMATE_STT_AVAILABLE:
    global_ai_instances['ultimate_stt'] = None  # ì§€ì—° ë¡œë”©
    print("âš¡ Ultimate STT ì‹œìŠ¤í…œ: ì§€ì—° ë¡œë”© ì„¤ì • (ì²« ì‚¬ìš© ì‹œ ìë™ ì´ˆê¸°í™”)")
else:
    global_ai_instances['ultimate_stt'] = None

# Korean Audio Optimizer ì´ˆê¸°í™”
if KOREAN_OPTIMIZER_AVAILABLE:
    try:
        print("ğŸ‡°ğŸ‡· Korean Audio Optimizer ì´ˆê¸°í™” ì¤‘...")
        global_ai_instances['korean_optimizer'] = KoreanAudioOptimizer()
        print("âœ… Korean Audio Optimizer ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ Korean Optimizer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        global_ai_instances['korean_optimizer'] = None
else:
    global_ai_instances['korean_optimizer'] = None

print("ğŸ¯ ToneBridge AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
print(f"   í™œì„± ì‹œìŠ¤í…œ: {list(global_ai_instances.keys())}")

# ë®¤í…ìŠ¤ (ìˆœì„œ ë³´ì¥ìš©)
import asyncio
ai_processing_lock = asyncio.Lock()

# Pydantic models
class RefPoint(BaseModel):
    t: float
    f0: float
    dB: float
    semitone: float

class Syllable(BaseModel):
    label: str
    start: float
    end: float

class SyllableAnalysis(BaseModel):
    label: str  # 'syllable' â†’ 'label'
    start: float
    end: float
    duration: float  # str â†’ float
    f0: float  # 'pitch_mean' â†’ 'f0'
    semitone: float
    qtone: float
    intensity: float  # str â†’ float

class RefAnalysis(BaseModel):
    curve: List[RefPoint]
    syllables: List[Syllable]
    syllable_analysis: List[SyllableAnalysis]
    stats: dict

def split_korean_sentence(sentence: str) -> List[str]:
    """Split Korean sentence into individual syllables"""
    return [char for char in sentence.strip() if char.strip()]

# ì •ë°€ ìŒì ˆ ë¶„ì ˆ ê¸°ëŠ¥ì€ audio_analysis.py ëª¨ë“ˆë¡œ ì´ë™ë¨

def auto_segment_syllables(sound: pm.Sound, sentence: str) -> List[dict]:
    """
    ìë™ ìŒì ˆ ë¶„ì ˆ ê¸°ëŠ¥ - Parselmouth ê¸°ë°˜ ìŒì„± ë¶„ì„
    ìŒì„±ì—ì„œ ìë™ìœ¼ë¡œ ìŒì ˆ ê²½ê³„ë¥¼ íƒì§€í•˜ê³  TextGrid ìƒì„±
    """
    print("ğŸ¤–ğŸ¤–ğŸ¤– ìë™ ìŒì ˆ ë¶„ì ˆ ì‹œì‘ ğŸ¤–ğŸ¤–ğŸ¤–")
    
    if not sentence or not sentence.strip():
        print("âŒ ë¬¸ì¥ ì •ë³´ê°€ ì—†ì–´ ìë™ ë¶„ì ˆ ë¶ˆê°€")
        return []
    
    # í•œêµ­ì–´ ìŒì ˆë¡œ ë¶„ë¦¬
    syllables_text = split_korean_sentence(sentence)
    print(f"ğŸ¯ ëª©í‘œ ìŒì ˆ: {syllables_text} ({len(syllables_text)}ê°œ)")
    
    try:
        # Step 1: Intensity ê¸°ë°˜ ìŒì„± í™œë™ êµ¬ê°„ íƒì§€
        intensity = sound.to_intensity(minimum_pitch=75.0)
        
        # Step 2: ë¬´ìŒ êµ¬ê°„ íƒì§€ë¡œ ëŒ€ëµì ì¸ ê²½ê³„ ì°¾ê¸°
        # í‰ê·  intensityì˜ 20% ì´í•˜ë¥¼ ë¬´ìŒìœ¼ë¡œ íŒì •
        mean_intensity = intensity.values.mean()
        silence_threshold = mean_intensity * 0.2
        
        print(f"ğŸ¯ í‰ê·  ê°•ë„: {mean_intensity:.2f}dB, ë¬´ìŒ ì„ê³„ê°’: {silence_threshold:.2f}dB")
        
        # Step 3: ì •ë°€í•œ ìŒì„±í•™ì  ë¶„ì ˆ ì•Œê³ ë¦¬ì¦˜ ì ìš©
        duration = sound.xmax - sound.xmin
        
        print(f"ğŸ¯ ìŒì„± ê¸¸ì´: {duration:.3f}ì´ˆ")
        print(f"ğŸ¯ ëª©í‘œ: {len(syllables_text)}ê°œ ìŒì ˆ - {syllables_text}")
        
        # Step 4: STT ê¸°ë°˜ ì •ë°€ ë¶„ì ˆ (ìƒˆ ëª¨ë“ˆ ì‚¬ìš©) - í†µí•© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
        from tonebridge_core.segmentation.korean_segmenter import KoreanSyllableSegmenter
        segmenter = KoreanSyllableSegmenter()
        
        # ì„ì‹œ íŒŒì¼ ìƒì„± (Parselmouth Sound ê°ì²´ë¡œë¶€í„°)
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            temp_path = tmp_file.name
            sound.save(temp_path, "WAV")
        
        segment_results = segmenter.segment(temp_path, sentence)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        import os
        os.unlink(temp_path)
        
        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        syllables = []
        for segment in segment_results:
            syllables.append({
                'label': segment.label,
                'start': segment.start,
                'end': segment.end
            })
        
        for i, syl in enumerate(syllables):
            print(f"   ğŸ¯ '{syl['label']}': {syl['start']:.3f}s ~ {syl['end']:.3f}s")
        
        print(f"âœ… ìë™ ìŒì ˆ ë¶„ì ˆ ì™„ë£Œ: {len(syllables)}ê°œ")
        return syllables
        
    except Exception as e:
        print(f"âŒ ìë™ ë¶„ì ˆ ì‹¤íŒ¨: {e}")
        return []

def save_textgrid(syllables: List[dict], output_path: str, total_duration: float):
    """
    ìŒì ˆ ì •ë³´ë¥¼ TextGrid íŒŒì¼ë¡œ ì €ì¥
    """
    print(f"ğŸ’¾ TextGrid ì €ì¥: {output_path}")
    
    try:
        # ğŸš€ í†µí•© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•˜ì—¬ TextGrid ìƒì„±
        from tonebridge_core.textgrid.generator import UnifiedTextGridGenerator
        from tonebridge_core.models import SyllableSegment
        
        # ê¸°ì¡´ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì„ SyllableSegmentë¡œ ë³€í™˜
        segments = []
        for syl in syllables:
            if isinstance(syl, dict):
                segments.append(SyllableSegment(
                    label=syl.get('label', syl.get('syllable', '')),
                    start=syl.get('start', 0.0),
                    end=syl.get('end', 0.0),
                    confidence=syl.get('confidence', 0.8)
                ))
        
        # í†µí•© ìƒì„±ê¸°ë¡œ TextGrid ìƒì„±
        generator = UnifiedTextGridGenerator()
        textgrid_content = generator.from_syllables(segments, total_duration)
        
        # UTF-16ìœ¼ë¡œ ì €ì¥ (ê¸°ì¡´ TextGridì™€ ë™ì¼í•œ ì¸ì½”ë”©)
        with open(output_path, 'w', encoding='utf-16') as f:
            f.write(textgrid_content)
        
        print(f"âœ… TextGrid ì €ì¥ ì™„ë£Œ: {len(syllables)}ê°œ ìŒì ˆ")
        return True
        
    except Exception as e:
        print(f"âŒ TextGrid ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def adjust_textgrid_timing(syllables: List[dict]) -> List[dict]:
    """
    TextGrid ì‹œê°„ ì •ë³´ ìë™ ë³´ì • - ë¬´ìŒ êµ¬ê°„ ì œê±° ëŒ€ì‘
    ì²« ë²ˆì§¸ ìŒì ˆì˜ ì‹œì‘ ì‹œê°„ì„ 0ìœ¼ë¡œ ë§ì¶°ì„œ ì „ì²´ ì‹œê°„ ì¡°ì •
    """
    if not syllables:
        return syllables
    
    # ì²« ë²ˆì§¸ ìŒì ˆì˜ ì‹œì‘ ì‹œê°„ í™•ì¸
    first_start = syllables[0]['start']
    
    if first_start > 0.1:  # 0.1ì´ˆ ì´ìƒì˜ ì§€ì—°ì´ ìˆìœ¼ë©´ ë³´ì •
        print(f"ğŸ”§ğŸ”§ğŸ”§ TextGrid ì‹œê°„ ë³´ì •: {first_start:.3f}ì´ˆë§Œí¼ ì•ë‹¹ê¹€")
        
        # ëª¨ë“  ìŒì ˆì˜ ì‹œê°„ì„ ì•ë‹¹ê¹€
        for syllable in syllables:
            syllable['start'] -= first_start
            syllable['end'] -= first_start
            
        print(f"ğŸ”§ ë³´ì • ì™„ë£Œ: ì²« ìŒì ˆì´ {syllables[0]['start']:.3f}ì´ˆë¶€í„° ì‹œì‘")
    
    return syllables

def praat_script_textgrid_parser(tg: pm.TextGrid) -> List[dict]:
    """
    Praat Call ê¸°ë°˜ TextGrid parser - í‘œì¤€ Parselmouth ë°©ì‹
    """
    print("ğŸ¯ğŸ¯ğŸ¯ PRAAT CALL TEXTGRID PARSER ì‹œì‘ ğŸ¯ğŸ¯ğŸ¯")
    
    if not tg:
        print("âŒ TextGrid object is None")
        return []
    
    try:
        from parselmouth.praat import call
        
        # Praat callë¡œ tier ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        n_tiers = call(tg, "Get number of tiers")
        print(f"ğŸ¯ Found {n_tiers} tiers via Praat call")
        
        # ëª¨ë“  tierì—ì„œ interval ìˆ˜ì§‘
        table_rows = []
        
        for tier_num in range(1, n_tiers + 1):  # Praatì€ 1-based indexing
            try:
                tier_name = call(tg, "Get tier name", tier_num)
                is_interval_tier = call(tg, "Is interval tier", tier_num)
                
                print(f"ğŸ¯ Tier {tier_num}: '{tier_name}' (interval={is_interval_tier})")
                
                if is_interval_tier:
                    n_intervals = call(tg, "Get number of intervals", tier_num)
                    print(f"    ğŸ¯ Found {n_intervals} intervals")
                    
                    for interval_num in range(1, n_intervals + 1):  # 1-based
                        start_time = call(tg, "Get starting point", tier_num, interval_num)
                        end_time = call(tg, "Get end point", tier_num, interval_num)
                        label = call(tg, "Get label of interval", tier_num, interval_num).strip()
                        
                        if label:  # ë¹ˆ ë¼ë²¨ ì œì™¸
                            table_rows.append({
                                "tier": tier_name.lower(),
                                "tier_idx": tier_num - 1,  # 0-basedë¡œ ë³€í™˜
                                "text": label,
                                "tmin": float(start_time),
                                "tmax": float(end_time),
                                "duration": float(end_time - start_time)
                            })
                            print(f"      ğŸ¯ Interval {interval_num}: '{label}' ({start_time:.3f}s-{end_time:.3f}s)")
                
            except Exception as e:
                print(f"âŒ Error processing tier {tier_num}: {e}")
                continue
        
        print(f"ğŸ¯ Table created with {len(table_rows)} rows")
        
        # ìŒì ˆ tier ì°¾ê¸° (ìˆ«ì tierë„ í¬í•¨)
        target_tier_names = ["syllable", "syllables", "ìŒì ˆ", "syl", "word", "words", "phones", "phone", "1", "2", "3", "intervals", "segment", "segments", "tier", "tier1", "tier2", "tier3"]
        extracted_rows = []
        
        for tier_name in target_tier_names:
            matches = [row for row in table_rows 
                      if row["tier"] == tier_name and row["text"] and row["duration"] > 0.001]
            if matches:
                extracted_rows = matches
                print(f"ğŸ¯âœ… Found {len(matches)} syllables in tier '{tier_name}'")
                break
        
        # íŠ¹ì • tierë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ê°€ì¥ ë§ì€ intervalì„ ê°€ì§„ tier ì‚¬ìš©
        if not extracted_rows and table_rows:
            tier_counts = {}
            for row in table_rows:
                if row["text"] and row["duration"] > 0.001:
                    tier_name = row["tier"]
                    tier_counts[tier_name] = tier_counts.get(tier_name, 0) + 1
            
            if tier_counts:
                best_tier = max(tier_counts.keys(), key=lambda k: tier_counts[k])
                extracted_rows = [row for row in table_rows 
                                if row["tier"] == best_tier and row["text"] and row["duration"] > 0.001]
                print(f"ğŸ¯âœ… Using tier with most intervals: '{best_tier}' ({len(extracted_rows)} syllables)")
        
        # ğŸš¨ CRITICAL FIX: ì—¬ì „íˆ ìŒì ˆì´ ì—†ìœ¼ë©´ ëª¨ë“  tierì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ê°•ì œë¡œ ì‚¬ìš©
        if not extracted_rows and table_rows:
            print("ğŸ¯ğŸš¨ FALLBACK: ëª¨ë“  tier ë°ì´í„°ë¥¼ ìŒì ˆë¡œ ê°•ì œ ì‚¬ìš©")
            extracted_rows = [row for row in table_rows if row["text"] and row["duration"] > 0.001]
            extracted_rows.sort(key=lambda x: x["tmin"])  # ì‹œê°„ìˆœ ì •ë ¬
            print(f"ğŸ¯âœ… Forced extraction: {len(extracted_rows)} syllables from all tiers")
        
        # ìŒì ˆì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        if not extracted_rows:
            print("ğŸ¯âŒ COMPLETE FAILURE: No syllable data found at all")
            return []
        
        # ì‹œê°„ìˆœ ì •ë ¬
        extracted_rows.sort(key=lambda x: x["tmin"])
        
        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        syllables = []
        for row in extracted_rows:
            syllables.append({
                "label": row["text"],
                "start": row["tmin"],
                "end": row["tmax"]
            })
        
        print(f"ğŸ¯âœ… Successfully parsed {len(syllables)} syllables from TextGrid")
        for syl in syllables:
            print(f"    - '{syl['label']}': {syl['start']:.3f}s-{syl['end']:.3f}s")
        
        # ğŸ”§ ì‹œê°„ ë³´ì • ì ìš©
        print(f"ğŸ”§ ë³´ì • ì „ ì²« ìŒì ˆ: {syllables[0]['start']:.3f}ì´ˆ")
        syllables = adjust_textgrid_timing(syllables)
        print(f"ğŸ”§ ë³´ì • í›„ ì²« ìŒì ˆ: {syllables[0]['start']:.3f}ì´ˆ")
        
        return syllables
        
    except Exception as e:
        print(f"âŒ Praat call parsing failed: {e}")
        return []

def apply_gender_normalization(analysis_result: dict, target_gender: str, learner_gender: str) -> dict:
    """
    í•™ìŠµì ì„±ë³„ì— ë”°ë¼ ì°¸ì¡° ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # ì„±ë³„ë³„ í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ (Hz) - ì—°êµ¬ ê¸°ë°˜ ë°ì´í„°
        gender_f0_base = {
            "male": 120.0,    # ë‚¨ì„± í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜
            "female": 220.0   # ì—¬ì„± í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜
        }
        
        if target_gender == "auto":
            target_gender = "female"  # autoì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            print(f"ğŸ¯ ì°¸ì¡° ì„±ë³„ì„ ìë™ìœ¼ë¡œ femaleë¡œ ì„¤ì •")
            
        if target_gender not in gender_f0_base or learner_gender not in gender_f0_base:
            print(f"ğŸ¯ ì •ê·œí™” ìƒëµ: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„±ë³„ ({target_gender} -> {learner_gender})")
            return analysis_result
        
        # ì •ê·œí™” ë¹„ìœ¨ ê³„ì‚°
        source_base = gender_f0_base[target_gender]  # ì°¸ì¡° ìŒì„±ì˜ ì„±ë³„ ê¸°ì¤€
        target_base = gender_f0_base[learner_gender]  # í•™ìŠµì ì„±ë³„ ê¸°ì¤€
        normalization_ratio = target_base / source_base
        
        print(f"ğŸ¯ ì •ê·œí™” ë¹„ìœ¨: {source_base}Hz({target_gender}) -> {target_base}Hz({learner_gender}) = {normalization_ratio:.3f}")
        print(f"ğŸ¯ Semitone ê¸°ì¤€ ì£¼íŒŒìˆ˜: {target_base}Hz (í•™ìŠµì: {learner_gender})")
        print(f"ğŸ¯ ì»¨íˆ¬ì–´ ì¼ì¹˜ì„±: ëŒ€í‘œ í”¼ì¹˜ê°€ ì‹¤ì œ ê³¡ì„ ì—ì„œ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ë³´ì • ì ìš©")
        
        # ê³¡ì„  ë°ì´í„° ì •ê·œí™” (dict í˜•íƒœ ì²˜ë¦¬)
        normalized_curve = []
        for point in analysis_result.get('curve', []):
            if isinstance(point, dict):
                # dict í˜•íƒœì˜ í¬ì¸íŠ¸ (t, f0, dB, semitone)
                normalized_point = point.copy()
                if 'f0' in normalized_point:
                    normalized_f0 = normalized_point['f0'] * normalization_ratio
                    normalized_point['f0'] = normalized_f0
                    # semitone ì¬ê³„ì‚° (ì •ê·œí™”ëœ f0 ê¸°ì¤€)
                    if normalized_f0 > 0 and target_base > 0:
                        semitone_val = 12 * np.log2(normalized_f0 / target_base)
                        normalized_point['semitone'] = semitone_val
                        # ì²« ë²ˆì§¸ í¬ì¸íŠ¸ë§Œ ë””ë²„ê¹… ì¶œë ¥
                        if len(normalized_curve) == 0:
                            print(f"ğŸ¯ ì²« í¬ì¸íŠ¸ semitone ê³„ì‚°: f0={normalized_f0:.1f}Hz, base={target_base}Hz â†’ {semitone_val:.2f}st")
                    else:
                        normalized_point['semitone'] = 0.0
                normalized_curve.append(normalized_point)
            elif len(point) >= 2:
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ í¬ì¸íŠ¸ [time, freq]
                time_val = point[0]
                freq_val = point[1] * normalization_ratio
                normalized_curve.append([time_val, freq_val])
            else:
                normalized_curve.append(point)
        
        # ìŒì ˆ ë°ì´í„° ì •ê·œí™”
        normalized_syllables = []
        for syl in analysis_result.get('syllables', []):
            normalized_syl = syl.copy()
            
            # ğŸ¯ ëª¨ë“  í•™ìŠµìì—ê²Œ ì •ê·œí™”ëœ ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ í‘œì‹œ
            if True:  # ë‚¨ì„±/ì—¬ì„± ëª¨ë‘ ì •ê·œí™”ëœ ë°ì´í„° í‘œì‹œ
                # ğŸ¯ ëª¨ë“  ì„±ë³„ì—ê²Œ f0 ê´€ë ¨ í•„ë“œ ì •ê·œí™”
                f0_fields = ['f0', 'median_f0', 'representative_f0', 'center_f0']
                for field in f0_fields:
                    if field in normalized_syl and normalized_syl[field] is not None:
                        original_f0 = normalized_syl[field]
                        normalized_f0 = original_f0 * normalization_ratio
                        normalized_syl[field] = normalized_f0
                        
                        # ëŒ€í‘œ f0 í•„ë“œì˜ ê²½ìš° semitoneë„ ì—…ë°ì´íŠ¸ (ì„±ë³„ë³„ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ì ìš©)
                        if field == 'f0' and normalized_f0 > 0 and target_base > 0:
                            # ğŸ¯ ì„±ë³„ë³„ ìµœì í™”ëœ ê¸°ì¤€ ì£¼íŒŒìˆ˜
                            gender = analysis_result.get('gender', 'unknown')
                            semitone_base = 200 if gender == 'female' else 150  # ì—¬ì„± 200Hz, ë‚¨ì„± 150Hz
                            qtone_base = 130  # Q-toneì€ í‘œì¤€ 130Hz ìœ ì§€
                            
                            normalized_semitone = 12 * np.log2(normalized_f0 / semitone_base)
                            normalized_syl['semitone'] = normalized_semitone
                            # ğŸ¯ ì˜¬ë°”ë¥¸ Q-tone ê³µì‹: 5 * log2(f0/130)
                            normalized_syl['qtone'] = 5 * np.log2(normalized_f0 / qtone_base) if normalized_f0 > 0 else 0.0
                            normalized_syl['semitone_median'] = normalized_semitone  # í˜¸í™˜ì„±
                            
                            print(f"ğŸ¯ ìŒì ˆ '{normalized_syl.get('label', '?')}': {original_f0:.1f}Hz â†’ {normalized_f0:.1f}Hz ({normalized_semitone:.2f}st)")
                            
                            # ğŸ¯ CRITICAL DEBUG: ì •ê·œí™”ëœ syllable_analysisì—ë„ ë°˜ì˜í•´ì•¼í•¨!
                            if 'syllable_analysis' in analysis_result:
                                for syl_analysis in analysis_result['syllable_analysis']:
                                    if syl_analysis.get('label') == normalized_syl.get('label'):
                                        syl_analysis['f0'] = normalized_f0
                                        syl_analysis['semitone'] = normalized_semitone
                                        syl_analysis['semitone_median'] = normalized_semitone
                                        # ğŸ¯ ì˜¬ë°”ë¥¸ Q-tone ê³µì‹: 5 * log2(f0/130)  
                                        syl_analysis['qtone'] = 5 * np.log2(normalized_f0 / qtone_base) if normalized_f0 > 0 else 0.0
                                        print(f"ğŸ¯ syllable_analysis ì—…ë°ì´íŠ¸: {syl_analysis['label']} = {normalized_semitone:.2f}st")
                normalized_syl['show_syllable_pitch'] = True
                    
            # ë¹ˆ f0 í•„ë“œ ì²˜ë¦¬
            if 'f0' not in normalized_syl or normalized_syl['f0'] is None or normalized_syl['f0'] <= 0:
                normalized_syl['semitone'] = 0.0
                normalized_syl['qtone'] = 0.0
                normalized_syl['semitone_median'] = 0.0
                
            normalized_syllables.append(normalized_syl)
        
        # í†µê³„ ë°ì´í„° ì •ê·œí™”
        normalized_stats = analysis_result.get('stats', {}).copy()
        if 'mean_f0' in normalized_stats:
            normalized_stats['mean_f0'] = normalized_stats['mean_f0'] * normalization_ratio
        if 'median_f0' in normalized_stats:
            normalized_stats['median_f0'] = normalized_stats['median_f0'] * normalization_ratio
        if 'max_f0' in normalized_stats:
            normalized_stats['max_f0'] = normalized_stats['max_f0'] * normalization_ratio
        if 'min_f0' in normalized_stats:
            normalized_stats['min_f0'] = normalized_stats['min_f0'] * normalization_ratio
        
        # ì •ê·œí™”ëœ ê²°ê³¼ ë°˜í™˜
        normalized_result = analysis_result.copy()
        normalized_result['curve'] = normalized_curve
        normalized_result['syllables'] = normalized_syllables
        normalized_result['stats'] = normalized_stats
        
        print(f"ğŸ¯ ì •ê·œí™” ì™„ë£Œ: {len(normalized_curve)}ê°œ í¬ì¸íŠ¸, {len(normalized_syllables)}ê°œ ìŒì ˆ")
        return normalized_result
        
    except Exception as e:
        print(f"ğŸš¨ ì •ê·œí™” ì˜¤ë¥˜: {e}")
        return analysis_result

def detect_reference_gender(analysis_result: dict) -> str:
    """
    ì°¸ì¡° ìŒì„±ì˜ ì„±ë³„ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ë³„ì„ ì¶”ì •
    """
    try:
        # ê³¡ì„  ë°ì´í„°ì—ì„œ í‰ê·  ì£¼íŒŒìˆ˜ ê³„ì‚°
        curve_data = analysis_result.get('curve', [])
        if not curve_data:
            return "female"  # ê¸°ë³¸ê°’ì„ femaleë¡œ ì„¤ì •
        
        # ì£¼íŒŒìˆ˜ ê°’ë“¤ ì¶”ì¶œ (dict í˜•íƒœì™€ list í˜•íƒœ ëª¨ë‘ ì²˜ë¦¬)
        frequencies = []
        for point in curve_data:
            if isinstance(point, dict) and 'f0' in point:
                frequencies.append(point['f0'])
            elif isinstance(point, (list, tuple)) and len(point) >= 2 and isinstance(point[1], (int, float)):
                frequencies.append(point[1])
        
        if not frequencies:
            return "female"  # ê¸°ë³¸ê°’
        
        # í‰ê·  ê¸°ë³¸ ì£¼íŒŒìˆ˜ ê³„ì‚°
        mean_f0 = sum(frequencies) / len(frequencies)
        
        # ì„±ë³„ ë¶„ë¥˜ ê¸°ì¤€ (ì¼ë°˜ì ì¸ ìŒì„±í•™ ê¸°ì¤€)
        gender_threshold = 165.0  # Hz - ë‚¨ì„±ê³¼ ì—¬ì„±ì„ êµ¬ë¶„í•˜ëŠ” ì„ê³„ê°’
        
        if mean_f0 < gender_threshold:
            detected_gender = "male"
        else:
            detected_gender = "female"
        
        print(f"ğŸ¯ ì°¸ì¡° ìŒì„± ë¶„ì„: í‰ê·  F0 = {mean_f0:.1f}Hz -> {detected_gender}")
        return detected_gender
        
    except Exception as e:
        print(f"ğŸš¨ ì„±ë³„ ê°ì§€ ì˜¤ë¥˜: {e}")
        return "female"  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’

def simple_pitch_analysis_implementation(sound: pm.Sound, syllables: List[dict]) -> tuple:
    """
    Simple pitch analysis implementation
    """
    try:
        duration = sound.get_total_duration()
        print(f"ğŸš€ AUDIO: {duration:.3f}s duration")
        
        # Basic pitch extraction
        pitch = sound.to_pitch(
            time_step=0.01,
            pitch_floor=75.0,
            pitch_ceiling=500.0
        )
        
        # Extract valid pitch points
        times = pitch.xs()
        valid_points = []
        
        for t in times:
            f0 = pitch.get_value_at_time(t)
            if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                valid_points.append((t, f0))
        
        print(f"ğŸš€ Found {len(valid_points)} valid pitch points")
        
        # Calculate sentence median
        all_f0_values = [f0 for t, f0 in valid_points]
        sentence_median = np.median(all_f0_values) if all_f0_values else 200.0
        
        # ğŸ¯ PERCEPTUAL PITCH CONTOUR: ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ë¡œ ë¶€ë“œëŸ¬ìš´ ê³¡ì„  ìƒì„±
        curve = []
        
        if len(syllables) > 0 and len(valid_points) > 0:
            # 1. ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚° (ì‚¬ëŒì´ ì¸ì§€í•˜ëŠ” ì–µì–‘ íŒ¨í„´)
            syllable_pitch_points = []
            
            for i, syl in enumerate(syllables):
                start_t = syl["start"]
                end_t = syl["end"]
                center_t = start_t + (end_t - start_t) / 2
                label = syl["label"]
                
                # ğŸ¯ ê°œì„ ëœ ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚°
                syllable_data = [(t, f0) for t, f0 in valid_points if start_t <= t <= end_t]
                
                if len(syllable_data) >= 2:
                    # ğŸ¯ ìŠ¤ë§ˆíŠ¸ ëŒ€í‘œê°’ ê³„ì‚°: ì´ìƒê°’ ì œê±° + ì¤‘ì‹¬ë¶€ ê°€ì¤‘í‰ê· 
                    times, pitches = zip(*syllable_data)
                    
                    # 1. ì´ìƒê°’ ì œê±° (IQR ë°©ì‹)
                    pitch_array = np.array(pitches)
                    Q1 = np.percentile(pitch_array, 25)
                    Q3 = np.percentile(pitch_array, 75)
                    IQR = Q3 - Q1
                    
                    # ì´ìƒê°’ ê¸°ì¤€: Q1 - 1.5*IQR ~ Q3 + 1.5*IQR
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    # ì •ìƒê°’ë§Œ í•„í„°ë§
                    filtered_data = [(t, f0) for t, f0 in syllable_data 
                                   if lower_bound <= f0 <= upper_bound]
                    
                    if len(filtered_data) >= 2:
                        times, pitches = zip(*filtered_data)
                        
                        # 2. ì¤‘ì‹¬ë¶€ ê°€ì¤‘í‰ê·  (ë” ì •êµí•œ ê°€ì¤‘ì¹˜)
                        weights = []
                        for t in times:
                            # ìŒì ˆ ì¤‘ì‹¬ì—ì„œì˜ ê±°ë¦¬ ë¹„ìœ¨ (0~1)
                            if (end_t - start_t) > 0:
                                distance_ratio = abs(t - center_t) / ((end_t - start_t) / 2)
                                distance_ratio = min(1.0, distance_ratio)  # 1.0 ì´ìƒ ì œí•œ
                            else:
                                distance_ratio = 0
                            
                            # ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜: ì¤‘ì‹¬ì—ì„œ ë©€ì–´ì§ˆìˆ˜ë¡ ê¸‰ê²©íˆ ê°ì†Œ
                            weight = np.exp(-2 * distance_ratio ** 2)  # e^(-2*d^2)
                            weights.append(weight)
                        
                        # ğŸ¯ ë” ì—„ê²©í•œ ì»¨íˆ¬ì–´ ì¼ì¹˜ ê²€ì¦
                        min_f0 = min(pitches)
                        max_f0 = max(pitches)
                        center_f0 = np.median(pitches)
                        q1_f0 = np.percentile(pitches, 25)
                        q3_f0 = np.percentile(pitches, 75)
                        
                        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                        representative_f0 = np.average(pitches, weights=weights)
                        
                        # ğŸ¯ ë”ìš± ì—„ê²©í•œ ë³´ì •: ë‚¨ì„± ì„±ë³„ ë¬¸ì œ í•´ê²°
                        iqr_range = q3_f0 - q1_f0
                        acceptable_range = max(iqr_range * 0.3, 8.0)  # ë” ì—„ê²©í•˜ê²Œ: 30% ë²”ìœ„, ìµœì†Œ 8Hz
                        
                        # ê°€ì¤‘ í‰ê· ì´ ì¤‘ì•™ê°’ì—ì„œ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì§„ ê²½ìš°
                        if abs(representative_f0 - center_f0) > acceptable_range:
                            representative_f0 = center_f0
                            print(f"  ğŸ¯ '{label}': IQRë³´ì • {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì¤‘ì•™ê°’ì‚¬ìš©)")
                        else:
                            # ì¶”ê°€ ê²€ì¦: ìµœëŒ“ê°’/ìµœì†Ÿê°’ ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸
                            if representative_f0 < min_f0 or representative_f0 > max_f0:
                                representative_f0 = center_f0
                                print(f"  ğŸ¯ '{label}': ë²”ìœ„ë³´ì • {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì¤‘ì•™ê°’ì‚¬ìš©)")
                            else:
                                # ìµœì¢… ê²€ì¦: 25-75% ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸ (ë” ì—„ê²©)
                                if representative_f0 < q1_f0 or representative_f0 > q3_f0:
                                    representative_f0 = center_f0
                                    print(f"  ğŸ¯ '{label}': Që²”ìœ„ë³´ì • {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì¤‘ì•™ê°’ì‚¬ìš©)")
                                else:
                                    print(f"  ğŸ¯ '{label}': {len(syllable_data)}ê°œâ†’{len(filtered_data)}ê°œ â†’ {representative_f0:.1f}Hz (ê²€ì¦ì™„ë£Œ)")
                    else:
                        # í•„í„°ë§ í›„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì›ë³¸ median ì‚¬ìš©
                        representative_f0 = np.median([f0 for t, f0 in syllable_data])
                        print(f"  ğŸ¯ '{label}': {len(syllable_data)}ê°œ â†’ {representative_f0:.1f}Hz (ì›ë³¸median)")
                elif len(syllable_data) == 1:
                    # ë°ì´í„°ê°€ 1ê°œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    representative_f0 = syllable_data[0][1]
                    print(f"  ğŸ¯ '{label}': 1ê°œ â†’ {representative_f0:.1f}Hz (ë‹¨ì¼ê°’)")
                else:
                    # ìŒì ˆ ë‚´ ë°ì´í„° ì—†ìŒ: ë” ë„“ì€ ë²”ìœ„ì—ì„œ ê²€ìƒ‰
                    margin = 0.1  # 100msë¡œ í™•ì¥
                    extended_data = [(t, f0) for t, f0 in valid_points 
                                   if (start_t - margin) <= t <= (end_t + margin)]
                    
                    if len(extended_data) >= 2:
                        # í™•ì¥ ë°ì´í„°ë¡œ ë™ì¼í•œ ìŠ¤ë§ˆíŠ¸ ê³„ì‚°
                        times, pitches = zip(*extended_data)
                        pitch_array = np.array(pitches)
                        representative_f0 = np.median(pitch_array)
                        print(f"  ğŸ¯ '{label}': í™•ì¥ê²€ìƒ‰ {len(extended_data)}ê°œ â†’ {representative_f0:.1f}Hz")
                    elif extended_data:
                        representative_f0 = extended_data[0][1]
                        print(f"  ğŸ¯ '{label}': í™•ì¥ê²€ìƒ‰ 1ê°œ â†’ {representative_f0:.1f}Hz")
                    elif valid_points:
                        # ê°€ì¥ ê°€ê¹Œìš´ 3ê°œ í”¼ì¹˜ì˜ median
                        distances = [(abs(t - center_t), f0) for t, f0 in valid_points]
                        distances.sort()
                        nearest_pitches = [f0 for _, f0 in distances[:3]]
                        representative_f0 = np.median(nearest_pitches)
                        print(f"  ğŸ¯ '{label}': ìµœê·¼ì ‘3ê°œ â†’ {representative_f0:.1f}Hz")
                    else:
                        representative_f0 = sentence_median
                        print(f"  ğŸ¯ '{label}': ê¸°ë³¸ê°’ â†’ {representative_f0:.1f}Hz")
                
                syllable_pitch_points.append((center_t, representative_f0))
            
            # 2. ìŒì ˆ ì‚¬ì´ë¥¼ ë¶€ë“œëŸ½ê²Œ ë³´ê°„ (ìŠ¤í”Œë¼ì¸ ê³¡ì„  ì‹œë®¬ë ˆì´ì…˜)
            if len(syllable_pitch_points) >= 2:
                # ì „ì²´ ì‹œê°„ ë²”ìœ„
                start_time = syllable_pitch_points[0][0]
                end_time = syllable_pitch_points[-1][0]
                total_duration = end_time - start_time
                
                # 0.02ì´ˆ ê°„ê²©ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ê³¡ì„  ìƒì„± (50Hz ìƒ˜í”Œë§)
                time_step = 0.02
                num_points = int(total_duration / time_step) + 1
                
                for i in range(num_points):
                    current_time = start_time + i * time_step
                    
                    # í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” í”¼ì¹˜ ë³´ê°„
                    if current_time <= syllable_pitch_points[0][0]:
                        # ì‹œì‘ ì „
                        interpolated_f0 = syllable_pitch_points[0][1]
                    elif current_time >= syllable_pitch_points[-1][0]:
                        # ë ì´í›„
                        interpolated_f0 = syllable_pitch_points[-1][1]
                    else:
                        # ì¤‘ê°„ êµ¬ê°„ - ì„ í˜• ë³´ê°„
                        for j in range(len(syllable_pitch_points) - 1):
                            t1, f0_1 = syllable_pitch_points[j]
                            t2, f0_2 = syllable_pitch_points[j + 1]
                            
                            if t1 <= current_time <= t2:
                                # ì„ í˜• ë³´ê°„ (ë¶€ë“œëŸ¬ìš´ ê³¡ì„ )
                                ratio = (current_time - t1) / (t2 - t1) if t2 != t1 else 0
                                interpolated_f0 = f0_1 + (f0_2 - f0_1) * ratio
                                break
                        else:
                            interpolated_f0 = syllable_pitch_points[0][1]
                    
                    # ê³¡ì„  ë°ì´í„° ì¶”ê°€
                    semitone = 12 * np.log2(interpolated_f0 / sentence_median) if sentence_median > 0 else 0.0
                    curve.append({
                        "t": float(current_time),
                        "f0": float(interpolated_f0),
                        "dB": -30.0,  # Default intensity
                        "semitone": float(semitone)
                    })
            
            elif len(syllable_pitch_points) == 1:
                # ìŒì ˆì´ í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ í”Œë« ë¼ì¸
                t, f0 = syllable_pitch_points[0]
                semitone = 12 * np.log2(f0 / sentence_median) if sentence_median > 0 else 0.0
                curve.append({
                    "t": float(t),
                    "f0": float(f0),
                    "dB": -30.0,
                    "semitone": float(semitone)
                })
        
        elif len(valid_points) > 0:
            # ìŒì ˆ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°± (í•˜ì§€ë§Œ ë” ê°„ì†Œí™”)
            # ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§ (0.1ì´ˆë§ˆë‹¤)
            time_step = 0.1
            start_time = valid_points[0][0]
            end_time = valid_points[-1][0]
            
            current_time = start_time
            while current_time <= end_time:
                # í˜„ì¬ ì‹œê°„ ê·¼ì²˜ì˜ í”¼ì¹˜ë“¤ í‰ê· 
                nearby_pitches = [f0 for t, f0 in valid_points if abs(t - current_time) <= time_step/2]
                
                if nearby_pitches:
                    representative_f0 = np.median(nearby_pitches)
                    semitone = 12 * np.log2(representative_f0 / sentence_median) if sentence_median > 0 else 0.0
                    curve.append({
                        "t": float(current_time),
                        "f0": float(representative_f0),
                        "dB": -30.0,
                        "semitone": float(semitone)
                    })
                
                current_time += time_step
        
        print(f"ğŸ¯ ì¸ì§€ì  í”¼ì¹˜ ê³¡ì„ : {len(valid_points)} raw â†’ {len(curve)} ë¶€ë“œëŸ¬ìš´ í¬ì¸íŠ¸")
        
        # Process syllables for analysis table (unchanged)
        syllable_analysis = []
        
        for i, syl in enumerate(syllables):
            start_t = syl["start"]
            end_t = syl["end"]
            center_t = start_t + (end_t - start_t) / 2
            label = syl["label"]
            
            # Find pitch in syllable range
            syllable_pitches = [f0 for t, f0 in valid_points if start_t <= t <= end_t]
            
            if syllable_pitches:
                f0_val = np.mean(syllable_pitches)  # Use average instead of max
            elif valid_points:
                # Find nearest pitch
                nearest = min(valid_points, key=lambda x: abs(x[0] - center_t))
                f0_val = nearest[1]
            else:
                f0_val = sentence_median
            
            # Calculate semitone
            semitone = 12 * np.log2(f0_val / sentence_median) if sentence_median > 0 else 0.0
            
            syllable_analysis.append({
                "label": label,
                "start": float(start_t),
                "end": float(end_t),
                "duration": float(end_t - start_t),
                "f0": float(f0_val),
                "representative_f0": float(f0_val),  # ëŒ€í‘œ f0 ì¶”ê°€
                "semitone": float(semitone),
                "semitone_median": float(semitone),  # í˜¸í™˜ì„±
                "qtone": float(5 * np.log2(f0_val / 130)) if f0_val > 0 else 0.0,
                "intensity": -30.0,
                # ğŸ¯ ìŒì ˆ ì¤‘ì‹¬ì  ë°ì´í„° ì¶”ê°€ (ì°¨íŠ¸ í‘œì‹œìš©)
                "center_time": float(center_t),
                "start_time": float(start_t),  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±
                "end_time": float(end_t),      # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±
                "start": float(start_t),       # ì¶”ê°€ í˜¸í™˜ì„±
                "end": float(end_t)            # ì¶”ê°€ í˜¸í™˜ì„±
            })
        
        print(f"ğŸ¯ Generated {len(curve)} time series points and {len(syllable_analysis)} syllable analyses")
        
        return curve, syllable_analysis, sentence_median
        
    except Exception as e:
        print(f"Simple pitch analysis error: {e}")
        # Return default values
        return [], [], 200.0

def praat_pitch_analysis(
    sound: pm.Sound,
    syllables: List[dict],
    pitch_floor: float = 75.0,
    pitch_ceiling: float = 500.0,   
    time_step: float = 0.01,
) -> tuple:
    """
    ğŸš€ NEW SIMPLE ENGINE: ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼
    """
    # Simple pitch analysis implementation
    return simple_pitch_analysis_implementation(sound, syllables)
    
    duration = sound.get_total_duration()
    print(f"ğŸš€ AUDIO: {duration:.3f}s duration")
    
    # ğŸ¯ STEP 1: ê¸°ë³¸ í”¼ì¹˜ ì¶”ì¶œ (í‘œì¤€ ì„¤ì •)
    pitch = sound.to_pitch(
        time_step=time_step,
        pitch_floor=pitch_floor,
        pitch_ceiling=pitch_ceiling
    )
    
    print(f"ğŸš€ PITCH TRACK: {pitch_floor}-{pitch_ceiling}Hz, step={time_step}s")
    
    # ğŸ¯ STEP 2: ìŒì„± êµ¬ê°„ ì°¾ê¸° (ì‹¬í”Œí•œ ë°©ë²•)
    times = pitch.xs()
    valid_points = []
    
    for t in times:
        f0 = pitch.get_value_at_time(t)
        if f0 and not np.isnan(f0) and f0 > pitch_floor and f0 < pitch_ceiling:
            valid_points.append((t, f0))
    
    print(f"ğŸš€ FOUND: {len(valid_points)} valid pitch points")
    
    # ì²˜ìŒ ëª‡ê°œ í¬ì¸íŠ¸ í™•ì¸
    if valid_points:
        print("ğŸš€ FIRST VALID POINTS:")
        for i in range(min(3, len(valid_points))):
            t, f0 = valid_points[i]
            print(f"ğŸš€   {t:.3f}s = {f0:.1f}Hz")
    else:
        print("ğŸš€ ERROR: NO VALID PITCH FOUND")
        # ë” ê´€ëŒ€í•œ ì¡°ê±´ìœ¼ë¡œ ì¬ì‹œë„
        print("ğŸš€ TRYING BROADER RANGE...")
        pitch = sound.to_pitch(pitch_floor=50, pitch_ceiling=800, time_step=0.01)
        times = pitch.xs()
        for t in times:
            f0 = pitch.get_value_at_time(t)
            if f0 and not np.isnan(f0) and f0 > 50:
                valid_points.append((t, f0))
        print(f"ğŸš€ BROADER SEARCH: {len(valid_points)} points")
    
    # ğŸ¯ STEP 3: ê°•ë„(intensity) ê³„ì‚°
    intensity = sound.to_intensity()
    
    # ğŸ¯ STEP 4: ì „ì²´ ë¬¸ì¥ì˜ ê¸°ì¤€ í”¼ì¹˜ ê³„ì‚°
    all_f0_values = [f0 for t, f0 in valid_points]
    sentence_median = np.median(all_f0_values) if all_f0_values else 200.0
    print(f"ğŸš€ SENTENCE MEDIAN: {sentence_median:.1f} Hz")
    
    # ğŸ¯ STEP 5: ê° ìŒì ˆë³„ í”¼ì¹˜ ë¶„ì„ (ì‹¬í”Œí•˜ê²Œ!)
    curve = []
    syllable_analysis = []
    
    # Process each syllable (equivalent to Praat script's for loop)
    for i, syl in enumerate(syllables):
        start_t = syl["start"]
        end_t = syl["end"]
        dur = end_t - start_t
        center_t = start_t + dur/2
        label = syl["label"]
        
        print(f"ğŸ¯ Processing syllable '{label}' ({start_t:.3f}s - {end_t:.3f}s)")
        
        # ğŸ¯ DEBUG: Check pitch values in syllable range
        print(f"   ğŸ¯ Checking pitch values from {start_t:.3f}s to {end_t:.3f}s...")
        
        # ë” ì¡°ë°€í•˜ê²Œ ìƒ˜í”Œë§ (20ê°œ í¬ì¸íŠ¸)
        sample_times = [start_t + (end_t - start_t) * i / 19 for i in range(20)]
        valid_f0_values = []
        
        for sample_t in sample_times:
            try:
                f0_at_t = pitch.get_value_at_time(sample_t)
                if f0_at_t is not None and not np.isnan(f0_at_t) and f0_at_t > pitch_floor * 0.8:  # ë” ê´€ëŒ€í•œ í•„í„°ë§
                    valid_f0_values.append(f0_at_t)
                    print(f"     ğŸ¯ t={sample_t:.3f}s: f0={f0_at_t:.1f}Hz")
            except Exception as e:
                print(f"     ğŸ¯ t={sample_t:.3f}s: Error - {e}")
        
        print(f"   ğŸ¯ Found {len(valid_f0_values)} valid F0 values in syllable")
        
        # ğŸ¯ CRITICAL FIX: ì „ì²´ í”¼ì¹˜ íŠ¸ë™ì—ì„œ í•´ë‹¹ ì‹œê°„ëŒ€ ë°ì´í„° ì§ì ‘ ì¶”ì¶œ
        pitch_times = pitch.xs()  # ëª¨ë“  ì‹œê°„ í¬ì¸íŠ¸
        pitch_values = []
        
        for t in pitch_times:
            if start_t <= t <= end_t:
                f0_val = pitch.get_value_at_time(t)
                if f0_val is not None and not np.isnan(f0_val) and f0_val > pitch_floor * 0.8:
                    pitch_values.append((t, f0_val))
        
        print(f"   ğŸ¯ Direct extraction found {len(pitch_values)} pitch points in syllable")
        
        if pitch_values:
            # ìœ íš¨í•œ í”¼ì¹˜ê°’ì´ ìˆìœ¼ë©´ ìµœëŒ€ê°’ ì‚¬ìš©
            max_pitch_point = max(pitch_values, key=lambda x: x[1])
            f0_max = max_pitch_point[1]
            time_of_max = max_pitch_point[0]
            f0_mean = np.mean([p[1] for p in pitch_values])
            print(f"   ğŸ¯ Direct extraction: max={f0_max:.1f}Hz at {time_of_max:.3f}s, mean={f0_mean:.1f}Hz")
        elif valid_f0_values:
            # ìƒ˜í”Œë§ì—ì„œ ì°¾ì€ ê°’ë“¤ ì‚¬ìš©
            f0_max = max(valid_f0_values)
            f0_mean = np.mean(valid_f0_values)
            time_of_max = center_t
            print(f"   ğŸ¯ Sampling fallback: max={f0_max:.1f}Hz, mean={f0_mean:.1f}Hz")
        else:
            # ë§ˆì§€ë§‰ ëŒ€ì•ˆ: ì¸ê·¼ ìœ íš¨í•œ í”¼ì¹˜ê°’ ì°¾ê¸°
            nearby_f0_values = []
            search_range = 0.1  # 100ms ë²”ìœ„ë¡œ í™•ì¥ ê²€ìƒ‰
            
            for t in pitch_times:
                if (start_t - search_range) <= t <= (end_t + search_range):
                    f0_val = pitch.get_value_at_time(t)
                    if f0_val is not None and not np.isnan(f0_val) and f0_val > pitch_floor * 0.8:
                        nearby_f0_values.append(f0_val)
            
            if nearby_f0_values:
                f0_max = np.median(nearby_f0_values)  # ì¤‘ê°„ê°’ ì‚¬ìš©
                time_of_max = center_t
                print(f"   ğŸ¯ Extended search found {len(nearby_f0_values)} nearby values, using median={f0_max:.1f}Hz")
            else:
                f0_max = None
                time_of_max = center_t
                print(f"   ğŸ¯ No pitch found even with extended search")
        
        # Get mean F0 as fallback (like Praat script: Get mean...)
        try:
            f0_mean = pitch.get_mean(start_t, end_t, "Hertz")
            print(f"   ğŸ¯ get_mean() returned: {f0_mean}")
        except Exception as e:
            print(f"   ğŸ¯ get_mean() failed: {e}")
            f0_mean = None
        
        # Manual calculation from valid samples
        if valid_f0_values:
            manual_max = max(valid_f0_values)
            manual_mean = np.mean(valid_f0_values)
            print(f"   ğŸ¯ Manual calculation: max={manual_max:.1f}Hz, mean={manual_mean:.1f}Hz")
            
            # Use manual values if official methods failed
            if f0_max is None or np.isnan(f0_max):
                f0_max = manual_max
                time_of_max = center_t
                print(f"   ğŸ¯ Using manual max: {f0_max:.1f}Hz")
            
            if f0_mean is None or np.isnan(f0_mean):
                f0_mean = manual_mean
                print(f"   ğŸ¯ Using manual mean: {f0_mean:.1f}Hz")
        
        # Choose F0 value (prefer max, fallback to mean)
        if f0_max is not None and not np.isnan(f0_max):
            f0_val = f0_max
            time_val = time_of_max
            print(f"   ğŸ¯ Max F0: {f0_val:.1f} Hz @ {time_val:.3f}s")
        elif f0_mean is not None and not np.isnan(f0_mean):
            f0_val = f0_mean
            time_val = center_t
            print(f"   ğŸ¯ Mean F0: {f0_val:.1f} Hz @ {time_val:.3f}s")
        else:
            f0_val = sentence_median  # fallback to sentence median
            time_val = center_t
            print(f"   ğŸ¯ Fallback to sentence median: {f0_val:.1f} Hz")
        
        # Get intensity
        try:
            db_val = intensity.get_value(time_val)
            if db_val is None or np.isnan(db_val):
                db_val = -40.0
        except:
            db_val = -40.0
        
        # Calculate semitone and quarter-tone (like Praat script)
        if f0_val and not np.isnan(f0_val):
            semi_tone = 12 * np.log2(f0_val / sentence_median)
            quarter_tone = 24 * np.log2(f0_val / sentence_median)
            print(f"   ğŸ¯ Semi-tone: {semi_tone:.1f}, Quarter-tone: {quarter_tone:.1f}")
        else:
            semi_tone = 0.0
            quarter_tone = 0.0
        
        curve.append({
            "t": time_val,
            "f0": float(f0_val),
            "dB": float(db_val),
            "semitone": float(semi_tone)
        })
        
        syllable_analysis.append({
            "label": label,  # ğŸ¯ "syllable" â†’ "label" ìˆ˜ì •
            "start": float(start_t),
            "end": float(end_t), 
            "duration": float(dur),
            "f0": float(f0_val),
            "representative_f0": float(f0_val),
            "semitone": float(semi_tone),  # ğŸ¯ ì¤‘ìš”! semitone ì¶”ê°€
            "semitone_median": float(semi_tone),
            "qtone": float(5 * np.log2(f0_val / 130)) if f0_val > 0 else 0.0,
            "intensity": float(db_val),
            "center_time": float(time_val),  # ğŸ¯ ì¤‘ì‹¬ ì‹œê°„ ì¶”ê°€
            "start_time": float(start_t),
            "end_time": float(end_t)
        })
        
        print(f"   ğŸ¯âœ… '{label}': {f0_val:.1f}Hz @ {time_val:.3f}s, {db_val:.1f}dB")
    
    print(f"ğŸ¯ğŸ¯ğŸ¯ PRAAT ANALYSIS ì™„ë£Œ: {len(curve)}ê°œ í¬ì¸íŠ¸ ğŸ¯ğŸ¯ğŸ¯")
    return curve, syllable_analysis, sentence_median

def extract_ref_praat_implementation(
    sound: pm.Sound,
    tg: pm.TextGrid,
    pitch_floor: float = 75.0,
    pitch_ceiling: float = 600.0,
    time_step: float = 0.01,
    sentence: str | None = None,
    extracted_syllables: Optional[list] = None,
    target_gender: str = 'auto',
):
    """
    Complete Praat-based reference extraction implementing Script_toneLabeler_cj.praat
    """
    print("ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ PRAAT IMPLEMENTATION ì‹œì‘!!! ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
    print("ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ PRAAT IMPLEMENTATION ì‹œì‘!!! ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
    print("ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ PRAAT IMPLEMENTATION ì‹œì‘!!! ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
    print(f"ğŸ¯ Parameters: pitch_floor={pitch_floor}, pitch_ceiling={pitch_ceiling}")
    print(f"ğŸ¯ Sound duration: {sound.xmax - sound.xmin:.3f}s")
    
    t_min, t_max = sound.xmin, sound.xmax
    
    # Step 1: Use extracted syllables from new TextGrid parser or fallback
    if extracted_syllables:
        print(f"ğŸ¯ Using extracted syllables: {len(extracted_syllables)} syllables")
        syllables = adjust_textgrid_timing(extracted_syllables)  # ğŸ”§ ì‹œê°„ ë³´ì • ì ìš©
    else:
        print("ğŸ¯ Fallback: Using old TextGrid parser")
        syllables = praat_script_textgrid_parser(tg) if tg else []
    
    # Step 1.5: TextGridê°€ ì—†ê±°ë‚˜ ë¬¸ì œê°€ ìˆìœ¼ë©´ ìë™ ë¶„ì ˆ ì‹œë„
    if not syllables and sentence and sentence.strip():
        print("ğŸ¤– TextGrid ë¶„ì„ ì‹¤íŒ¨ â†’ ìë™ ìŒì ˆ ë¶„ì ˆ ì‹œë„")
        syllables = auto_segment_syllables(sound, sentence)
        
        # ìë™ ìƒì„±ëœ ìŒì ˆë¡œ TextGrid íŒŒì¼ ì—…ë°ì´íŠ¸
        if syllables:
            textgrid_path = str(Path("static/reference_files") / f"{sentence.replace(' ', '')}.TextGrid")
            save_textgrid(syllables, textgrid_path, sound.duration)
            print(f"ğŸ¤– ìƒˆë¡œìš´ TextGrid ìƒì„±: {textgrid_path}")
    
    # Step 2: Fallback to sentence-based or time-based segmentation
    if not syllables:
        if sentence and sentence.strip():
            print(f"ğŸ¯ Sentence-based segmentation: '{sentence}'")
            syllable_labels = split_korean_sentence(sentence.strip())
            num_syllables = len(syllable_labels)
            segment_duration = float(t_max - t_min) / num_syllables
            
            for i, label in enumerate(syllable_labels):
                start_time = float(t_min + i * segment_duration)
                end_time = float(t_min + (i+1) * segment_duration)
                syllables.append({
                    "label": label,
                    "start": start_time,
                    "end": end_time,
                })
                print(f"   ğŸ¯ Sentence syllable: '{label}' ({start_time:.3f}s-{end_time:.3f}s)")
        else:
            print("ğŸ¯ Default 3-segment division")
            segment_duration = float(t_max - t_min) / 3
            for i in range(3):
                start_time = float(t_min + i * segment_duration)
                end_time = float(t_min + (i+1) * segment_duration)
                syllables.append({
                    "label": f"êµ¬ê°„{i+1}",
                    "start": start_time,
                    "end": end_time,
                })
    
    print(f"ğŸ¯ Final syllables: {len(syllables)} syllables")
    
    # Step 3: Praat pitch analysis
    curve, syllable_analysis, sentence_median = praat_pitch_analysis(
        sound, syllables, pitch_floor, pitch_ceiling, time_step
    )
    
    
    return {
        "curve": curve,
        "syllables": syllables,
        "syllable_analysis": syllable_analysis,
        "spectrogram": [],
        "stats": {
            "meanF0": sentence_median,
            "maxF0": max([p["f0"] for p in curve]) if curve else 180.0,
            "maxdB": max([p["dB"] for p in curve]) if curve else -40.0,
            "sentence_median": sentence_median,
            "duration": float(t_max - t_min),
        },
    }

@app.get("/", response_class=HTMLResponse)
async def get_index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/react-demo", response_class=HTMLResponse)
async def react_demo(request: Request):
    """React migration demo using voice-analysis-demo directory contents only"""
    # Use voice-analysis-demo directory templates and static files
    from fastapi.templating import Jinja2Templates
    demo_templates = Jinja2Templates(directory="voice-analysis-demo/templates")
    return demo_templates.TemplateResponse("index.html", {"request": request})

@app.post("/analyze_ref", response_model=RefAnalysis)
async def analyze_ref(
    wav: UploadFile = File(..., description="Reference WAV"),
    textgrid: UploadFile = File(..., description="Reference TextGrid"),
    sentence: str = Form(None, description="Sentence text for syllable labeling"),
    learner_gender: str = Form(..., description="Learner gender (male/female)"),
    learner_name: str = Form(None, description="Learner name (optional)"),
    learner_level: str = Form(None, description="Learner level (optional)"),
    pitch_floor: Optional[float] = Form(75.0),
    pitch_ceiling: Optional[float] = Form(600.0),
    time_step: Optional[float] = Form(0.01),
):
    try:
        print("ğŸ¯ğŸ¯ğŸ¯ PRAAT API ENDPOINT í˜¸ì¶œë¨!!! ğŸ¯ğŸ¯ğŸ¯")
        print(f"Received files: WAV={wav.filename}, TextGrid={textgrid.filename}")
        print(f"ğŸ¯ í•™ìŠµì ì •ë³´: ì„±ë³„={learner_gender}, ì´ë¦„={learner_name or 'ë¯¸ì…ë ¥'}, ìˆ˜ì¤€={learner_level or 'ë¯¸ì…ë ¥'}")
        if sentence:
            print(f"Received sentence: '{sentence}'")
        
        # Validate file types
        if wav.filename and not wav.filename.lower().endswith('.wav'):
            raise HTTPException(status_code=400, detail="WAV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        if textgrid.filename and not textgrid.filename.lower().endswith(('.textgrid', '.TextGrid')):
            raise HTTPException(status_code=400, detail="TextGrid íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        wav_bytes = await wav.read()
        tg_bytes = await textgrid.read()
        
        print(f"File sizes: WAV={len(wav_bytes)} bytes, TextGrid={len(tg_bytes)} bytes")

        # Create temporary files for parselmouth
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_temp:
            wav_temp.write(wav_bytes)
            wav_temp_path = wav_temp.name
            
        with tempfile.NamedTemporaryFile(suffix='.TextGrid', delete=False) as tg_temp:
            tg_temp.write(tg_bytes)
            tg_temp_path = tg_temp.name

        try:
            import parselmouth as pm
            snd = pm.Sound(wav_temp_path)
            
            # Try to read TextGrid file
            try:
                tg = pm.TextGrid.read(tg_temp_path)
                
                # ğŸ¯ COMPLETE TextGrid structure analysis
                print(f"ğŸ¯ğŸ” TextGrid ê°ì²´ ì™„ì „ ë¶„ì„:")
                print(f"    ğŸ¯ Type: {type(tg)}")
                print(f"    ğŸ¯ Dir: {[attr for attr in dir(tg) if not attr.startswith('_')]}")
                
                # Check all possible attributes AND methods
                attributes_to_check = [
                    'n_tiers', 'tiers', 'size', 'count', 'length',
                    'xmin', 'xmax', 'start_time', 'end_time', 'info'
                ]
                
                for attr in attributes_to_check:
                    if hasattr(tg, attr):
                        try:
                            if callable(getattr(tg, attr)):
                                if attr == 'info':
                                    value = getattr(tg, attr)()  # Call the method
                                else:
                                    value = f"<method {attr}>"
                            else:
                                value = getattr(tg, attr)
                            print(f"    ğŸ¯ {attr}: {value} (type: {type(value)})")
                        except Exception as e:
                            print(f"    ğŸ¯ {attr}: Error calling - {e}")
                
                # ğŸ¯ TRY DIFFERENT PARSELMOUTH METHODS
                print("ğŸ¯ Trying different Parselmouth access methods...")
                
                # Method: Try to find tier-related methods in dir
                all_methods = [attr for attr in dir(tg) if not attr.startswith('_')]
                tier_methods = [m for m in all_methods if 'tier' in m.lower()]
                if tier_methods:
                    print(f"    ğŸ¯ Found tier-related methods: {tier_methods}")
                
                # Method: Try to use info() method for structure
                try:
                    if hasattr(tg, 'info'):
                        info_result = tg.info()
                        print(f"    ğŸ¯ Info method result: {info_result}")
                except Exception as e:
                    print(f"    ğŸ¯ Info method failed: {e}")
                
                # ğŸ¯ CORRECT APPROACH: Use official Parselmouth TextGrid API
                tier_count = 0
                intervals = []
                
                # Method 1: Try TextGridTools (to_tgt) - OFFICIAL METHOD
                try:
                    print("ğŸ¯ Method 1: Using TextGridTools (.to_tgt())")
                    try:
                        import textgrid as tgt  # TextGrid parser
                    except ImportError:
                        print("ğŸš¨ textgrid ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                    
                    # Simple TextGrid parsing without external library
                    print("ğŸ¯ Using simple TextGrid parsing")
                    
                    # Read TextGrid file content
                    with open(tg_temp_path, 'r', encoding='utf-8') as f:
                        tg_content = f.read()
                    
                    tgt_grid = None
                    print(f"    ğŸ¯ TextGrid content read successful!")
                    print(f"    ğŸ¯ Content length: {len(tg_content)} characters")
                    
                    # Simple TextGrid parsing - extract intervals using regex
                    import re
                    
                    # Find intervals in TextGrid content
                    interval_pattern = r'intervals \[\d+\]:\s*xmin = ([\d.]+)\s*xmax = ([\d.]+)\s*text = "([^"]*)"'  
                    matches = re.findall(interval_pattern, tg_content)
                    
                    for start_str, end_str, text in matches:
                        if text.strip() and text.strip().lower() not in ['', 'p', 'sp']:
                            intervals.append({
                                "label": text.strip(),
                                "start": float(start_str),
                                "end": float(end_str)
                            })
                            print(f"      ğŸ¯ Parsed interval: '{text}' ({start_str}s-{end_str}s)")
                    
                    tier_count = 1 if intervals else 0
                    print(f"ğŸ¯âœ… Simple parsing method SUCCESS: {len(intervals)} intervals extracted")
                        
                except ImportError:
                    print("    ğŸ¯ TextGridTools not installed, trying Method 2...")
                except Exception as e:
                    print(f"    ğŸ¯ TextGridTools method failed: {e}")
                
                # Method 2: Direct Praat calls - OFFICIAL METHOD
                if tier_count == 0:
                    try:
                        print("ğŸ¯ Method 2: Using parselmouth.praat.call()")
                        import parselmouth as pm
                        
                        # Get basic tier information  
                        num_tiers = pm.praat.call(tg, "Get number of tiers")
                        print(f"    ğŸ¯ Number of tiers: {num_tiers}")
                        
                        if num_tiers > 0:
                            tier_count = num_tiers
                            
                            # Get first tier information (1-based indexing in Praat!)
                            tier_name = pm.praat.call(tg, "Get tier name", 1)
                            num_intervals = pm.praat.call(tg, "Get number of intervals", 1)
                            print(f"    ğŸ¯ Tier 1 name: '{tier_name}', intervals: {num_intervals}")
                            
                            # Extract all intervals from first tier
                            for i in range(1, num_intervals + 1):  # 1-based indexing!
                                start_time = pm.praat.call(tg, "Get start time of interval", 1, i)
                                end_time = pm.praat.call(tg, "Get end time of interval", 1, i)
                                label = pm.praat.call(tg, "Get label of interval", 1, i)
                                
                                intervals.append({
                                    'start': start_time,
                                    'end': end_time,
                                    'label': label.strip(),
                                    'index': i-1  # Convert to 0-based for consistency
                                })
                                print(f"        ğŸ¯ Interval {i}: '{label}' ({start_time:.3f}s - {end_time:.3f}s)")
                            
                            print(f"ğŸ¯âœ… Praat calls method SUCCESS: {len(intervals)} intervals extracted")
                            
                    except Exception as e:
                        print(f"    ğŸ¯ Praat calls method failed: {e}")
                
                # Filter out empty intervals and prepare syllable data
                syllables = []
                if intervals:
                    print(f"ğŸ¯ Processing {len(intervals)} intervals...")
                    
                    for interval in intervals:
                        # Only include non-empty intervals
                        if interval['label'] and interval['label'].strip():
                            syllables.append({
                                'label': interval['label'],
                                'start': interval['start'],
                                'end': interval['end']
                            })
                            print(f"    ğŸ¯ Valid syllable: '{interval['label']}' ({interval['start']:.3f}s - {interval['end']:.3f}s)")
                    
                    print(f"ğŸ¯âœ… Final syllable count: {len(syllables)} syllables")
                else:
                    print("ğŸ¯âš ï¸ No intervals extracted from TextGrid")
                
                # Use extracted syllables or fallback
                if syllables:
                    tier_count = len(syllables) 
                    print(f"ğŸ¯âœ… Successfully extracted {len(syllables)} syllables from TextGrid")
                else:
                    tier_count = 0
                    print("ğŸ¯âš ï¸ No syllables found - using fallback mode")
                    
            except Exception as e1:
                try:
                    # Alternative reading method
                    import subprocess
                    result = subprocess.run(['file', tg_temp_path], capture_output=True, text=True)
                    print(f"ğŸ¯ File type check: {result.stdout.strip()}")
                    
                    data_obj = pm.Data.read(tg_temp_path)
                    if hasattr(data_obj, 'n_tiers') or hasattr(data_obj, 'tiers'):
                        tg = data_obj
                        tier_count = getattr(data_obj, 'n_tiers', len(getattr(data_obj, 'tiers', [])))
                        print(f"ğŸ¯âœ… TextGrid ì½ê¸° ì„±ê³µ (Dataë¡œ): {tier_count}ê°œ tier")
                    else:
                        raise Exception("Read object is not a valid TextGrid")
                except Exception as e2:
                    print(f"ğŸ¯âŒ TextGrid ì½ê¸° ì‹¤íŒ¨: {e1}, {e2}")
                    print("ğŸ¯ğŸ”„ ìŒì„± ì „ìš© ë¶„ì„ ëª¨ë“œë¡œ ì§„í–‰ (TextGrid ì—†ì´)")
                    tg = None
                    tier_count = 0
            
            tg_info = f"Sound duration: {snd.duration:.2f}s"
            if tg is not None:
                tg_info += f", TextGrid tiers: {tier_count}"
            else:
                tg_info += ", TextGrid: fallback mode"
            print(tg_info)
            
            # ğŸ¯ ì„±ë³„ ë§¤ê°œë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸° 
            target_gender = 'auto'  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            print(f"ğŸ¯ Target gender: {target_gender}")
            
            # ğŸ¯ syllables ë³€ìˆ˜ ì´ˆê¸°í™” (í™•ì‹¤í•˜ê²Œ ì •ì˜)
            syllables = []
            if 'syllables' not in locals():
                syllables = []
            
            # ğŸ¯ í•™ìŠµì ì„±ë³„ì— ë”°ë¥¸ ìµœì í™”ëœ ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
            if learner_gender == "male":
                optimized_pitch_floor = 75.0
                optimized_pitch_ceiling = 300.0
                print(f"ğŸ¯ ë‚¨ì„± í•™ìŠµì - ìµœì í™”ëœ í”¼ì¹˜ ë²”ìœ„: {optimized_pitch_floor}-{optimized_pitch_ceiling}Hz")
            elif learner_gender == "female":
                optimized_pitch_floor = 100.0
                optimized_pitch_ceiling = 600.0
                print(f"ğŸ¯ ì—¬ì„± í•™ìŠµì - ìµœì í™”ëœ í”¼ì¹˜ ë²”ìœ„: {optimized_pitch_floor}-{optimized_pitch_ceiling}Hz")
            else:
                optimized_pitch_floor = pitch_floor or 75.0
                optimized_pitch_ceiling = pitch_ceiling or 600.0
                print(f"ğŸ¯ ê¸°ë³¸ í”¼ì¹˜ ë²”ìœ„ ì‚¬ìš©: {optimized_pitch_floor}-{optimized_pitch_ceiling}Hz")
            
            print("ğŸ¯ğŸ¯ğŸ¯ PRAAT extract_ref í•¨ìˆ˜ í˜¸ì¶œ ì§ì „!!! ğŸ¯ğŸ¯ğŸ¯")
            # Pass extracted syllables from TextGrid to the processing function with optimized parameters
            out = extract_ref_praat_implementation(
                snd, tg,
                pitch_floor=optimized_pitch_floor,
                pitch_ceiling=optimized_pitch_ceiling,
                time_step=time_step or 0.01,
                sentence=sentence,
                extracted_syllables=syllables if syllables and len(syllables) > 0 else None,
                target_gender=target_gender
            )
            print("ğŸ¯ğŸ¯ğŸ¯ PRAAT extract_ref í•¨ìˆ˜ í˜¸ì¶œ ì™„ë£Œ!!! ğŸ¯ğŸ¯ğŸ¯")
            
            # ğŸ¯ ì°¸ì¡° ìŒì„±ì˜ ì„±ë³„ ìë™ ê°ì§€
            reference_gender = detect_reference_gender(out)
            print(f"ğŸ¯ ì°¸ì¡° ìŒì„± ì„±ë³„ ê°ì§€: {reference_gender}")
            
            # ğŸ¯ í•™ìŠµì ì„±ë³„ì— ë”°ë¥¸ ì°¸ì¡° ë°ì´í„° ì •ê·œí™”
            if learner_gender == "male":
                print("ğŸ¯ ë‚¨ì„± í•™ìŠµì - ì°¸ì¡° ë°ì´í„°ë¥¼ ë‚¨ì„± ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” ì¤‘...")
                out = apply_gender_normalization(out, target_gender=reference_gender, learner_gender="male")
                print("ğŸ¯ ë‚¨ì„± í•™ìŠµì - ì •ê·œí™”ëœ ê³¡ì„ ì— ë§ëŠ” ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ í‘œì‹œ")
            elif learner_gender == "female":
                print("ğŸ¯ ì—¬ì„± í•™ìŠµì - ì°¸ì¡° ë°ì´í„°ë¥¼ ì—¬ì„± ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” ì¤‘...")
                out = apply_gender_normalization(out, target_gender=reference_gender, learner_gender="female")
            else:
                print("ğŸ¯ ì„±ë³„ ë¯¸ì§€ì • - ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
            
            print(f"Analysis complete: {len(out['curve'])} points, {len(out['syllables'])} syllables, {len(out.get('syllable_analysis', []))} syllable_analysis")
            print(f"ğŸ¯ CRITICAL DEBUG - out keys: {list(out.keys())}")
            if 'syllable_analysis' in out:
                print(f"ğŸ¯ syllable_analysis ìƒ˜í”Œ: {out['syllable_analysis'][:3] if len(out['syllable_analysis']) > 0 else 'EMPTY'}")
            
        finally:
            # Clean up temporary files
            try:
                os.unlink(wav_temp_path)
                os.unlink(tg_temp_path)
            except:
                pass
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"Analysis error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    curve = [RefPoint(**p) for p in out["curve"]]
    syll  = [Syllable(**s) for s in out["syllables"]]
    
    print(f"ğŸ¯ FINAL CHECK - syllable_analysis exists: {'syllable_analysis' in out}")
    if 'syllable_analysis' in out:
        print(f"ğŸ¯ FINAL CHECK - syllable_analysis length: {len(out['syllable_analysis'])}")
        print(f"ğŸ¯ FINAL CHECK - syllable_analysis sample: {out['syllable_analysis'][:2] if out['syllable_analysis'] else 'EMPTY'}")
    
    syllable_analysis = [SyllableAnalysis(**s) for s in out.get("syllable_analysis", [])]
    print(f"ğŸ¯ FINAL CHECK - Pydantic syllable_analysis length: {len(syllable_analysis)}")
    return RefAnalysis(
        curve=curve, 
        syllables=syll, 
        syllable_analysis=syllable_analysis,
        stats=out["stats"]
    )

@app.post("/api/save_session")
async def save_session(request: Request):
    """Save analysis session data"""
    try:
        data = await request.json()
        print(f"ğŸ¯ Saving session data: {len(data)} items")
        # Here you would typically save to database
        return JSONResponse({"status": "success", "message": "Session saved"})
    except Exception as e:
        print(f"Save session error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.post("/api/record_realtime")
async def record_realtime(
    audio_data: UploadFile = File(...),
    session_id: str = Form(None)
):
    """Real-time audio recording and analysis endpoint"""
    try:
        print("ğŸ¯ Real-time recording received")
        audio_bytes = await audio_data.read()
        
        # Process real-time audio with Praat algorithms
        # Handle webm files from browser recording
        if audio_data.filename and audio_data.filename.endswith('.webm'):
            # Save as webm first, then convert to wav
            with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as temp_webm:
                temp_webm.write(audio_bytes)
                temp_webm_path = temp_webm.name
            
            # Convert webm to wav using FFmpeg
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                temp_audio_path = temp_wav.name
            
            import subprocess
            result = subprocess.run([
                'ffmpeg', '-i', temp_webm_path, '-ar', '16000', '-ac', '1', 
                '-y', temp_audio_path
            ], capture_output=True, text=True)
            
            os.unlink(temp_webm_path)  # Clean up webm file
            
            if result.returncode != 0:
                raise Exception(f"FFmpeg conversion failed: {result.stderr}")
        else:
            # Direct wav file
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
                temp_audio.write(audio_bytes)
                temp_audio_path = temp_audio.name
        
        try:
            snd = pm.Sound(temp_audio_path)
            
            # Quick pitch analysis for real-time
            pitch = snd.to_pitch_ac(
                time_step=0.01,
                pitch_floor=75.0,
                pitch_ceiling=600.0,
                very_accurate=False  # Faster for real-time
            )
            
            times = pitch.xs()
            f0_values = []
            for t in times:
                f0 = pitch.get_value_at_time(t)
                if f0 is not None and not np.isnan(f0):
                    f0_values.append({"t": t, "f0": f0})
            
            print(f"ğŸ¯ Real-time analysis: {len(f0_values)} pitch points")
            
        finally:
            os.unlink(temp_audio_path)
        
        # ğŸ¯ ê°œì„ ëœ ì‹¤ì‹œê°„ ì‘ë‹µ: Hz, semitone, Q-tone ëª¨ë“  ë‹¨ìœ„ í¬í•¨
        enhanced_f0_values = []
        for f0_data in f0_values[-10:]:  # ìµœê·¼ 10ê°œ í¬ì¸íŠ¸ë§Œ
            f0 = f0_data['f0']
            # ğŸ¯ ì„±ë³„ ì¶”ì • ê¸°ë°˜ ìµœì í™” (ì‹¤ì‹œê°„ì—ì„œëŠ” ì£¼íŒŒìˆ˜ ë²”ìœ„ë¡œ ì¶”ì •)
            estimated_gender = 'female' if f0 > 180 else 'male'
            semitone_base = 200 if estimated_gender == 'female' else 150
            qtone_base = 130  # Q-tone í‘œì¤€ ê¸°ì¤€
            
            enhanced_f0_values.append({
                "t": f0_data['t'],
                "f0": f0,
                "semitone": 12 * np.log2(f0 / semitone_base) if f0 > 0 else 0.0,
                "qtone": 5 * np.log2(f0 / qtone_base) if f0 > 0 else 0.0,
                "estimated_gender": estimated_gender
            })
        
        return JSONResponse({
            "status": "success",
            "pitch_data": enhanced_f0_values,
            "duration": snd.duration if 'snd' in locals() else 0,
            "units": ["hz", "semitone", "qtone"]  # ì§€ì›ë˜ëŠ” ë‹¨ìœ„ ëª…ì‹œ
        })
        
    except Exception as e:
        print(f"Real-time analysis error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

# Database dependency
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.post("/api/save_reference")
async def save_reference_file(
    title: str = Form(...),
    description: str = Form(""),
    sentence_text: str = Form(""),
    wav_file: UploadFile = File(...),
    textgrid_file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """ì°¸ì¡° íŒŒì¼ì„ ì„œë²„ì— ì €ì¥"""
    try:
        # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        file_id = str(uuid.uuid4())
        wav_filename = f"{file_id}_{wav_file.filename}"
        textgrid_filename = f"{file_id}_{textgrid_file.filename}"
        
        # íŒŒì¼ ì €ì¥
        wav_path = UPLOAD_DIR / wav_filename
        textgrid_path = UPLOAD_DIR / textgrid_filename
        
        with open(wav_path, "wb") as f:
            shutil.copyfileobj(wav_file.file, f)
        
        with open(textgrid_path, "wb") as f:
            shutil.copyfileobj(textgrid_file.file, f)
        
        # íŒŒì¼ í¬ê¸° ê³„ì‚°
        file_size = wav_path.stat().st_size + textgrid_path.stat().st_size
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ ìŒì ˆ ìˆ˜ ë¶„ì„
        try:
            snd = pm.Sound(str(wav_path))
            duration = snd.duration
            
            # TextGridì—ì„œ ìŒì ˆ ìˆ˜ ì¶”ì¶œ
            tg = pm.TextGrid.read_from_file(str(textgrid_path))
            syllable_count = len([tier for tier in tg.tiers if tier.name == "syllables"])
            if syllable_count == 0:
                syllable_count = len(tg.tiers[0].intervals) if tg.tiers else 0
        except:
            duration = 0.0
            syllable_count = 0
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        ref_file = ReferenceFile(
            title=title,
            description=description,
            sentence_text=sentence_text,
            wav_filename=wav_filename,
            textgrid_filename=textgrid_filename,
            file_size=file_size,
            duration=duration,
            syllable_count=syllable_count,
            is_public=True
        )
        
        db.add(ref_file)
        db.commit()
        db.refresh(ref_file)
        
        return JSONResponse({
            "status": "success",
            "message": "ì°¸ì¡° íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "file_id": ref_file.id
        })
        
    except Exception as e:
        print(f"Save reference file error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.get("/api/reference_files")
async def get_reference_files():
    """ì €ì¥ëœ ì°¸ì¡° íŒŒì¼ ëª©ë¡ ì¡°íšŒ - íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜"""
    try:
        # ì§ì ‘ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì¡° ë°˜ì˜
        reference_dir = "static/reference_files"
        if not os.path.exists(reference_dir):
            return JSONResponse({"files": []})
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ WAV íŒŒì¼ë“¤ ì°¾ê¸°
        wav_files = []
        for filename in os.listdir(reference_dir):
            if filename.endswith('.wav'):
                base_name = filename[:-4]  # .wav ì œê±°
                textgrid_file = base_name + '.TextGrid'
                textgrid_path = os.path.join(reference_dir, textgrid_file)
                
                if os.path.exists(textgrid_path):
                    # íŒŒì¼ í¬ê¸° ë° ì§€ì†ì‹œê°„ ê³„ì‚°
                    wav_path = os.path.join(reference_dir, filename)
                    file_size = os.path.getsize(wav_path)
                    
                    # ğŸ¯ ì‹¤ì œ ì˜¤ë””ì˜¤ ì§€ì†ì‹œê°„ê³¼ ì„±ë³„ ë¶„ì„
                    duration = 0.0
                    detected_gender = "female"  # ê¸°ë³¸ê°’
                    average_f0 = 0.0
                    
                    try:
                        import parselmouth as pm
                        sound = pm.Sound(wav_path)
                        duration = sound.get_total_duration()
                        
                        # ì„±ë³„ ìë™ ê°ì§€ë¥¼ ìœ„í•œ í”¼ì¹˜ ë¶„ì„
                        pitch = sound.to_pitch()
                        f0_values = []
                        for i in range(pitch.get_number_of_frames()):
                            f0 = pitch.get_value_in_frame(i + 1)
                            if not np.isnan(f0) and f0 > 0:
                                f0_values.append(f0)
                        
                        if f0_values:
                            average_f0 = np.mean(f0_values)
                            # ì„±ë³„ ê°ì§€ (165Hz ê¸°ì¤€)
                            detected_gender = "male" if average_f0 < 165.0 else "female"
                        
                        print(f"ğŸ¯ {filename}: {duration:.2f}ì´ˆ, í‰ê· F0={average_f0:.1f}Hz, ì„±ë³„={detected_gender}")
                    except Exception as e:
                        print(f"ğŸ¯ {filename}: ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨ - {e}")
                        duration = 0.0
                    
                    # íŒŒì¼ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì œëª© ìƒì„±
                    title = base_name.replace('_', ' ').replace('-', ' ')
                    if base_name == "ì˜¬ë¼ê°€":
                        title = "ì–´ë””ê¹Œì§€ ì˜¬ë¼ê°€ëŠ” ê±°ì˜ˆìš”"
                    elif base_name == "ë‚´ë ¤ê°€":
                        title = "ì–´ë””ê¹Œì§€ ë‚´ë ¤ê°€ëŠ” ê±°ì˜ˆìš”"
                    elif base_name == "ë‚´ì¹œêµ¬":
                        title = "ë‚´ ì¹œêµ¬ê°€ ë©´ì ‘ì— í•©ê²©í–ˆëŒ€"
                    elif base_name == "friend_interview":
                        title = "ë‚´ ì¹œêµ¬ê°€ ë©´ì ‘ì— í•©ê²©í–ˆëŒ€ (ìƒˆë²„ì „)"
                    elif base_name == "ë­ë¼ê³ ê·¸ëŸ¬ì…¨ì†Œ":
                        title = "ë­ë¼ê³  ê·¸ëŸ¬ì…¨ì†Œ"
                    elif base_name == "ë‰´ìŠ¤ì½ê¸°":
                        title = "ë‰´ìŠ¤ ì½ê¸°"
                    elif base_name == "ë‚­ë…ë¬¸ì¥":
                        title = "ë‚­ë… ë¬¸ì¥"
                    
                    wav_files.append({
                        "id": base_name,
                        "title": title,
                        "description": f"{title} ì—°ìŠµìš© ì°¸ì¡° ìŒì„±",
                        "sentence_text": title,
                        "duration": duration,
                        "syllable_count": 0,
                        "file_size": file_size,
                        "detected_gender": detected_gender,
                        "average_f0": average_f0,
                        "created_at": "2025-01-01T00:00:00",
                        "wav": filename,
                        "textgrid": textgrid_file
                    })
        
        # ğŸ¯ ì‚¬ìš©ì ì§€ì • ìˆœì„œë¡œ ì •ë ¬
        custom_order = [
            "ì•ˆë…•í•˜ì„¸ìš”", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "ë°˜ê°€ì›Œìš”", "ì˜¬ë¼ê°€", "ë‚´ë ¤ê°€", 
            "ë­ë¼ê³ ê·¸ëŸ¬ì…¨ì†Œ", "ì•„ì£¼ì˜ë³´ì´ë„¤ìš”", "ë‚­ë…ë¬¸ì¥", "ë‰´ìŠ¤ì½ê¸°"
        ]
        
        # ìˆœì„œ ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë ¬
        def get_sort_key(file_item):
            base_name = file_item["id"]
            try:
                return custom_order.index(base_name)
            except ValueError:
                return len(custom_order)  # ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” íŒŒì¼ì€ ë§¨ ë’¤ë¡œ
        
        wav_files.sort(key=get_sort_key)
        
        print(f"ğŸ¯ Found {len(wav_files)} reference files")
        return JSONResponse({"files": wav_files})
        
    except Exception as e:
        print(f"Get reference files error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.get("/api/reference_files/{file_id}/wav")
async def get_reference_wav(file_id: str):
    """ì €ì¥ëœ WAV íŒŒì¼ ë‹¤ìš´ë¡œë“œ - íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜"""
    try:
        wav_path = f"static/reference_files/{file_id}.wav"
        if not os.path.exists(wav_path):
            raise HTTPException(status_code=404, detail="WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ¯ Serving WAV file: {wav_path}")
        return FileResponse(wav_path, media_type="audio/wav", filename=f"{file_id}.wav")
        
    except Exception as e:
        print(f"Get reference WAV error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analyze/{file_id}")
async def analyze_reference_file(file_id: str):
    """ì°¸ì¡° íŒŒì¼ ë¶„ì„ - ê¸°ì¡´ íŒŒì¼ë¡œë¶€í„° ë¶„ì„ ìˆ˜í–‰"""
    try:
        print(f"ğŸ¯ Analyzing reference file: {file_id}")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        wav_path = f"static/reference_files/{file_id}.wav"
        tg_path = f"static/reference_files/{file_id}.TextGrid"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(wav_path):
            raise HTTPException(status_code=404, detail=f"WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {wav_path}")
        if not os.path.exists(tg_path):
            raise HTTPException(status_code=404, detail=f"TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {tg_path}")
        
        # íŒŒì¼ ë¶„ì„ ìˆ˜í–‰ (ê¸°ì¡´ analyze_ref ë¡œì§ ì¬ì‚¬ìš©)
        import parselmouth as pm
        
        try:
            snd = pm.Sound(wav_path)
            tg = pm.TextGrid.read(tg_path)
            
            print(f"ğŸ¯ Successfully loaded: {wav_path} and {tg_path}")
            
            # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            duration = snd.get_total_duration()
            pitch = snd.to_pitch(time_step=0.01, pitch_floor=75.0, pitch_ceiling=500.0)
            
            # ê¸°ë³¸ í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
            times = pitch.xs()
            valid_points = []
            
            for t in times:
                f0 = pitch.get_value_at_time(t)
                if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                    valid_points.append({"time": float(t), "frequency": float(f0)})
            
            return {
                "success": True,
                "file_id": file_id,
                "duration": float(duration),
                "pitch_data": valid_points[:100],  # ì²˜ìŒ 100ê°œ í¬ì¸íŠ¸ë§Œ
                "total_points": len(valid_points),
                "message": f"ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤: {len(valid_points)}ê°œ í”¼ì¹˜ í¬ì¸íŠ¸"
            }
            
        except Exception as parse_error:
            print(f"âŒ Parselmouth parsing error: {parse_error}")
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(parse_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Analyze reference file error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/reference_files/{file_id}/pitch")
async def get_reference_pitch(file_id: str, syllable_only: bool = False):
    """ì°¸ì¡° íŒŒì¼ì˜ í”¼ì¹˜ ë°ì´í„° ë°˜í™˜ - Chart.jsì—ì„œ ì‚¬ìš©"""
    try:
        print(f"ğŸ¯ Getting pitch data for reference file: {file_id} (syllable_only={syllable_only})")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        wav_path = f"static/reference_files/{file_id}.wav"
        tg_path = f"static/reference_files/{file_id}.TextGrid"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(wav_path):
            raise HTTPException(status_code=404, detail=f"WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {wav_path}")
        
        # íŒŒì¼ ë¶„ì„ ìˆ˜í–‰
        import parselmouth as pm
        
        try:
            snd = pm.Sound(wav_path)
            print(f"ğŸ¯ Successfully loaded WAV: {wav_path}")
            
            # í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
            pitch = snd.to_pitch(time_step=0.01, pitch_floor=75.0, pitch_ceiling=500.0)
            times = pitch.xs()
            
            if syllable_only:
                # ğŸ¯ ìŒì ˆë³„ ëŒ€í‘œ í¬ì¸íŠ¸ë§Œ ë°˜í™˜
                return await get_syllable_representative_pitch(file_id, wav_path, tg_path, snd, pitch)
            else:
                # ğŸ¯ ëª¨ë“  í”¼ì¹˜ í¬ì¸íŠ¸ ë°˜í™˜ (ê¸°ì¡´ ë™ì‘)
                pitch_points = []
                for t in times:
                    f0 = pitch.get_value_at_time(t)
                    if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                        pitch_points.append({
                            "time": float(t), 
                            "frequency": float(f0)
                        })
                
                print(f"ğŸ¯ Extracted {len(pitch_points)} pitch points")
                return JSONResponse(pitch_points)
            
        except Exception as parse_error:
            print(f"âŒ Parselmouth parsing error: {parse_error}")
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(parse_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Get reference pitch error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def get_syllable_representative_pitch(file_id: str, wav_path: str, tg_path: str, snd, pitch):
    """ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ í¬ì¸íŠ¸ ê³„ì‚°"""
    try:
        # TextGrid íŒŒì¼ ë¡œë“œ
        if not os.path.exists(tg_path):
            print(f"ğŸ¯ No TextGrid file found: {tg_path}")
            return JSONResponse([])
        
        # TextGrid íŒŒì‹± (ê¸°ì¡´ ì •ê·œì‹ ë¡œì§ ì¬ì‚¬ìš©)
        syllables = []
        try:
            # UTF-16 ì¸ì½”ë”©ìœ¼ë¡œ TextGrid íŒŒì¼ ì½ê¸°
            encodings_to_try = ['utf-16', 'utf-16-le', 'utf-16-be', 'utf-8', 'cp949']
            content = None
            
            for encoding in encodings_to_try:
                try:
                    with open(tg_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    print(f"âœ… TextGrid íŒŒì¼ ì½ê¸° ì„±ê³µ: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print(f"âŒ TextGrid íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {tg_path}")
                return JSONResponse([])
                
            # ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ìŒì ˆ êµ¬ê°„ ì¶”ì¶œ
            import re
            interval_pattern = r'intervals\s*\[\s*(\d+)\s*\]:\s*\n\s*xmin\s*=\s*([0-9.]+)\s*\n\s*xmax\s*=\s*([0-9.]+)\s*\n\s*text\s*=\s*"([^"]*)"'
            
            matches = re.findall(interval_pattern, content, re.MULTILINE)
            print(f"ğŸ¯ ì •ê·œì‹ ë§¤ì¹­ ê²°ê³¼: {len(matches)}ê°œ êµ¬ê°„ ë°œê²¬")
            
            for i, (index, xmin, xmax, text) in enumerate(matches):
                if text.strip() and text.strip().lower() not in ['', 'sp', 'sil', '<p:>', 'p']:
                    syllables.append({
                        "label": text.strip(),
                        "start": float(xmin),
                        "end": float(xmax),
                        "duration": float(xmax) - float(xmin)
                    })
                    print(f"  ğŸ¯ ìŒì ˆ {i+1}: '{text}' ({xmin}s-{xmax}s)")
                    
        except Exception as e:
            print(f"ğŸš¨ TextGrid íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return JSONResponse([])
        
        if not syllables:
            print(f"ğŸ¯ No syllables found in TextGrid")
            return JSONResponse([])
        
        # í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
        times = pitch.xs()
        valid_points = []
        for t in times:
            f0 = pitch.get_value_at_time(t)
            if f0 and not np.isnan(f0) and 75.0 < f0 < 500.0:
                valid_points.append((float(t), float(f0)))
        
        print(f"ğŸ¯ Processing {len(syllables)} syllables with {len(valid_points)} pitch points")
        
        syllable_pitch_points = []
        
        # ê° ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚°
        for syl in syllables:
            start_t = syl['start']
            end_t = syl['end'] 
            center_t = (start_t + end_t) / 2
            label = syl['label']
            
            # ìŒì ˆ êµ¬ê°„ ë‚´ í”¼ì¹˜ ë°ì´í„° ì°¾ê¸°
            syllable_data = [(t, f0) for t, f0 in valid_points 
                           if start_t <= t <= end_t]
            
            if len(syllable_data) >= 2:
                # ì¤‘ì•™ê°’ ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
                pitches = [f0 for t, f0 in syllable_data]
                representative_f0 = float(np.median(pitches))
                print(f"  ğŸ¯ '{label}': {len(syllable_data)}ê°œ â†’ {representative_f0:.1f}Hz")
            elif len(syllable_data) == 1:
                representative_f0 = syllable_data[0][1]
                print(f"  ğŸ¯ '{label}': 1ê°œ â†’ {representative_f0:.1f}Hz")
            else:
                # ê°€ì¥ ê°€ê¹Œìš´ í”¼ì¹˜ í¬ì¸íŠ¸ ì‚¬ìš©
                if valid_points:
                    distances = [(abs(t - center_t), f0) for t, f0 in valid_points]
                    distances.sort()
                    representative_f0 = distances[0][1] if distances else 200.0
                    print(f"  ğŸ¯ '{label}': ìµœê·¼ì ‘ â†’ {representative_f0:.1f}Hz")
                else:
                    representative_f0 = 200.0
                    print(f"  ğŸ¯ '{label}': ê¸°ë³¸ê°’ â†’ {representative_f0:.1f}Hz")
            
            syllable_pitch_points.append({
                "time": float(center_t),  # ìŒì ˆ ì¤‘ì‹¬ ì‹œê°„
                "frequency": representative_f0,
                "syllable": label,
                "start": float(start_t),  # âœ… ì‹¤ì œ ì‹œì‘ ì‹œê°„ ì¶”ê°€
                "end": float(end_t),      # âœ… ì‹¤ì œ ë ì‹œê°„ ì¶”ê°€
                "duration": float(end_t - start_t)  # âœ… ì§€ì† ì‹œê°„ ì¶”ê°€
            })
        
        print(f"ğŸ¯ Returning {len(syllable_pitch_points)} syllable representative points")
        return JSONResponse(syllable_pitch_points)
        
    except Exception as e:
        print(f"âŒ Syllable pitch calculation error: {e}")
        return JSONResponse([])

@app.get("/api/reference_files/{file_id}/textgrid")
async def get_reference_textgrid(file_id: str):
    """ì €ì¥ëœ TextGrid íŒŒì¼ ë‹¤ìš´ë¡œë“œ - íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜"""
    try:
        tg_path = f"static/reference_files/{file_id}.TextGrid"
        if not os.path.exists(tg_path):
            raise HTTPException(status_code=404, detail="TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ¯ Serving TextGrid file: {tg_path}")
        return FileResponse(tg_path, media_type="text/plain", filename=f"{file_id}.TextGrid")
        
    except Exception as e:
        print(f"Get reference TextGrid error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/syllable_pitch_analysis")
async def get_syllable_pitch_analysis():
    """ëª¨ë“  ì°¸ì¡° íŒŒì¼ì˜ ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ë¥¼ ë‚¨ì„±/ì—¬ì„± ë²„ì „ìœ¼ë¡œ ì¶”ì¶œ"""
    try:
        reference_dir = "static/reference_files"
        if not os.path.exists(reference_dir):
            return JSONResponse({"analysis": []})
        
        analysis_results = []
        
        # ëª¨ë“  WAV íŒŒì¼ì— ëŒ€í•´ ë¶„ì„
        for filename in os.listdir(reference_dir):
            if filename.endswith('.wav'):
                base_name = filename[:-4]
                textgrid_file = base_name + '.TextGrid'
                wav_path = os.path.join(reference_dir, filename)
                tg_path = os.path.join(reference_dir, textgrid_file)
                
                if os.path.exists(tg_path):
                    print(f"ğŸ¯ ìŒì ˆ í”¼ì¹˜ ë¶„ì„: {base_name}")
                    
                    # ë‚¨ì„±/ì—¬ì„± ë²„ì „ìœ¼ë¡œ ê°ê° ë¶„ì„ (Sound ê°ì²´ ìƒì„± í•„ìš”)
                    male_sound = pm.Sound(wav_path)
                    male_tg = pm.read(tg_path)
                    male_analysis = extract_ref_praat_implementation(
                        male_sound, male_tg, 75.0, 300.0, 0.01
                    )
                    
                    female_sound = pm.Sound(wav_path)
                    female_tg = pm.read(tg_path)
                    female_analysis = extract_ref_praat_implementation(
                        female_sound, female_tg, 100.0, 600.0, 0.01
                    )
                    
                    # ì°¸ì¡° ìŒì„± ì„±ë³„ ê°ì§€
                    ref_gender = detect_reference_gender(male_analysis['stats']['meanF0'])
                    
                    # ì„±ë³„ë³„ ì •ê·œí™” ì ìš©
                    male_normalized = apply_gender_normalization(
                        male_analysis, target_gender=ref_gender, learner_gender="male"
                    )
                    
                    female_normalized = apply_gender_normalization(
                        female_analysis, target_gender=ref_gender, learner_gender="female"
                    )
                    
                    # ìŒì ˆ ëŒ€í‘œ í”¼ì¹˜ ì¶”ì¶œ
                    male_syllables = []
                    female_syllables = []
                    
                    if 'syllable_analysis' in male_normalized:
                        for syl in male_normalized['syllable_analysis']:
                            male_syllables.append({
                                'label': syl['label'],
                                'start_time': syl['start_time'],
                                'end_time': syl['end_time'],
                                'duration': syl['duration'],
                                'f0_hz': syl['f0'],
                                'semitone': syl['semitone'],
                                'center_time': syl['center_time']
                            })
                    
                    if 'syllable_analysis' in female_normalized:
                        for syl in female_normalized['syllable_analysis']:
                            female_syllables.append({
                                'label': syl['label'],
                                'start_time': syl['start_time'],
                                'end_time': syl['end_time'],
                                'duration': syl['duration'],
                                'f0_hz': syl['f0'],
                                'semitone': syl['semitone'],
                                'center_time': syl['center_time']
                            })
                    
                    analysis_results.append({
                        'sentence_id': base_name,
                        'reference_gender': ref_gender,
                        'duration': male_analysis['stats']['duration'],
                        'male_version': {
                            'base_frequency': 120.0,  # ë‚¨ì„± ê¸°ì¤€ ì£¼íŒŒìˆ˜
                            'syllables': male_syllables
                        },
                        'female_version': {
                            'base_frequency': 220.0,  # ì—¬ì„± ê¸°ì¤€ ì£¼íŒŒìˆ˜
                            'syllables': female_syllables
                        }
                    })
                    
                    print(f"   âœ… {base_name}: {len(male_syllables)}ê°œ ìŒì ˆ, ì°¸ì¡°ì„±ë³„={ref_gender}")
        
        print(f"ğŸ¯ ì „ì²´ ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ ë¬¸ì¥")
        return JSONResponse({"analysis": analysis_results})
        
    except Exception as e:
        print(f"Syllable pitch analysis error: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.delete("/api/reference_files/{file_id}")
async def delete_reference_file(file_id: int, db: Session = Depends(get_db)):
    """ì €ì¥ëœ ì°¸ì¡° íŒŒì¼ ì‚­ì œ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ
        ref_file = db.query(ReferenceFile).filter(ReferenceFile.id == file_id).first()
        if not ref_file:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ íŒŒì¼ë“¤ ì‚­ì œ
        wav_path = UPLOAD_DIR / ref_file.wav_filename
        textgrid_path = UPLOAD_DIR / ref_file.textgrid_filename
        
        # WAV íŒŒì¼ ì‚­ì œ
        if wav_path.exists():
            wav_path.unlink()
            print(f"ğŸ—‘ï¸ Deleted WAV file: {wav_path}")
        else:
            print(f"âš ï¸ WAV file not found: {wav_path}")
        
        # TextGrid íŒŒì¼ ì‚­ì œ
        if textgrid_path.exists():
            textgrid_path.unlink()
            print(f"ğŸ—‘ï¸ Deleted TextGrid file: {textgrid_path}")
        else:
            print(f"âš ï¸ TextGrid file not found: {textgrid_path}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë ˆì½”ë“œ ì‚­ì œ
        db.delete(ref_file)
        db.commit()
        
        print(f"ğŸ—‘ï¸ Successfully deleted reference file {file_id}: {ref_file.title}")
        
        return JSONResponse({
            "status": "success", 
            "message": f"ì°¸ì¡° íŒŒì¼ '{ref_file.title}'ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
        
    except Exception as e:
        db.rollback()
        print(f"Delete reference file error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/uploaded_files/{file_id}")
async def delete_uploaded_file(file_id: str):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ (WAV + TextGrid)"""
    try:
        # íŒŒì¼ ID ê²€ì¦
        if not file_id or file_id.strip() == '':
            raise HTTPException(status_code=400, detail="íŒŒì¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„±
        wav_path = UPLOAD_DIR / f"{file_id}.wav"
        textgrid_path = UPLOAD_DIR / f"{file_id}.TextGrid"
        
        deleted_files = []
        
        # WAV íŒŒì¼ ì‚­ì œ
        if wav_path.exists():
            wav_path.unlink()
            deleted_files.append("WAV")
            print(f"ğŸ—‘ï¸ Deleted uploaded WAV file: {wav_path}")
        else:
            print(f"âš ï¸ Upload WAV file not found: {wav_path}")
        
        # TextGrid íŒŒì¼ ì‚­ì œ
        if textgrid_path.exists():
            textgrid_path.unlink()
            deleted_files.append("TextGrid")
            print(f"ğŸ—‘ï¸ Deleted uploaded TextGrid file: {textgrid_path}")
        else:
            print(f"âš ï¸ Upload TextGrid file not found: {textgrid_path}")
        
        if not deleted_files:
            raise HTTPException(status_code=404, detail="ì‚­ì œí•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"ğŸ—‘ï¸ Successfully deleted uploaded file {file_id}: {', '.join(deleted_files)} files")
        
        return JSONResponse({
            "status": "success",
            "message": f"ì—…ë¡œë“œ íŒŒì¼ '{file_id}'ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "deleted_files": deleted_files
        })
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Delete uploaded file error: {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@app.post("/analyze_live_audio")
async def analyze_live_audio(audio: UploadFile = File(...)):
    """ğŸ¯ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Praat ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì •í™•í•œ í”¼ì¹˜ ë°ì´í„° ë°˜í™˜"""
    try:
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
        audio_data = await audio.read()
        
        # WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        audio_array = np.frombuffer(audio_data, dtype=np.float32)
        
        # ğŸ¯ Parselmouth(Praat) ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì •ë°€ í”¼ì¹˜ ë¶„ì„
        try:
            import soundfile as sf
        except ImportError:
            print("ğŸš¨ soundfile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            raise HTTPException(status_code=500, detail="soundfile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Parselmouthë¡œ ë¶„ì„
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            # NumPy ë°°ì—´ì„ WAV íŒŒì¼ë¡œ ì €ì¥ (16kHz ìƒ˜í”Œë§)
            sf.write(tmp_file.name, audio_array, 16000)
            
            # ğŸ¯ Praat ê³ ì •ë°€ í”¼ì¹˜ ë¶„ì„ ì„¤ì •
            sound = pm.Sound(tmp_file.name)
            pitch = sound.to_pitch(
                time_step=0.01,      # 10ms ê°„ê²©ìœ¼ë¡œ ë¶„ì„
                pitch_floor=75.0,    # ìµœì†Œ 75Hz (ë‚¨ì„± ì €ìŒ)
                pitch_ceiling=500.0, # ìµœëŒ€ 500Hz (ì—¬ì„± ê³ ìŒ)
                max_number_of_candidates=15,  # ì •í™•ë„ í–¥ìƒ
                silence_threshold=0.03,
                voicing_threshold=0.45,
                octave_cost=0.01,
                octave_jump_cost=0.35,
                voiced_unvoiced_cost=0.14
            )
            
            # ğŸ¯ í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ (Praat ê³ ì •ë°€ ë¶„ì„ ê²°ê³¼)
            pitch_values = []
            times = pitch.xs()
            
            for i, time in enumerate(times):
                f0 = pitch.get_value_at_time(time)
                if not np.isnan(f0) and f0 > 0:
                    # ğŸ¯ ì„±ë³„ ì¶”ì • ê¸°ë°˜ ìµœì í™”
                    estimated_gender = 'female' if f0 > 180 else 'male'
                    semitone_base = 200 if estimated_gender == 'female' else 150
                    qtone_base = 130
                    
                    pitch_values.append({
                        "time": float(time),
                        "f0": float(f0),
                        "semitone": float(12 * np.log2(f0 / semitone_base)) if f0 > 0 else 0.0,
                        "qtone": float(5 * np.log2(f0 / qtone_base)) if f0 > 0 else 0.0,
                        "estimated_gender": estimated_gender
                    })
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_file.name)
            
        print(f"ğŸ¯ Praat ë¶„ì„ ì™„ë£Œ: {len(pitch_values)}ê°œ í”¼ì¹˜ í¬ì¸íŠ¸ ì¶”ì¶œ")
        return {"success": True, "pitch_data": pitch_values}
        
    except Exception as e:
        print(f"ğŸ”¥ ì‹¤ì‹œê°„ Praat ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

# Flask-style routes for survey
@app.get("/survey", response_class=HTMLResponse)
async def survey_page(request: Request):
    """Survey selection page"""
    return templates.TemplateResponse("survey.html", {"request": request})

@app.get("/", response_class=HTMLResponse)
async def main_page(request: Request):
    """Main prosody analysis interface"""
    return templates.TemplateResponse("index.html", {"request": request})

# ğŸ¯ ìƒˆë¡œìš´ syllables API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/api/reference_files/{file_id}/syllables")
async def get_reference_file_syllables(file_id: str, db: Session = Depends(get_db)):
    """ğŸ¯ í•µì‹¬ ê¸°ëŠ¥: TextGrid íŒŒì¼ì—ì„œ ì‹¤ì œ ìŒì ˆ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # ğŸ¯ íŒŒì¼ëª…ìœ¼ë¡œ ì§ì ‘ TextGrid íŒŒì¼ ì°¾ê¸° (ë°ì´í„°ë² ì´ìŠ¤ ì˜ì¡´ì„± ì œê±°)
        reference_dir = "static/reference_files"
        textgrid_path = os.path.join(reference_dir, f"{file_id}.TextGrid")
        
        print(f"ğŸ¯ Looking for TextGrid: {textgrid_path}")
        
        if not os.path.exists(textgrid_path):
            print(f"ğŸš¨ TextGrid file not found: {textgrid_path}")
            return []
        
        # ğŸ¯ TextGrid íŒŒì¼ì—ì„œ ìŒì ˆ êµ¬ê°„ ì¶”ì¶œ - ì˜¤ë¦¬ì§€ë„ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        syllables = []
        try:
            # ğŸ¯ UTF-16 ì¸ì½”ë”©ìœ¼ë¡œ TextGrid íŒŒì¼ ì½ê¸° (Praat í‘œì¤€)
            encodings_to_try = ['utf-16', 'utf-16-le', 'utf-16-be', 'utf-8', 'cp949']
            content = None
            
            for encoding in encodings_to_try:
                try:
                    with open(textgrid_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    print(f"âœ… TextGrid íŒŒì¼ ì½ê¸° ì„±ê³µ: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print(f"âŒ TextGrid íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {textgrid_path}")
                return []
                
            # ğŸ¯ ì˜¤ë¦¬ì§€ë„ ì •ê·œì‹ íŒ¨í„´ ì‚¬ìš© (ToneBridge_Implementation_Guide.md)
            import re
            interval_pattern = r'intervals\s*\[\s*(\d+)\s*\]:\s*\n\s*xmin\s*=\s*([0-9.]+)\s*\n\s*xmax\s*=\s*([0-9.]+)\s*\n\s*text\s*=\s*"([^"]*)"'
            
            matches = re.findall(interval_pattern, content, re.MULTILINE)
            print(f"ğŸ¯ ì •ê·œì‹ ë§¤ì¹­ ê²°ê³¼: {len(matches)}ê°œ êµ¬ê°„ ë°œê²¬")
            
            for i, (index, xmin, xmax, text) in enumerate(matches):
                if text.strip() and text.strip().lower() not in ['', 'sp', 'sil', '<p:>', 'p']:  # ë¹ˆ í…ìŠ¤íŠ¸ì™€ ì¹¨ë¬µ êµ¬ê°„ ì œì™¸
                    syllable_data = {
                        "label": text.strip(),
                        "start": float(xmin),
                        "end": float(xmax),
                        "duration": float(xmax) - float(xmin)
                    }
                    syllables.append(syllable_data)
                    print(f"  ğŸ¯ ìŒì ˆ {i+1}: '{text}' ({xmin}s-{xmax}s)")
            
        except Exception as e:
            print(f"ğŸš¨ TextGrid íŒŒì‹± ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
            # Fallback: íŒŒì¼ ë‚´ìš© ìƒ˜í”Œ ì¶œë ¥ìœ¼ë¡œ ë””ë²„ê¹…
            try:
                with open(textgrid_path, 'rb') as f:
                    raw_content = f.read(100)
                print(f"ğŸ” íŒŒì¼ ì‹œì‘ ë°”ì´íŠ¸: {raw_content}")
            except:
                pass
            
        # ğŸ¯ íŒŒì¼ë³„ ê¸°ë³¸ ìŒì ˆ ì •ë³´ (TextGridê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ëŒ€ë¹„)
        if not syllables:
            print(f"ğŸ¯ Using default syllables for {file_id}")
            if file_id == "ë°˜ê°‘ìŠµë‹ˆë‹¤":
                syllables = [
                    {"label": "ë°˜", "start": 0.0, "end": 0.4},
                    {"label": "ê°‘", "start": 0.4, "end": 0.8},
                    {"label": "ìŠµ", "start": 0.8, "end": 1.1},
                    {"label": "ë‹ˆ", "start": 1.1, "end": 1.3},
                    {"label": "ë‹¤", "start": 1.3, "end": 1.4}
                ]
            elif file_id == "ì•ˆë…•í•˜ì„¸ìš”":
                syllables = [
                    {"label": "ì•ˆ", "start": 0.0, "end": 0.2},
                    {"label": "ë…•", "start": 0.2, "end": 0.4},
                    {"label": "í•˜", "start": 0.4, "end": 0.6},
                    {"label": "ì„¸", "start": 0.6, "end": 0.9},
                    {"label": "ìš”", "start": 0.9, "end": 1.1}
                ]
            else:
                # ê¸°ë³¸ ë”ë¯¸ ë°ì´í„°
                syllables = [{"label": "ìŒì ˆ", "start": 0.0, "end": 1.0}]
        
        print(f"ğŸ¯ Returning {len(syllables)} syllables for {file_id}: {[s['label'] for s in syllables]}")
        return syllables
        
    except Exception as e:
        print(f"ğŸš¨ Error in get_reference_file_syllables: {e}")
        return []

# ğŸ¯ ìˆ¨ê²¨ì§„ ìë™ ì •ê·œí™” ê¸°ëŠ¥
from audio_normalization import AutomationProcessor

@app.post("/api/normalize_reference_files")
async def normalize_reference_files():
    """
    ìˆ¨ê²¨ì§„ ìë™ ì •ê·œí™” ê¸°ëŠ¥ - ë‹¨ì¼ ë²„íŠ¼ìœ¼ë¡œ ëª¨ë“  ì°¸ì¡° íŒŒì¼ ì •ê·œí™”
    - ë¬´ìŒ êµ¬ê°„ ì œê±° (ìë™)
    - ë³¼ë¥¨ ì •ê·œí™” (ì¼ì •í•œ ë³¼ë¥¨ìœ¼ë¡œ ì¡°ì •)  
    - ìƒ˜í”Œë ˆì´íŠ¸ ë³€ê²½ (16kHz í‘œì¤€í™”)
    - TextGrid ìë™ ë™ê¸°í™” (WAV í¸ì§‘ì— ë§ì¶¤)
    """
    try:
        reference_dir = "static/reference_files"
        backup_dir = "static/backup_reference_files"
        
        # ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
        if not os.path.exists(backup_dir):
            raise HTTPException(status_code=400, detail="ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            
        # ìë™í™” í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” (16kHz, -20dB í‘œì¤€)
        processor = AutomationProcessor(target_sample_rate=16000, target_db=-20.0)
        
        print("ğŸ¯ ToneBridge ì°¸ì¡° íŒŒì¼ ìë™ ì •ê·œí™” ì‹œì‘...")
        print(f"   ë°±ì—… ì†ŒìŠ¤: {backup_dir}")
        print(f"   ì¶œë ¥ ëŒ€ìƒ: {reference_dir}")
        
        # ëª¨ë“  íŒŒì¼ ìŒ ì²˜ë¦¬
        results = processor.process_directory(reference_dir, backup_dir)
        
        # ê²°ê³¼ ë¶„ì„
        successful = [r for r in results if r['status'] == 'success']
        failed = [r for r in results if r['status'] == 'error']
        skipped = [r for r in results if r['status'] == 'skipped']
        
        print(f"ğŸ¯ ìë™ ì •ê·œí™” ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {len(successful)}ê°œ íŒŒì¼")
        print(f"   ì‹¤íŒ¨: {len(failed)}ê°œ íŒŒì¼") 
        print(f"   ê±´ë„ˆëœ€: {len(skipped)}ê°œ íŒŒì¼")
        
        # ì„±ê³µí•œ íŒŒì¼ë“¤ì˜ ìš”ì•½ ì •ë³´
        summary = {
            'total_processed': len(results),
            'successful': len(successful),
            'failed': len(failed), 
            'skipped': len(skipped),
            'processing_details': []
        }
        
        for result in successful:
            if 'audio_processing' in result:
                audio_info = result['audio_processing']
                summary['processing_details'].append({
                    'file': result['file_name'],
                    'original_duration': audio_info.get('original_duration', 0),
                    'final_duration': audio_info.get('final_duration', 0),
                    'time_ratio': audio_info.get('time_ratio', 1.0),
                    'sample_rate': audio_info.get('sample_rate', 16000),
                    'textgrid_synced': result.get('textgrid_sync', False)
                })
        
        return JSONResponse({
            "status": "success",
            "message": "ì°¸ì¡° íŒŒì¼ ìë™ ì •ê·œí™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "summary": summary,
            "detailed_results": results
        })
        
    except Exception as e:
        print(f"âŒ ìë™ ì •ê·œí™” ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì •ê·œí™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

@app.post("/api/normalize_single_file")  
async def normalize_single_file(file_name: str):
    """
    ë‹¨ì¼ íŒŒì¼ ì •ê·œí™” (í…ŒìŠ¤íŠ¸ìš©)
    Args:
        file_name: íŒŒì¼ëª… (í™•ì¥ì ì œì™¸, ì˜ˆ: "ë‚­ë…ë¬¸ì¥")
    """
    try:
        reference_dir = "static/reference_files"
        backup_dir = "static/backup_reference_files"
        
        wav_file = f"{file_name}.wav"
        textgrid_file = f"{file_name}.TextGrid"
        
        wav_backup = os.path.join(backup_dir, wav_file)
        textgrid_backup = os.path.join(backup_dir, textgrid_file)
        wav_output = os.path.join(reference_dir, wav_file)
        textgrid_output = os.path.join(reference_dir, textgrid_file)
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(wav_backup) or not os.path.exists(textgrid_backup):
            raise HTTPException(status_code=404, detail=f"ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_name}")
            
        # ìë™í™” í”„ë¡œì„¸ì„œë¡œ ì²˜ë¦¬
        processor = AutomationProcessor(target_sample_rate=16000, target_db=-20.0)
        result = processor.process_file_pair(wav_backup, textgrid_backup, wav_output, textgrid_output)
        
        print(f"ğŸ¯ ë‹¨ì¼ íŒŒì¼ ì •ê·œí™” ì™„ë£Œ: {file_name}")
        
        return JSONResponse({
            "status": "success", 
            "message": f"{file_name} íŒŒì¼ ì •ê·œí™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "result": result
        })
        
    except Exception as e:
        print(f"âŒ ë‹¨ì¼ íŒŒì¼ ì •ê·œí™” ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì •ê·œí™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# Initialize processors (shared STT instance to avoid duplication)
automated_processor = AutomatedProcessor()
# Use the STT instance from automated_processor to avoid duplicate initialization
if hasattr(automated_processor.stt, 'advanced_stt') and automated_processor.stt.advanced_stt:
    advanced_stt_processor = automated_processor.stt.advanced_stt
    print("ğŸ”„ ê¸°ì¡´ STT ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©")
else:
    advanced_stt_processor = AdvancedSTTProcessor(preferred_engine='whisper')
    print("ğŸ†• ìƒˆ STT ì¸ìŠ¤í„´ìŠ¤ ìƒì„±")

@app.post("/api/optimize-uploaded-file")
async def optimize_uploaded_file(file_id: str = Form(...), use_ultimate_stt: bool = Form(False)):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì„ 99% ì •í™•ë„ Ultimate STT ì‹œìŠ¤í…œìœ¼ë¡œ ìµœì í™”
    ğŸ¯ í•œêµ­ì–´ íŠ¹í™” ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ â†’ ë‹¤ì¤‘ STT ì—”ì§„ ì•™ìƒë¸” â†’ ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ â†’ ì ì‘í˜• ì¬ì²˜ë¦¬
    """
    # ë¹ˆ íŒŒì¼ID ê²€ì¦
    if not file_id or file_id.strip() == '' or file_id == '()':
        raise HTTPException(status_code=400, detail="íŒŒì¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
    async with ai_processing_lock:  # ë®¤í…ìŠ¤ë¡œ ìˆœì„œ ë³´ì¥
        try:
            wav_file = f"{file_id}.wav"
            wav_path = UPLOAD_DIR / wav_file
            textgrid_path = UPLOAD_DIR / f"{file_id}.TextGrid"
            
            if not wav_path.exists():
                raise HTTPException(status_code=404, detail="WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            print(f"ğŸ¯ğŸ¯ğŸ¯ ì—…ë¡œë“œ íŒŒì¼ Ultimate STT ì²˜ë¦¬ ì‹œì‘: {file_id} ğŸ¯ğŸ¯ğŸ¯")
            
            # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
            parts = file_id.split('_')
            reference_sentence = "ë°˜ê°€ì›Œìš”"  # ê¸°ë³¸ê°’
            if len(parts) >= 4:
                reference_sentence = parts[3]
            
            # ğŸš€ Ultimate STT ì‹œìŠ¤í…œ ì‚¬ìš© (99% ì •í™•ë„)
            if use_ultimate_stt:
                print("ğŸ¯ Ultimate STT ì‹œìŠ¤í…œ ì‚¬ìš© - 99% ì •í™•ë„ ëª©í‘œ")
                
                # ì§€ì—° ë¡œë”©: í•„ìš”í•  ë•Œë§Œ ì´ˆê¸°í™”
                if global_ai_instances.get('ultimate_stt') is None:
                    print("âš¡ Ultimate STT ì²« ì‚¬ìš©: ì´ˆê¸°í™” ì¤‘... (1ë¶„ ì •ë„ ì†Œìš”)")
                    try:
                        global_ai_instances['ultimate_stt'] = UltimateSTTSystem(
                            target_accuracy=0.99,
                            max_reprocessing_attempts=2,
                            quality_threshold=0.95
                        )
                        print("âœ… Ultimate STT ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
                    except Exception as e:
                        print(f"âŒ Ultimate STT ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        # ë°±ì—… ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜
                        print("ğŸ”„ ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ ë°±ì—… ì²˜ë¦¬")
                        from tonebridge_core.pipeline.voice_processor import UnifiedVoiceProcessor
                        advanced_stt = global_ai_instances.get('advanced_stt')
                        unified_processor = UnifiedVoiceProcessor(shared_stt_processor=advanced_stt)
                        process_result = unified_processor.process_uploaded_file(str(wav_path), reference_sentence)
                        result = process_result.to_legacy_dict()
                
                ultimate_stt = global_ai_instances.get('ultimate_stt')
                if ultimate_stt:
                    ultimate_result = await ultimate_stt.process_audio_ultimate(
                    str(wav_path), 
                    reference_sentence,
                    enable_reprocessing=True
                )
                
                # Ultimate STT ê²°ê³¼ë¥¼ ê¸°ì¡´ API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                result = {
                    'success': ultimate_result.accuracy_achieved >= 0.8,  # 80% ì´ìƒì´ë©´ ì„±ê³µ
                    'transcription': ultimate_result.final_text,
                    'confidence': ultimate_result.confidence,
                    'accuracy_achieved': ultimate_result.accuracy_achieved,
                    'processing_time': ultimate_result.total_processing_time,
                    'reprocessing_attempts': ultimate_result.reprocessing_attempts,
                    'quality_score': ultimate_result.final_quality_score
                }
                
                # ìŒì ˆ ë°ì´í„° ì¶”ì¶œ (Ultimate STT ê²°ê³¼ì—ì„œ)
                syllables = []
                if ultimate_result.final_text:
                    # ê°„ë‹¨í•œ ìŒì ˆ ë¶„í•  (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì²˜ë¦¬ í•„ìš”)
                    korean_syllables = [c for c in ultimate_result.final_text.replace(' ', '') if 0xAC00 <= ord(c) <= 0xD7A3]
                    if korean_syllables:
                        duration_per_syllable = 0.25  # ê¸°ë³¸ê°’
                        for i, syllable in enumerate(korean_syllables):
                            start_time = i * duration_per_syllable
                            end_time = (i + 1) * duration_per_syllable
                            syllables.append({
                                'label': syllable,
                                'start': start_time,
                                'end': end_time,
                                'confidence': ultimate_result.confidence
                            })
                
                result['syllables'] = syllables
                result['duration'] = len(syllables) * 0.25 if syllables else 1.0
                
                print(f"âœ… Ultimate STT ì™„ë£Œ: ì •í™•ë„ {ultimate_result.accuracy_achieved:.1%}, ì‹ ë¢°ë„ {ultimate_result.confidence:.3f}")
                
            else:
                # ğŸ”„ ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš© (ë°±ì—…)
                print("ğŸ”§ ê¸°ì¡´ í†µí•© í”„ë¡œì„¸ì„œ ì‚¬ìš©: ë°±ì—… ì²˜ë¦¬")
                from tonebridge_core.pipeline.voice_processor import UnifiedVoiceProcessor
                
                # ì „ì—­ STT ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
                advanced_stt = global_ai_instances.get('advanced_stt')
                unified_processor = UnifiedVoiceProcessor(shared_stt_processor=advanced_stt)
                process_result = unified_processor.process_uploaded_file(str(wav_path), reference_sentence)
                
                # ê¸°ì¡´ API í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                result = process_result.to_legacy_dict()
            
            if result['success']:
                # ìµœì í™”ëœ TextGrid ìƒì„±
                syllables = result.get('syllables', [])
                
                if syllables:
                    # TextGrid íŒŒì¼ ìƒì„±
                    textgrid_content = create_textgrid_from_syllables(syllables, result.get('duration', 1.0))
                    
                    with open(textgrid_path, 'w', encoding='utf-16') as f:
                        f.write(textgrid_content)
                    
                    print(f"âœ… TextGrid ì¬ìƒì„± ì™„ë£Œ: {len(syllables)}ê°œ ìŒì ˆ")
                
                # ìµœì í™”ëœ ì˜¤ë””ì˜¤ ì €ì¥ (0.25ì´ˆ ë§ˆì§„ ì ìš©)
                optimized_audio_path = create_optimized_audio(str(wav_path), syllables)
                if optimized_audio_path:
                    # ì›ë³¸ íŒŒì¼ì„ ìµœì í™”ëœ ë²„ì „ìœ¼ë¡œ êµì²´
                    shutil.move(optimized_audio_path, str(wav_path))
                    print(f"âœ… ì˜¤ë””ì˜¤ ìµœì í™” ì™„ë£Œ")
        
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            response_data = {
                "success": result['success'],
                "file_id": file_id,
                "transcription": result.get('transcription', ''),
                "syllables": result.get('syllables', []),
                "duration": result.get('duration', 0),
                "optimized": True
            }
            
            # Ultimate STT ì¶”ê°€ ì •ë³´ í¬í•¨
            if 'accuracy_achieved' in result:
                response_data.update({
                    "accuracy_achieved": result['accuracy_achieved'],
                    "confidence": result.get('confidence', 0.0),
                    "quality_score": result.get('quality_score', 0.0),
                    "processing_time": result.get('processing_time', 0.0),
                    "reprocessing_attempts": result.get('reprocessing_attempts', 0),
                    "ultimate_stt_used": True
                })
            else:
                response_data["ultimate_stt_used"] = False
            
            return response_data
            
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ìµœì í™” ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail=f"ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")

def create_textgrid_from_syllables(syllables, duration):
    """ìŒì ˆ ë°ì´í„°ë¡œë¶€í„° TextGrid ìƒì„± - ì§ì ‘ ìƒì„± ë°©ì‹"""
    print(f"ğŸ¯ TextGrid ìƒì„±: {len(syllables)}ê°œ ìŒì ˆ, ì§€ì†ì‹œê°„: {duration:.3f}ì´ˆ")
    
    # ìŒì ˆ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ ì´ë¦„ ëŒ€ì‘)
    processed_syllables = []
    for i, syl in enumerate(syllables):
        if isinstance(syl, dict):
            # ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ í‚¤ í™•ì¸
            text = syl.get('label', '') or syl.get('text', '') or syl.get('syllable', '') or syl.get('name', '')
            start = syl.get('start', 0.0)
            end = syl.get('end', 0.0)
            
            processed_syllables.append({
                'text': text,
                'start': start,
                'end': end
            })
            print(f"   ìŒì ˆ {i+1}: '{text}' [{start:.3f}s ~ {end:.3f}s]")
    
    # ì§ì ‘ TextGrid ë‚´ìš© ìƒì„±
    textgrid_content = f'''File type = "ooTextFile"
Object class = "TextGrid"

xmin = 0.0
xmax = {duration}
tiers? <exists>
size = 1
item []:
    item [1]:
        class = "IntervalTier"
        name = "syllables"
        xmin = 0.0
        xmax = {duration}
        intervals: size = {len(processed_syllables)}
'''
    
    # ê° ìŒì ˆ êµ¬ê°„ ì¶”ê°€
    for i, syl in enumerate(processed_syllables, 1):
        textgrid_content += f'''        intervals [{i}]:
            xmin = {syl['start']}
            xmax = {syl['end']}
            text = "{syl['text']}"
'''
    
    print(f"âœ… TextGrid ë‚´ìš© ìƒì„± ì™„ë£Œ: {len(processed_syllables)}ê°œ ìŒì ˆ")
    return textgrid_content

def create_optimized_audio(wav_path, syllables):
    """0.25ì´ˆ ë§ˆì§„ì„ ì ìš©í•œ ìµœì í™”ëœ ì˜¤ë””ì˜¤ ìƒì„±"""
    try:
        import tempfile
        
        if not syllables:
            return None
            
        sound = pm.Sound(wav_path)
        
        # ìŒì ˆ êµ¬ê°„ì—ì„œ ìµœì†Œ/ìµœëŒ€ ì‹œê°„ ì°¾ê¸°
        start_times = [s.get('start', 0) for s in syllables if s.get('start') is not None]
        end_times = [s.get('end', 0) for s in syllables if s.get('end') is not None]
        
        if not start_times or not end_times:
            return None
            
        voice_start = max(0, min(start_times) - 0.25)  # 0.25ì´ˆ ë§ˆì§„
        voice_end = min(sound.duration, max(end_times) + 0.25)  # 0.25ì´ˆ ë§ˆì§„
        
        # êµ¬ê°„ ì¶”ì¶œ
        trimmed_sound = sound.extract_part(from_time=voice_start, to_time=voice_end, preserve_times=False)
        
        # ë³¼ë¥¨ ì •ê·œí™” (RMS 0.02)
        values = trimmed_sound.values[0] if trimmed_sound.n_channels > 0 else trimmed_sound.values
        rms = np.sqrt(np.mean(values**2))
        if rms > 0:
            target_rms = 0.02
            amplification_factor = target_rms / rms
            amplification_factor = min(amplification_factor, 10.0)  # ìµœëŒ€ 10ë°°
            
            normalized_values = values * amplification_factor
            normalized_values = np.clip(normalized_values, -0.9, 0.9)
            
            optimized_sound = pm.Sound(normalized_values, sampling_frequency=trimmed_sound.sampling_frequency)
        else:
            optimized_sound = trimmed_sound
        
        # ì„ì‹œ íŒŒì¼ì— ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            optimized_sound.save(tmp_file.name, "WAV")
            return tmp_file.name
            
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ìµœì í™” ì‹¤íŒ¨: {e}")
        return None

@app.post("/api/test-ultimate-stt")
async def test_ultimate_stt_on_uploaded_file(file_id: str = Form(...), expected_text: str = Form("")):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ Ultimate STT 99% ì •í™•ë„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    ğŸ¯ ì‹¤ì‹œê°„ ì •í™•ë„ ì¸¡ì • ë° ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ì œê³µ
    """
    # ë¹ˆ íŒŒì¼ID ê²€ì¦
    if not file_id or file_id.strip() == '' or file_id == '()':
        raise HTTPException(status_code=400, detail="íŒŒì¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
    async with ai_processing_lock:  # ë®¤í…ìŠ¤ë¡œ ìˆœì„œ ë³´ì¥
        try:
            wav_file = f"{file_id}.wav"
            wav_path = UPLOAD_DIR / wav_file
            
            if not wav_path.exists():
                raise HTTPException(status_code=404, detail="WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            print(f"ğŸ§ªğŸ§ªğŸ§ª Ultimate STT í…ŒìŠ¤íŠ¸ ì‹œì‘: {file_id} ğŸ§ªğŸ§ªğŸ§ª")
            
            # íŒŒì¼ëª…ì—ì„œ ê¸°ëŒ€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ ì‚¬ìš©)
            if not expected_text:
                parts = file_id.split('_')
                if len(parts) >= 4:
                    expected_text = parts[3]  # ë°˜ê°€ì›Œìš” ë“±
                else:
                    expected_text = "ë°˜ê°€ì›Œìš”"  # ê¸°ë³¸ê°’
            
            print(f"ğŸ¯ ê¸°ëŒ€ í…ìŠ¤íŠ¸: '{expected_text}'")
            
            # Ultimate STT ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ì§€ì—° ë¡œë”©)
            # ì§€ì—° ë¡œë”©: í•„ìš”í•  ë•Œë§Œ ì´ˆê¸°í™”
            if global_ai_instances.get('ultimate_stt') is None:
                print("âš¡ Ultimate STT ì²« ì‚¬ìš©: ì´ˆê¸°í™” ì¤‘... (1ë¶„ ì •ë„ ì†Œìš”)")
                try:
                    global_ai_instances['ultimate_stt'] = UltimateSTTSystem(
                        target_accuracy=0.99,
                        max_reprocessing_attempts=2,
                        quality_threshold=0.95
                    )
                    print("âœ… Ultimate STT ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
                except Exception as e:
                    print(f"âŒ Ultimate STT ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    raise HTTPException(status_code=503, detail=f"Ultimate STT ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            ultimate_stt = global_ai_instances.get('ultimate_stt')
            if ultimate_stt:
                
                # í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œê°„
                import time
                test_start = time.time()
                
                ultimate_result = await ultimate_stt.process_audio_ultimate(
                    str(wav_path), 
                    expected_text,
                    enable_reprocessing=True
                )
                
                test_duration = time.time() - test_start
                
                # ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ êµ¬ì„±
                test_report = {
                    "success": True,
                    "file_id": file_id,
                    "expected_text": expected_text,
                    "predicted_text": ultimate_result.final_text,
                    "accuracy_achieved": ultimate_result.accuracy_achieved,
                    "target_accuracy": 0.99,
                    "accuracy_met": ultimate_result.accuracy_achieved >= 0.99,
                    "confidence": ultimate_result.confidence,
                    "quality_score": ultimate_result.final_quality_score,
                    "processing_time": ultimate_result.total_processing_time,
                    "total_test_time": test_duration,
                    "reprocessing_attempts": ultimate_result.reprocessing_attempts,
                    
                    # ìƒì„¸ ë¶„ì„
                    "processing_stages": ultimate_result.processing_stages,
                    "audio_optimizations": ultimate_result.audio_optimizations_applied,
                    "stt_engines_used": ultimate_result.stt_engines_used,
                    "quality_improvements": ultimate_result.quality_improvements,
                    
                    # ì„±ëŠ¥ ë“±ê¸‰
                    "performance_grade": "S" if ultimate_result.accuracy_achieved >= 0.99 else 
                                       "A" if ultimate_result.accuracy_achieved >= 0.95 else
                                       "B" if ultimate_result.accuracy_achieved >= 0.90 else
                                       "C" if ultimate_result.accuracy_achieved >= 0.80 else "D",
                    
                    # ì‹œìŠ¤í…œ ìƒíƒœ
                    "system_components": {
                        "korean_optimizer": global_ai_instances.get('korean_optimizer') is not None,
                        "advanced_stt": global_ai_instances.get('advanced_stt') is not None,
                        "ultimate_stt": global_ai_instances.get('ultimate_stt') is not None
                    }
                }
                
                # ì •í™•ë„ë³„ ë©”ì‹œì§€
                if ultimate_result.accuracy_achieved >= 0.99:
                    test_report["result_message"] = "ğŸ¯ 99% ëª©í‘œ ë‹¬ì„±! ì™„ë²½í•œ ì¸ì‹ ì„±ê³µ"
                elif ultimate_result.accuracy_achieved >= 0.95:
                    test_report["result_message"] = "ğŸ¥ˆ 95% ì´ìƒ ë‹¬ì„±! ë§¤ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥"
                elif ultimate_result.accuracy_achieved >= 0.90:
                    test_report["result_message"] = "ğŸ¥‰ 90% ì´ìƒ ë‹¬ì„±! ì¢‹ì€ ì„±ëŠ¥"
                else:
                    test_report["result_message"] = "ğŸ“ˆ ì„±ëŠ¥ ê°œì„  í•„ìš” - ì¬ì²˜ë¦¬ ê¶Œì¥"
                
                print(f"âœ… Ultimate STT í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
                print(f"   ê¸°ëŒ€: '{expected_text}'")
                print(f"   ì˜ˆì¸¡: '{ultimate_result.final_text}'")
                print(f"   ì •í™•ë„: {ultimate_result.accuracy_achieved:.1%}")
                print(f"   ë“±ê¸‰: {test_report['performance_grade']}")
                
                return test_report
                
            else:
                raise HTTPException(status_code=503, detail="Ultimate STT ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ Ultimate STT í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_id": file_id,
                "result_message": "ğŸš¨ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            }

# ì²« ë²ˆì§¸ ì¤‘ë³µ í•¨ìˆ˜ ì œê±°ë¨ - í†µí•©ëœ ë²„ì „ì´ ì•„ë˜ì— ìˆìŒ

@app.post("/api/auto-process")
async def auto_process_audio(
    file: UploadFile = File(...), 
    sentence_hint: str = Form(""), 
    save_permanent: bool = Form(False),
    learner_name: str = Form(""),
    learner_gender: str = Form(""),
    learner_age_group: str = Form(""),
    reference_sentence: str = Form("")
):
    """
    ì™„ì „ ìë™í™”ëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬ API
    STT + ìë™ ë¶„ì ˆ + TextGrid ìƒì„±
    
    Parameters:
    - save_permanent: Trueì‹œ WAV + TextGridë¥¼ uploads/ í´ë”ì— ì˜êµ¬ ì €ì¥
    - learner_name: í•™ìŠµì ì´ë¦„
    - learner_gender: í•™ìŠµì ì„±ë³„ (male/female)
    - learner_age_group: í•™ìŠµì ì—°ë ¹ëŒ€
    - reference_sentence: ì°¸ì¡° ë¬¸ì¥ ì´ë¦„
    """
    if not file.filename or not file.filename.endswith(('.wav', '.mp3', '.m4a', '.webm')):
        raise HTTPException(status_code=400, detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹")
    
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ ë° ë³€í™˜
        content = await file.read()
        
        if file.filename and file.filename.endswith('.webm'):
            # webm íŒŒì¼ì¸ ê²½ìš° FFmpegë¡œ ë³€í™˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as webm_file:
                webm_file.write(content)
                webm_path = webm_file.name
            
            # Parselmouth í˜¸í™˜ì„± ìµœì í™” ë³€í™˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as wav_file:
                tmp_path = wav_file.name
            
            import subprocess
            result = subprocess.run([
                'ffmpeg', '-i', webm_path, 
                '-acodec', 'pcm_s16le',  # 16-bit PCM 
                '-ar', '22050',          # 22kHz ìƒ˜í”Œë§ (Parselmouth í˜¸í™˜)
                '-ac', '1',              # ëª¨ë…¸
                '-y', tmp_path
            ], capture_output=True, text=True)
            
            os.unlink(webm_path)  # webm íŒŒì¼ ì •ë¦¬
            
            if result.returncode != 0:
                raise HTTPException(status_code=400, detail=f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {result.stderr}")
                
            print(f"ğŸµ webm â†’ wav ë³€í™˜ ì™„ë£Œ: {tmp_path}")
        else:
            # ì§ì ‘ wav íŒŒì¼ì¸ ê²½ìš°
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
                tmp_file.write(content)
                tmp_path = tmp_file.name
        
        # ìë™ ì²˜ë¦¬ ì‹¤í–‰
        result = automated_processor.process_audio_completely(tmp_path, sentence_hint)
        
        if result['success']:
            response_data = {
                "success": True,
                "transcription": result['transcription'],
                "syllables": result['syllables'],
                "duration": result['duration'],
                "message": f"âœ… ìë™ ì²˜ë¦¬ ì™„ë£Œ - {len(result['syllables'])}ê°œ ìŒì ˆ ë¶„ì ˆ"
            }
            
            # ì˜êµ¬ ì €ì¥ì´ ìš”ì²­ëœ ê²½ìš°
            if save_permanent:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # ì˜ë¯¸ìˆëŠ” íŒŒì¼ëª… ìƒì„±
                filename_parts = []
                if learner_name:
                    filename_parts.append(learner_name)
                if learner_gender:
                    filename_parts.append(learner_gender)
                if learner_age_group:
                    filename_parts.append(learner_age_group)
                if reference_sentence:
                    filename_parts.append(reference_sentence)
                filename_parts.append(timestamp)
                
                filename = "_".join(filename_parts) if filename_parts else f"recording_{timestamp}"
                
                # ğŸµ ë¬´ìŒ ì œê±° + ë³¼ë¥¨ ì •ê·œí™”ëœ WAV íŒŒì¼ ìƒì„± ë° ì €ì¥
                print(f"ğŸµ ë¬´ìŒ ì œê±° + ë³¼ë¥¨ ì •ê·œí™” ì‹œì‘: {filename}")
                trimmed_path = advanced_stt_processor.create_trimmed_audio(
                    tmp_path, 
                    str(UPLOAD_DIR / f"{filename}_trimmed.wav")
                )
                
                # ìµœì í™”ëœ íŒŒì¼ì„ ìµœì¢… ì €ì¥ (ì‚¬ìš©ìê°€ ì¬ìƒí•  íŒŒì¼)
                wav_path = UPLOAD_DIR / f"{filename}.wav"
                shutil.copy2(trimmed_path, wav_path)
                
                # ì›ë³¸ë„ ë°±ì—…ìœ¼ë¡œ ì €ì¥
                original_wav_path = UPLOAD_DIR / f"{filename}_original.wav"
                shutil.copy2(tmp_path, original_wav_path)
                
                print(f"ğŸ’¾ ìµœì í™”ëœ WAV ì €ì¥: {wav_path}")
                print(f"ğŸ’¾ ì›ë³¸ WAV ë°±ì—…: {original_wav_path}")
                
                # TextGrid íŒŒì¼ ì €ì¥  
                textgrid_path = UPLOAD_DIR / f"{filename}.TextGrid"
                save_textgrid(result['syllables'], str(textgrid_path), result['duration'])
                
                response_data.update({
                    "saved_files": {
                        "wav": str(wav_path),  # ìµœì í™”ëœ íŒŒì¼ (ì¬ìƒìš©)
                        "wav_original": str(original_wav_path),  # ì›ë³¸ íŒŒì¼ (ë°±ì—…ìš©)
                        "textgrid": str(textgrid_path)
                    },
                    "filename": filename,
                    "optimization_applied": True,
                    "message": f"âœ… ë¬´ìŒ ì œê±° + ë³¼ë¥¨ ì •ê·œí™” ì™„ë£Œ - {len(result['syllables'])}ê°œ ìŒì ˆ ë¶„ì ˆ"
                })
                
                print(f"ğŸ’¾ ì˜êµ¬ ì €ì¥ ì™„ë£Œ: {filename}.wav + {filename}.TextGrid")
                print(f"ğŸ“‹ í•™ìŠµì: {learner_name} ({learner_gender}, {learner_age_group})")
                print(f"ğŸ“„ ì—°ìŠµë¬¸ì¥: {reference_sentence}")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì˜êµ¬ ì €ì¥ í›„)
            os.unlink(tmp_path)
            
            return JSONResponse(response_data)
        else:
            # ì‹¤íŒ¨ ì‹œì—ë„ ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.unlink(tmp_path)
            return JSONResponse({
                "success": False,
                "error": result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'),
                "message": "âŒ ìë™ ì²˜ë¦¬ ì‹¤íŒ¨"
            }, status_code=500)
            
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "âŒ ì„œë²„ ì²˜ë¦¬ ì˜¤ë¥˜"
        }, status_code=500)

@app.post("/api/optimize-textgrid/{file_id}")
async def optimize_existing_textgrid(file_id: str, db: Session = Depends(get_db)):
    """
    ê¸°ì¡´ reference íŒŒì¼ì˜ TextGrid ìµœì í™”
    """
    try:
        # DBì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ
        ref_file = db.query(ReferenceFile).filter(ReferenceFile.id == file_id).first()
        if not ref_file:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        audio_path = f"static/reference_files/{ref_file.filename}"
        if not os.path.exists(audio_path):
            raise HTTPException(status_code=404, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        # ìë™ ì²˜ë¦¬ë¡œ TextGrid ì¬ìƒì„±
        result = automated_processor.process_audio_completely(
            audio_path, 
            ref_file.sentence or ""
        )
        
        if result['success']:
            return JSONResponse({
                "success": True,
                "syllables": result['syllables'],
                "transcription": result['transcription'],
                "message": f"âœ… TextGrid ìµœì í™” ì™„ë£Œ - {len(result['syllables'])}ê°œ ìŒì ˆ"
            })
        else:
            return JSONResponse({
                "success": False,
                "error": result.get('error'),
                "message": "âŒ TextGrid ìµœì í™” ì‹¤íŒ¨"
            }, status_code=500)
            
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "âŒ ìµœì í™” ì²˜ë¦¬ ì˜¤ë¥˜"
        }, status_code=500)

@app.get("/api/stt-status")
async def get_stt_status():
    """
    STT(ìŒì„±ì¸ì‹) ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    """
    status = advanced_stt_processor.get_engine_status()
    
    return JSONResponse({
        "current_engine": status['current_engine'],
        "available_engines": status['available_engines'],
        "confidence_threshold": status['confidence_threshold'],
        "status": "ready" if len(status['available_engines']) > 1 else "limited",
        "message": f"ğŸ¤ {status['current_engine']} ì—”ì§„ í™œì„±í™”" if status['current_engine'] != 'local_fallback' else "âš ï¸ ì œí•œëœ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥"
    })

@app.post("/api/advanced-stt")
async def advanced_stt_process(file: UploadFile = File(...), 
                              target_text: str = Form(""),
                              engine: str = Form("auto")):
    """
    ê³ ê¸‰ STT ì²˜ë¦¬ API
    ë‹¤ì¤‘ ì—”ì§„ ì§€ì› ë° ì‹ ë¢°ë„ í‰ê°€
    """
    if not file.filename or not file.filename.endswith(('.wav', '.mp3', '.m4a', '.webm')):
        raise HTTPException(status_code=400, detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹")
    
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        # ì—”ì§„ ì„ íƒ
        if engine != "auto":
            # íŠ¹ì • ì—”ì§„ ìš”ì²­ ì‹œ ìƒˆë¡œ ì´ˆê¸°í™”
            processor = AdvancedSTTProcessor(preferred_engine=engine)
        else:
            processor = advanced_stt_processor
        
        # ê³ ê¸‰ STT ì²˜ë¦¬
        result = processor.process_audio_with_confidence(tmp_path, target_text)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.unlink(tmp_path)
        
        return JSONResponse({
            "success": True,
            "transcription": result['transcription'],
            "syllables": result['syllables'],
            "confidence": result['confidence'],
            "engine": result['engine'],
            "quality_metrics": result['quality_metrics'],
            "word_timestamps": result.get('word_timestamps', []),
            "message": f"âœ… ê³ ê¸‰ STT ì²˜ë¦¬ ì™„ë£Œ ({result['engine']} ì—”ì§„)"
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "âŒ ê³ ê¸‰ STT ì²˜ë¦¬ ì˜¤ë¥˜"
        }, status_code=500)

@app.post("/api/multi-engine-comparison")
async def multi_engine_comparison(file: UploadFile = File(...), 
                                target_text: str = Form("")):
    """
    ë‹¤ì¤‘ STT ì—”ì§„ ë¹„êµ ë¶„ì„
    """
    if not file.filename or not file.filename.endswith(('.wav', '.mp3', '.m4a', '.webm')):
        raise HTTPException(status_code=400, detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹")
    
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ì§„ë“¤ë¡œ ì²˜ë¦¬
        available_engines = advanced_stt_processor.stt.available_engines
        results = {}
        
        for engine in available_engines:
            if engine == 'local_fallback':
                continue  # ë¹„êµì—ì„œ ì œì™¸
            
            try:
                processor = AdvancedSTTProcessor(preferred_engine=engine)
                result = processor.process_audio_with_confidence(tmp_path, target_text)
                
                results[engine] = {
                    "transcription": result['transcription'],
                    "confidence": result['confidence'],
                    "syllable_count": result['quality_metrics']['syllable_count'],
                    "avg_syllable_confidence": result['quality_metrics']['avg_syllable_confidence'],
                    "has_word_timestamps": result['quality_metrics']['has_word_timestamps']
                }
            except Exception as e:
                results[engine] = {
                    "error": str(e),
                    "transcription": "",
                    "confidence": 0.0
                }
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.unlink(tmp_path)
        
        # ìµœê³  ì‹ ë¢°ë„ ì—”ì§„ ì„ íƒ
        best_engine = max(results.keys(), key=lambda k: results[k].get('confidence', 0))
        
        return JSONResponse({
            "success": True,
            "results": results,
            "best_engine": best_engine,
            "target_text": target_text,
            "message": f"âœ… ë‹¤ì¤‘ ì—”ì§„ ë¹„êµ ì™„ë£Œ - ìµœì : {best_engine}"
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "âŒ ë‹¤ì¤‘ ì—”ì§„ ë¹„êµ ì˜¤ë¥˜"
        }, status_code=500)

@app.post("/api/syllable-alignment-analysis")
async def syllable_alignment_analysis(file: UploadFile = File(...),
                                    text: str = Form(...)):
    """
    ìŒì ˆ ì •ë ¬ ìƒì„¸ ë¶„ì„
    """
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        # ê³ ê¸‰ ì²˜ë¦¬
        result = advanced_stt_processor.process_audio_with_confidence(tmp_path, text)
        
        # ìƒì„¸ ë¶„ì„ ì •ë³´ ì¶”ê°€
        syllable_analysis = []
        for syllable in result['syllables']:
            analysis = {
                "syllable": syllable['label'],
                "start": syllable['start'],
                "end": syllable['end'],
                "duration": syllable['end'] - syllable['start'],
                "confidence": syllable['confidence'],
                "phonetic_features": syllable.get('phonetic_features', {}),
                "analysis": {
                    "is_valid_duration": 0.05 <= (syllable['end'] - syllable['start']) <= 0.8,
                    "confidence_level": "high" if syllable['confidence'] > 0.8 else "medium" if syllable['confidence'] > 0.6 else "low"
                }
            }
            syllable_analysis.append(analysis)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.unlink(tmp_path)
        
        return JSONResponse({
            "success": True,
            "syllable_analysis": syllable_analysis,
            "summary": {
                "total_syllables": len(syllable_analysis),
                "avg_duration": np.mean([s['duration'] for s in syllable_analysis]),
                "avg_confidence": np.mean([s['confidence'] for s in syllable_analysis]),
                "high_confidence_ratio": len([s for s in syllable_analysis if s['confidence'] > 0.8]) / len(syllable_analysis)
            },
            "message": "âœ… ìŒì ˆ ì •ë ¬ ë¶„ì„ ì™„ë£Œ"
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "âŒ ìŒì ˆ ì •ë ¬ ë¶„ì„ ì˜¤ë¥˜"
        }, status_code=500)

# ========================================
# ğŸ“ ì—…ë¡œë“œ íŒŒì¼ í…ŒìŠ¤íŠ¸ APIë“¤
# ========================================

@app.get("/api/uploaded_files")
async def get_uploaded_files():
    """ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ - í†µí•©ëœ ë²„ì „ (Ultimate STT + ìƒì„¸ ì •ë³´)"""
    try:
        uploaded_files = []
        
        # uploads ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  wav íŒŒì¼ ì°¾ê¸°
        for file_path in UPLOAD_DIR.glob("*.wav"):
            wav_file = file_path.name
            file_id = file_path.stem
            textgrid_file = wav_file.replace('.wav', '.TextGrid')
            textgrid_path = UPLOAD_DIR / textgrid_file
            
            # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
            parts = file_id.split('_')
            
            # Ultimate STT í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ ì •ë³´
            expected_text = parts[3] if len(parts) >= 4 else "ì•Œ ìˆ˜ ì—†ìŒ"
            
            # ìƒì„¸ ì •ë³´ íŒŒì‹± (5ê°œ ì´ìƒ ë¶€ë¶„ì´ ìˆëŠ” ê²½ìš°)
            if len(parts) >= 5 and textgrid_path.exists():
                name = parts[0] if parts[0] else "ì´ë¦„ì—†ìŒ"
                gender = parts[1] if parts[1] else "ì„±ë³„ì—†ìŒ"
                age_group = parts[2] if parts[2] else "ì—°ë ¹ì—†ìŒ"
                sentence = parts[3] if parts[3] else "ë¬¸ì¥ì—†ìŒ"
                timestamp = '_'.join(parts[4:]) if len(parts) > 4 else "ì‹œê°„ì—†ìŒ"
                
                file_info = {
                    # Ultimate STT í˜¸í™˜ í•„ë“œë“¤
                    "file_id": file_id,
                    "filename": wav_file,
                    "expected_text": expected_text,
                    "has_textgrid": textgrid_path.exists(),
                    "file_size": file_path.stat().st_size,
                    "modified_time": file_path.stat().st_mtime,
                    
                    # ìƒì„¸ ì •ë³´ í•„ë“œë“¤
                    "id": file_id,
                    "wav_file": wav_file,
                    "textgrid_file": textgrid_file,
                    "name": name,
                    "gender": gender,
                    "age_group": age_group,
                    "sentence": sentence,
                    "timestamp": timestamp,
                    "display_name": f"{name} ({gender}, {age_group}) - {sentence}"
                }
            else:
                # TextGridê°€ ì—†ê±°ë‚˜ íŒŒì‹±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì •ë³´ë§Œ
                file_info = {
                    "file_id": file_id,
                    "filename": wav_file,
                    "expected_text": expected_text,
                    "has_textgrid": textgrid_path.exists(),
                    "file_size": file_path.stat().st_size,
                    "modified_time": file_path.stat().st_mtime,
                    
                    # ê¸°ë³¸ ìƒì„¸ ì •ë³´
                    "id": file_id,
                    "wav_file": wav_file,
                    "textgrid_file": textgrid_file,
                    "name": expected_text,
                    "gender": "ì•Œ ìˆ˜ ì—†ìŒ",
                    "age_group": "ì•Œ ìˆ˜ ì—†ìŒ",
                    "sentence": expected_text,
                    "timestamp": str(file_path.stat().st_mtime),
                    "display_name": f"{expected_text} (íŒŒì¼ëª…: {wav_file})"
                }
            
            uploaded_files.append(file_info)
        
        # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ ìµœì‹  ìˆœ ì •ë ¬
        uploaded_files.sort(key=lambda x: x['modified_time'], reverse=True)
        
        print(f"ğŸ—‚ï¸ ì—…ë¡œë“œëœ íŒŒì¼ {len(uploaded_files)}ê°œ ì°¾ìŒ")
        return {
            "success": True,
            "files": uploaded_files,
            "total_count": len(uploaded_files)
        }
        
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

@app.get("/api/uploaded_files/{file_id}/pitch")
async def get_uploaded_file_pitch(file_id: str, syllable_only: bool = False):
    # ë¹ˆ íŒŒì¼ID ê²€ì¦
    if not file_id or file_id.strip() == '' or file_id == '()':
        raise HTTPException(status_code=400, detail="íŒŒì¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ"""
    try:
        wav_file = f"{file_id}.wav"
        wav_path = UPLOAD_DIR / wav_file
        
        if not wav_path.exists():
            raise HTTPException(status_code=404, detail="WAV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"ğŸ¯ ì—…ë¡œë“œ íŒŒì¼ í”¼ì¹˜ ë¶„ì„: {wav_file} (syllable_only={syllable_only})")
        
        # Parselmouthë¡œ í”¼ì¹˜ ì¶”ì¶œ
        sound = pm.Sound(str(wav_path))
        
        # ë³¼ë¥¨ ì¦í­ (RMSê°€ ë‚®ì€ ê²½ìš°)
        values = sound.values[0] if sound.n_channels > 0 else sound.values
        rms = np.sqrt(np.mean(values**2))
        if rms < 0.01:  # ë³¼ë¥¨ì´ ì‘ì€ ê²½ìš°
            target_rms = 0.02  # ëª©í‘œ RMS
            amplification_factor = target_rms / (rms + 1e-10)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            # ìµœëŒ€ 10ë°°ê¹Œì§€ë§Œ ì¦í­
            amplification_factor = min(amplification_factor, 10.0)
            
            print(f"ğŸ”Š ë³¼ë¥¨ ì¦í­: RMS {rms:.4f} â†’ {target_rms:.4f} (x{amplification_factor:.2f})")
            
            # ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ìƒì„±
            amplified_values = values * amplification_factor
            # í´ë¦¬í•‘ ë°©ì§€
            amplified_values = np.clip(amplified_values, -0.9, 0.9)
            sound = pm.Sound(amplified_values, sampling_frequency=sound.sampling_frequency)
        
        # âœ… Reference íŒŒì¼ê³¼ ë™ì¼í•œ í”¼ì¹˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        pitch = sound.to_pitch(time_step=0.01, pitch_floor=75.0, pitch_ceiling=500.0)
        
        # í”¼ì¹˜ ë°ì´í„° ì¶”ì¶œ
        times = pitch.xs()
        frequencies = [pitch.get_value_at_time(t) for t in times]
        
        # NaN ê°’ ì œê±°
        pitch_data = []
        for i, (time, freq) in enumerate(zip(times, frequencies)):
            if not math.isnan(freq) and freq > 0:
                pitch_data.append({"time": time, "frequency": freq})
        
        print(f"ğŸ¯ {len(pitch_data)}ê°œ í”¼ì¹˜ í¬ì¸íŠ¸ ì¶”ì¶œ")
        
        if syllable_only:
            # âœ… Reference íŒŒì¼ê³¼ ë™ì¼í•œ í•¨ìˆ˜ ì‚¬ìš©
            textgrid_file = f"{file_id}.TextGrid"
            textgrid_path = UPLOAD_DIR / textgrid_file
            
            if textgrid_path.exists():
                # Reference íŒŒì¼ê³¼ ë™ì¼í•œ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
                return await get_syllable_representative_pitch(file_id, str(wav_path), str(textgrid_path), sound, pitch)
        
        return pitch_data
        
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ íŒŒì¼ í”¼ì¹˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í”¼ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {e}")

@app.get("/api/uploaded_files/{file_id}/syllables")
async def get_uploaded_file_syllables(file_id: str):
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ TextGrid ìŒì ˆ ì •ë³´"""
    try:
        textgrid_file = f"{file_id}.TextGrid"
        textgrid_path = UPLOAD_DIR / textgrid_file
        
        if not textgrid_path.exists():
            raise HTTPException(status_code=404, detail="TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"ğŸ¯ ì—…ë¡œë“œ íŒŒì¼ TextGrid ì½ê¸°: {textgrid_file}")
        
        # TextGrid íŒŒì‹±
        syllables = []
        try:
            with open(textgrid_path, 'r', encoding='utf-16') as f:
                content = f.read()
        except:
            with open(textgrid_path, 'r', encoding='utf-8') as f:
                content = f.read()
        
        # ìŒì ˆ ì •ë³´ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
        pattern = r'text = "([^"]+)"'
        matches = re.findall(pattern, content)
        
        for match in matches:
            if match.strip() and match.strip() != '':
                syllables.append(match.strip())
        
        print(f"ğŸ¯ {len(syllables)}ê°œ ìŒì ˆ ë°˜í™˜: {syllables}")
        return syllables
        
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ íŒŒì¼ TextGrid ì½ê¸° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"TextGrid ì½ê¸° ì‹¤íŒ¨: {e}")

def calculate_syllable_pitch_from_textgrid(textgrid_path: str, pitch_data: list):
    """TextGrid ê¸°ë°˜ ìŒì ˆë³„ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚°"""
    try:
        # TextGrid íŒŒì¼ ì½ê¸°
        try:
            with open(textgrid_path, 'r', encoding='utf-16') as f:
                content = f.read()
        except:
            with open(textgrid_path, 'r', encoding='utf-8') as f:
                content = f.read()
        
        # ìŒì ˆ êµ¬ê°„ ì •ë³´ ì¶”ì¶œ
        syllable_regions = []
        lines = content.split('\n')
        current_interval = {}
        
        for line in lines:
            line = line.strip()
            if 'xmin =' in line:
                current_interval['start'] = float(line.split('=')[1].strip())
            elif 'xmax =' in line:
                current_interval['end'] = float(line.split('=')[1].strip())
            elif 'text = "' in line:
                text = line.split('"')[1]
                if text.strip():
                    current_interval['text'] = text.strip()
                    syllable_regions.append(current_interval.copy())
                current_interval = {}
        
        # ê° ìŒì ˆì˜ ëŒ€í‘œ í”¼ì¹˜ ê³„ì‚°
        syllable_pitch = []
        print(f"ğŸ¯ ìŒì ˆ êµ¬ê°„ ì²˜ë¦¬: {len(syllable_regions)}ê°œ êµ¬ê°„, {len(pitch_data)}ê°œ í”¼ì¹˜ í¬ì¸íŠ¸")
        
        for i, region in enumerate(syllable_regions):
            start_time = region['start']
            end_time = region['end']
            syllable = region['text']
            
            print(f"  ğŸ¯ ìŒì ˆ {i+1}: '{syllable}' ({start_time:.3f}s ~ {end_time:.3f}s)")
            
            # í•´ë‹¹ êµ¬ê°„ì˜ í”¼ì¹˜ ë°ì´í„° í•„í„°ë§ (ê²½ê³„ ì¡°ê±´ ì™„í™”)
            region_pitches = []
            region_times = []
            for p in pitch_data:
                # êµ¬ê°„ ê²½ê³„ì—ì„œ ì•½ê°„ì˜ ì—¬ìœ ë¥¼ ë‘  (0.05ì´ˆ)
                margin = 0.05
                if (start_time - margin) <= p['time'] <= (end_time + margin):
                    region_pitches.append(p['frequency'])
                    region_times.append(p['time'])
            
            if region_times:
                print(f"    ğŸ“Š êµ¬ê°„ ë‚´ ì‹œê°„ ë²”ìœ„: {min(region_times):.3f}s ~ {max(region_times):.3f}s")
            
            print(f"    ğŸ“Š êµ¬ê°„ ë‚´ í”¼ì¹˜ í¬ì¸íŠ¸: {len(region_pitches)}ê°œ")
            
            if region_pitches:
                avg_pitch = sum(region_pitches) / len(region_pitches)
                syllable_data = {
                    "time": (start_time + end_time) / 2,  # êµ¬ê°„ ì¤‘ì 
                    "frequency": avg_pitch,
                    "syllable": syllable,
                    "start": start_time,
                    "end": end_time
                }
                syllable_pitch.append(syllable_data)
                print(f"    âœ… í‰ê·  í”¼ì¹˜: {avg_pitch:.1f}Hz")
            else:
                print(f"    âŒ êµ¬ê°„ ë‚´ í”¼ì¹˜ ë°ì´í„° ì—†ìŒ")
        
        print(f"ğŸ¯ ìµœì¢… ìŒì ˆ í”¼ì¹˜ ê²°ê³¼: {len(syllable_pitch)}ê°œ ë°˜í™˜")
        return syllable_pitch
        
    except Exception as e:
        print(f"âŒ TextGrid ê¸°ë°˜ ìŒì ˆ í”¼ì¹˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return []

@app.post("/api/update-all-textgrids")
async def update_all_textgrids():
    """ëª¨ë“  íŒŒì¼ì˜ TextGridë¥¼ ìƒˆë¡œìš´ ì •ë°€ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸"""
    try:
        print("ğŸ”„ ëª¨ë“  TextGrid íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        updated_files = []
        errors = []
        
        # 1. Reference Files ì—…ë°ì´íŠ¸
        reference_dir = Path("static/reference_files")
        if reference_dir.exists():
            for wav_file in reference_dir.glob("*.wav"):
                try:
                    # íŒŒì¼ëª…ì—ì„œ ë¬¸ì¥ ì¶”ì¶œ (í™•ì¥ì ì œê±°)
                    sentence = wav_file.stem
                    
                    # ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ TextGrid ìƒì„±
                    textgrid_path = create_textgrid_from_audio(
                        str(wav_file), 
                        sentence,
                        output_path=str(wav_file.with_suffix('.TextGrid'))
                    )
                    
                    updated_files.append({
                        "type": "reference",
                        "file": wav_file.name,
                        "textgrid": textgrid_path,
                        "sentence": sentence
                    })
                    print(f"âœ… Reference ì—…ë°ì´íŠ¸: {wav_file.name}")
                    
                except Exception as e:
                    error_msg = f"Reference {wav_file.name}: {str(e)}"
                    errors.append(error_msg)
                    print(f"âŒ {error_msg}")
        
        # 2. Uploaded Files ì—…ë°ì´íŠ¸ 
        uploads_dir = Path("static/uploads")
        if uploads_dir.exists():
            for wav_file in uploads_dir.glob("*.wav"):
                try:
                    # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: ë°•ìš°ìš©_male_30ëŒ€_ë°˜ê°€ì›Œìš”_20250908_184908.wav)
                    filename_parts = wav_file.stem.split('_')
                    if len(filename_parts) >= 4:
                        sentence = filename_parts[3]  # ì—°ìŠµë¬¸ì¥ ë¶€ë¶„
                        
                        # ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ TextGrid ìƒì„±
                        textgrid_path = create_textgrid_from_audio(
                            str(wav_file),
                            sentence, 
                            output_path=str(wav_file.with_suffix('.TextGrid'))
                        )
                        
                        updated_files.append({
                            "type": "uploaded",
                            "file": wav_file.name,
                            "textgrid": textgrid_path,
                            "sentence": sentence
                        })
                        print(f"âœ… Upload ì—…ë°ì´íŠ¸: {wav_file.name}")
                    else:
                        print(f"âš ï¸ íŒŒì¼ëª… í˜•ì‹ ë¶ˆì¼ì¹˜: {wav_file.name}")
                        
                except Exception as e:
                    error_msg = f"Upload {wav_file.name}: {str(e)}"
                    errors.append(error_msg)
                    print(f"âŒ {error_msg}")
        
        print(f"ğŸ‰ TextGrid ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(updated_files)}ê°œ ì„±ê³µ, {len(errors)}ê°œ ì‹¤íŒ¨")
        
        return {
            "success": True,
            "updated_count": len(updated_files),
            "error_count": len(errors),
            "updated_files": updated_files,
            "errors": errors,
            "message": f"ìƒˆë¡œìš´ ì •ë°€ ë¶„ì ˆ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ {len(updated_files)}ê°œ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ"
        }
        
    except Exception as e:
        print(f"âŒ TextGrid ì¼ê´„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"TextGrid ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

# ğŸµ ìŒì—­ëŒ€ ì¸¡ì • API - ìµœì €ìŒ/ìµœê³ ìŒ ì¸¡ì • ë° ê¸°í•˜í‰ê·  ê³„ì‚°
@app.post("/api/voice-range-measurement")
async def voice_range_measurement(file: UploadFile = File(...)):
    """
    í™”ìì˜ ìŒì—­ëŒ€ë¥¼ ì¸¡ì •í•˜ì—¬ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ê³„ì‚°
    - ìµœì €ìŒ/ìµœê³ ìŒ ì¸¡ì •
    - ê¸°í•˜í‰ê·  ê³„ì‚°: âˆš(ìµœì €ì£¼íŒŒìˆ˜ Ã— ìµœê³ ì£¼íŒŒìˆ˜)
    - ë¡œê·¸ ìŠ¤ì¼€ì¼ ì¤‘ê°„ì  ê³„ì‚°
    """
    try:
        print(f"ğŸµ ìŒì—­ëŒ€ ì¸¡ì • ì‹œì‘: {file.filename}")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        content = await file.read()
        temp_file.write(content)
        temp_file.close()
        
        # Parselmouthë¡œ ìŒì„± ë¡œë“œ
        sound = parselmouth.Sound(temp_file.name)
        
        # í”¼ì¹˜ ì¶”ì¶œ (ë” ë„“ì€ ë²”ìœ„ë¡œ ì„¤ì •)
        pitch = sound.to_pitch(time_step=0.01, pitch_floor=50.0, pitch_ceiling=600.0)
        
        # ìœ íš¨í•œ í”¼ì¹˜ ê°’ë“¤ë§Œ ì¶”ì¶œ (0ì´ ì•„ë‹Œ ê°’ë“¤)
        pitch_values = []
        for i in range(pitch.get_number_of_frames()):
            f0 = pitch.get_value_at_time(pitch.get_time_from_frame_number(i + 1))
            if f0 > 0:  # ìœ íš¨í•œ í”¼ì¹˜ ê°’ë§Œ
                pitch_values.append(f0)
        
        if len(pitch_values) < 10:
            raise HTTPException(status_code=400, detail="ì¶©ë¶„í•œ ìŒì„± ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ìµœì €ìŒ/ìµœê³ ìŒ ì¶”ì¶œ (ê·¹ë‹¨ê°’ ì œê±°)
        sorted_pitches = sorted(pitch_values)
        # í•˜ìœ„ 5%ì™€ ìƒìœ„ 5%ëŠ” ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ì—¬ ì œê±°
        trim_count = max(1, len(sorted_pitches) // 20)
        trimmed_pitches = sorted_pitches[trim_count:-trim_count]
        
        min_freq = min(trimmed_pitches)
        max_freq = max(trimmed_pitches)
        
        # ê¸°í•˜í‰ê·  ê³„ì‚°: âˆš(min Ã— max)
        geometric_mean = (min_freq * max_freq) ** 0.5
        
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì¤‘ê°„ì  ê³„ì‚° (ì„¸ë¯¸í†¤ ë‹¨ìœ„)
        import math
        log_midpoint = math.exp((math.log(min_freq) + math.log(max_freq)) / 2)
        
        # í‰ê·  í”¼ì¹˜ (ì‚°ìˆ í‰ê· )
        arithmetic_mean = sum(trimmed_pitches) / len(trimmed_pitches)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(temp_file.name)
        
        result = {
            "measurement_type": "voice_range",
            "min_frequency": round(min_freq, 2),
            "max_frequency": round(max_freq, 2),
            "geometric_mean": round(geometric_mean, 2),
            "log_midpoint": round(log_midpoint, 2),
            "arithmetic_mean": round(arithmetic_mean, 2),
            "total_samples": len(pitch_values),
            "valid_samples": len(trimmed_pitches),
            "range_semitones": round(12 * math.log2(max_freq / min_freq), 1)
        }
        
        print(f"ğŸµ ìŒì—­ëŒ€ ì¸¡ì • ì™„ë£Œ:")
        print(f"   ìµœì €ìŒ: {min_freq:.1f}Hz, ìµœê³ ìŒ: {max_freq:.1f}Hz")
        print(f"   ê¸°í•˜í‰ê· : {geometric_mean:.1f}Hz, ìŒì—­: {result['range_semitones']}st")
        
        return result
        
    except Exception as e:
        print(f"âŒ ìŒì—­ëŒ€ ì¸¡ì • ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìŒì—­ëŒ€ ì¸¡ì • ì‹¤íŒ¨: {str(e)}")

# ğŸ—£ï¸ ëª¨ìŒë³„ ë¶„ì„ API - /ì•„/, /ì´/, /ìš°/ ê°œë³„ ì£¼íŒŒìˆ˜ ë¶„ì„
@app.post("/api/vowel-analysis")
async def vowel_analysis(file: UploadFile = File(...), vowel_type: str = Form(...)):
    """
    íŠ¹ì • ëª¨ìŒì˜ ì£¼íŒŒìˆ˜ íŠ¹ì„± ë¶„ì„
    vowel_type: 'a' (/ì•„/), 'i' (/ì´/), 'u' (/ìš°/)
    """
    try:
        print(f"ğŸ—£ï¸ ëª¨ìŒë³„ ë¶„ì„ ì‹œì‘: {vowel_type} - {file.filename}")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        content = await file.read()
        temp_file.write(content)
        temp_file.close()
        
        # Parselmouthë¡œ ìŒì„± ë¡œë“œ
        sound = parselmouth.Sound(temp_file.name)
        
        # í”¼ì¹˜ ì¶”ì¶œ
        pitch = sound.to_pitch(time_step=0.01)
        
        # í¬ë¨¼íŠ¸ ë¶„ì„ (ëª¨ìŒ íŠ¹ì„±)
        formant = sound.to_formant_burg(time_step=0.01, max_number_of_formants=4)
        
        # í”¼ì¹˜ ê°’ë“¤ ì¶”ì¶œ
        pitch_values = []
        f1_values = []  # ì²« ë²ˆì§¸ í¬ë¨¼íŠ¸
        f2_values = []  # ë‘ ë²ˆì§¸ í¬ë¨¼íŠ¸
        
        for i in range(min(pitch.get_number_of_frames(), formant.get_number_of_frames())):
            time = pitch.get_time_from_frame_number(i + 1)
            f0 = pitch.get_value_at_time(time)
            f1 = formant.get_value_at_time(1, time)  # ì²« ë²ˆì§¸ í¬ë¨¼íŠ¸
            f2 = formant.get_value_at_time(2, time)  # ë‘ ë²ˆì§¸ í¬ë¨¼íŠ¸
            
            if f0 > 0:
                pitch_values.append(f0)
            if not math.isnan(f1) and f1 > 0:
                f1_values.append(f1)
            if not math.isnan(f2) and f2 > 0:
                f2_values.append(f2)
        
        if len(pitch_values) < 5:
            raise HTTPException(status_code=400, detail="ì¶©ë¶„í•œ ëª¨ìŒ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # í†µê³„ ê³„ì‚°
        mean_f0 = sum(pitch_values) / len(pitch_values)
        mean_f1 = sum(f1_values) / len(f1_values) if f1_values else 0
        mean_f2 = sum(f2_values) / len(f2_values) if f2_values else 0
        
        # í‘œì¤€í¸ì°¨ ê³„ì‚°
        import statistics
        std_f0 = statistics.stdev(pitch_values) if len(pitch_values) > 1 else 0
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(temp_file.name)
        
        result = {
            "vowel_type": vowel_type,
            "fundamental_frequency": round(mean_f0, 2),
            "f1_formant": round(mean_f1, 2),
            "f2_formant": round(mean_f2, 2),
            "f0_std_deviation": round(std_f0, 2),
            "stability_score": round(1 / (1 + std_f0/mean_f0), 3),  # ì•ˆì •ì„± ì ìˆ˜
            "sample_count": len(pitch_values)
        }
        
        print(f"ğŸ—£ï¸ ëª¨ìŒ /{vowel_type}/ ë¶„ì„ ì™„ë£Œ: F0={mean_f0:.1f}Hz, F1={mean_f1:.0f}Hz, F2={mean_f2:.0f}Hz")
        
        return result
        
    except Exception as e:
        print(f"âŒ ëª¨ìŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ëª¨ìŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

# ğŸ“Š ê¸°í•˜í‰ê·  ê¸°ë°˜ ê¸°ì¤€ì  ê³„ì‚° API
@app.post("/api/calculate-reference-frequency")
async def calculate_reference_frequency(measurements: dict):
    """
    ë‹¤ì¤‘ ì¸¡ì •ê°’ì„ í†µí•©í•˜ì—¬ ìµœì  ê¸°ì¤€ ì£¼íŒŒìˆ˜ ê³„ì‚°
    measurements: {
        "comfortable_pitch": float,  # í¸ì•ˆí•œ ë°œí™” ì£¼íŒŒìˆ˜
        "voice_range": {...},        # ìŒì—­ëŒ€ ì¸¡ì • ê²°ê³¼
        "vowel_analysis": [...]      # ëª¨ìŒë³„ ë¶„ì„ ê²°ê³¼ë“¤
    }
    """
    try:
        print("ğŸ“Š ê¸°í•˜í‰ê·  ê¸°ë°˜ ê¸°ì¤€ì  ê³„ì‚° ì‹œì‘")
        
        reference_candidates = []
        weights = []
        
        # 1. í¸ì•ˆí•œ ë°œí™” ì£¼íŒŒìˆ˜ (ê°€ì¤‘ì¹˜: 0.4)
        if "comfortable_pitch" in measurements:
            reference_candidates.append(measurements["comfortable_pitch"])
            weights.append(0.4)
            print(f"   í¸ì•ˆí•œ ë°œí™”: {measurements['comfortable_pitch']:.1f}Hz (ê°€ì¤‘ì¹˜: 0.4)")
        
        # 2. ìŒì—­ëŒ€ ê¸°í•˜í‰ê·  (ê°€ì¤‘ì¹˜: 0.3)
        if "voice_range" in measurements:
            range_data = measurements["voice_range"]
            reference_candidates.append(range_data["geometric_mean"])
            weights.append(0.3)
            print(f"   ìŒì—­ëŒ€ ê¸°í•˜í‰ê· : {range_data['geometric_mean']:.1f}Hz (ê°€ì¤‘ì¹˜: 0.3)")
        
        # 3. ëª¨ìŒë³„ ë¶„ì„ í‰ê·  (ê°€ì¤‘ì¹˜: 0.3)
        if "vowel_analysis" in measurements and measurements["vowel_analysis"]:
            vowel_freqs = []
            for vowel in measurements["vowel_analysis"]:
                # ì•ˆì •ì„± ì ìˆ˜ë¡œ ê°€ì¤‘ì¹˜ ì¡°ì •
                stability = vowel.get("stability_score", 0.5)
                freq = vowel["fundamental_frequency"]
                vowel_freqs.append(freq * stability)
            
            if vowel_freqs:
                vowel_mean = sum(vowel_freqs) / len(vowel_freqs)
                reference_candidates.append(vowel_mean)
                weights.append(0.3)
                print(f"   ëª¨ìŒ í‰ê· : {vowel_mean:.1f}Hz (ê°€ì¤‘ì¹˜: 0.3)")
        
        if not reference_candidates:
            raise HTTPException(status_code=400, detail="ê³„ì‚°ì— í•„ìš”í•œ ì¸¡ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê°€ì¤‘ ê¸°í•˜í‰ê·  ê³„ì‚°
        import math
        
        # ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        
        # ê°€ì¤‘ ê¸°í•˜í‰ê· : (âˆ fi^wi)^(1/Î£wi)
        log_sum = sum(math.log(freq) * weight for freq, weight in zip(reference_candidates, normalized_weights))
        weighted_geometric_mean = math.exp(log_sum)
        
        # ê°€ì¤‘ ì‚°ìˆ í‰ê·  (ë¹„êµìš©)
        weighted_arithmetic_mean = sum(freq * weight for freq, weight in zip(reference_candidates, normalized_weights))
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (ì¸¡ì •ê°’ë“¤ì˜ ì¼ê´€ì„±)
        import statistics
        if len(reference_candidates) > 1:
            cv = statistics.stdev(reference_candidates) / statistics.mean(reference_candidates)  # ë³€ë™ê³„ìˆ˜
            confidence_score = max(0, 1 - cv)  # ë³€ë™ì´ ì ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        else:
            confidence_score = 0.5
        
        result = {
            "reference_frequency": round(weighted_geometric_mean, 2),
            "alternative_reference": round(weighted_arithmetic_mean, 2),
            "confidence_score": round(confidence_score, 3),
            "measurement_count": len(reference_candidates),
            "individual_measurements": [
                {"value": round(freq, 2), "weight": round(weight, 2)} 
                for freq, weight in zip(reference_candidates, normalized_weights)
            ]
        }
        
        print(f"ğŸ“Š ìµœì  ê¸°ì¤€ ì£¼íŒŒìˆ˜: {weighted_geometric_mean:.1f}Hz (ì‹ ë¢°ë„: {confidence_score:.2f})")
        
        return result
        
    except Exception as e:
        print(f"âŒ ê¸°ì¤€ì  ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê¸°ì¤€ì  ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

# ğŸ”„ ì‹¤ì‹œê°„ ê¸°ì¤€ì  ì¡°ì • API - í˜„ì¬ ë°œí™” ê¸°ë°˜ ë™ì  ì—…ë°ì´íŠ¸
@app.post("/api/adaptive-reference-adjustment")
async def adaptive_reference_adjustment(current_data: dict):
    """
    ì‹¤ì‹œê°„ ë°œí™” ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ë™ì  ì¡°ì •
    current_data: {
        "current_frequency": float,    # í˜„ì¬ ë°œí™” ì£¼íŒŒìˆ˜
        "current_reference": float,    # í˜„ì¬ ê¸°ì¤€ ì£¼íŒŒìˆ˜
        "confidence": float,           # í”¼ì¹˜ ì‹ ë¢°ë„ (0-1)
        "adjustment_factor": float,    # ì¡°ì • ê°•ë„ (0-1, ê¸°ë³¸: 0.1)
        "context": str                 # ë°œí™” ìƒí™© ("normal", "stressed", "relaxed")
    }
    """
    try:
        print("ğŸ”„ ì‹¤ì‹œê°„ ê¸°ì¤€ì  ì¡°ì • ì‹œì‘")
        
        current_freq = current_data["current_frequency"]
        current_ref = current_data["current_reference"]
        confidence = current_data.get("confidence", 0.8)
        adjustment_factor = current_data.get("adjustment_factor", 0.1)
        context = current_data.get("context", "normal")
        
        # ìƒí™©ë³„ ì¡°ì • ê³„ìˆ˜
        context_multipliers = {
            "normal": 1.0,      # ì¼ë°˜ ìƒí™©
            "stressed": 0.5,    # ìŠ¤íŠ¸ë ˆìŠ¤ ìƒí™©: ì¡°ì • ê°•ë„ ì¤„ì„
            "relaxed": 1.2,     # í¸ì•ˆí•œ ìƒí™©: ì¡°ì • ê°•ë„ ë†’ì„
            "loud": 0.3,        # í° ì†Œë¦¬: ê¸‰ê²©í•œ ë³€í™” ì–µì œ
            "quiet": 0.8        # ì‘ì€ ì†Œë¦¬: ì ë‹¹í•œ ì¡°ì •
        }
        
        effective_adjustment = adjustment_factor * context_multipliers.get(context, 1.0) * confidence
        
        # ì£¼íŒŒìˆ˜ ì°¨ì´ ê³„ì‚° (ì„¸ë¯¸í†¤ ë‹¨ìœ„)
        import math
        freq_diff_semitones = 12 * math.log2(current_freq / current_ref)
        
        # ì ì§„ì  ì¡°ì • (exponential moving average ë°©ì‹)
        # ìƒˆë¡œìš´ ê¸°ì¤€ì  = ê¸°ì¡´ ê¸°ì¤€ì  + (ì°¨ì´ Ã— ì¡°ì •ê³„ìˆ˜)
        adjustment_hz = (current_freq - current_ref) * effective_adjustment
        new_reference = current_ref + adjustment_hz
        
        # ê·¹ë‹¨ì  ë³€í™” ë°©ì§€ (Â±3 ì„¸ë¯¸í†¤ ì´ë‚´ë¡œ ì œí•œ)
        max_change_semitones = 3.0
        max_change_hz = current_ref * (2**(max_change_semitones/12) - 1)
        
        if abs(adjustment_hz) > max_change_hz:
            adjustment_hz = max_change_hz if adjustment_hz > 0 else -max_change_hz
            new_reference = current_ref + adjustment_hz
        
        # ê²°ê³¼ ê²€ì¦ (50Hz ~ 600Hz ë²”ìœ„ ë‚´)
        new_reference = max(50.0, min(600.0, new_reference))
        
        result = {
            "original_reference": round(current_ref, 2),
            "new_reference": round(new_reference, 2),
            "adjustment_hz": round(adjustment_hz, 2),
            "adjustment_semitones": round(12 * math.log2(new_reference / current_ref), 3),
            "effective_factor": round(effective_adjustment, 3),
            "context": context,
            "confidence_used": confidence
        }
        
        print(f"ğŸ”„ ê¸°ì¤€ì  ì¡°ì •: {current_ref:.1f}Hz â†’ {new_reference:.1f}Hz (Â±{adjustment_hz:.1f}Hz)")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì‹¤ì‹œê°„ ê¸°ì¤€ì  ì¡°ì • ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì‹¤ì‹œê°„ ì¡°ì • ì‹¤íŒ¨: {str(e)}")

# ğŸ“ˆ ì´ë™í‰ê·  ê¸°ë°˜ ê¸°ì¤€ì  ì—…ë°ì´íŠ¸ API
@app.post("/api/moving-average-update")
async def moving_average_update(pitch_history: dict):
    """
    ìµœê·¼ Nê°œ ë°œí™”ì˜ ê°€ì¤‘í‰ê· ìœ¼ë¡œ ê¸°ì¤€ì  ì—…ë°ì´íŠ¸
    pitch_history: {
        "recent_pitches": [float],     # ìµœê·¼ í”¼ì¹˜ ê°’ë“¤
        "timestamps": [float],         # ê° í”¼ì¹˜ì˜ ì‹œê°„ì •ë³´
        "confidences": [float],        # ê° í”¼ì¹˜ì˜ ì‹ ë¢°ë„
        "window_size": int,            # ì´ë™í‰ê·  ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸: 20)
        "decay_factor": float          # ì‹œê°„ ê°ì‡  ê³„ìˆ˜ (ê¸°ë³¸: 0.95)
    }
    """
    try:
        print("ğŸ“ˆ ì´ë™í‰ê·  ê¸°ë°˜ ê¸°ì¤€ì  ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        recent_pitches = pitch_history["recent_pitches"]
        timestamps = pitch_history.get("timestamps", [])
        confidences = pitch_history.get("confidences", [1.0] * len(recent_pitches))
        window_size = pitch_history.get("window_size", 20)
        decay_factor = pitch_history.get("decay_factor", 0.95)
        
        if len(recent_pitches) < 3:
            raise HTTPException(status_code=400, detail="ì´ë™í‰ê·  ê³„ì‚°ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ìµœê·¼ Nê°œ ë°ì´í„°ë§Œ ì‚¬ìš©
        if len(recent_pitches) > window_size:
            recent_pitches = recent_pitches[-window_size:]
            if timestamps:
                timestamps = timestamps[-window_size:]
            confidences = confidences[-window_size:]
        
        # ì‹œê°„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
        weights = []
        if timestamps:
            max_time = max(timestamps)
            for i, timestamp in enumerate(timestamps):
                # ì‹œê°„ ì°¨ì´ì— ë”°ë¥¸ ê°ì‡ 
                time_diff = max_time - timestamp
                time_weight = decay_factor ** time_diff
                # ì‹ ë¢°ë„ì™€ ì‹œê°„ ê°€ì¤‘ì¹˜ ê²°í•©
                combined_weight = time_weight * confidences[i]
                weights.append(combined_weight)
        else:
            # ì‹œê°„ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìˆœì„œ ê¸°ë°˜ ê°€ì¤‘ì¹˜
            for i in range(len(recent_pitches)):
                position_weight = decay_factor ** (len(recent_pitches) - 1 - i)
                combined_weight = position_weight * confidences[i]
                weights.append(combined_weight)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ê¸°í•˜í‰ê·  ì‚¬ìš©)
        import math
        
        total_weight = sum(weights)
        if total_weight == 0:
            raise HTTPException(status_code=400, detail="ìœ íš¨í•œ ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜ë¡œ ê¸°í•˜í‰ê·  ê³„ì‚°
        normalized_weights = [w / total_weight for w in weights]
        log_sum = sum(math.log(freq) * weight for freq, weight in zip(recent_pitches, normalized_weights))
        weighted_geometric_mean = math.exp(log_sum)
        
        # ê°€ì¤‘ ì‚°ìˆ í‰ê·  (ë¹„êµìš©)
        weighted_arithmetic_mean = sum(freq * weight for freq, weight in zip(recent_pitches, normalized_weights))
        
        # ì•ˆì •ì„± ì§€í‘œ ê³„ì‚°
        import statistics
        pitch_std = statistics.stdev(recent_pitches) if len(recent_pitches) > 1 else 0
        pitch_mean = statistics.mean(recent_pitches)
        stability_coefficient = 1 - (pitch_std / pitch_mean)  # ë³€ë™ì´ ì ì„ìˆ˜ë¡ ë†’ìŒ
        
        result = {
            "updated_reference": round(weighted_geometric_mean, 2),
            "alternative_reference": round(weighted_arithmetic_mean, 2),
            "stability_coefficient": round(stability_coefficient, 3),
            "sample_count": len(recent_pitches),
            "effective_window": len(recent_pitches),
            "pitch_range": {
                "min": round(min(recent_pitches), 2),
                "max": round(max(recent_pitches), 2),
                "std": round(pitch_std, 2)
            }
        }
        
        print(f"ğŸ“ˆ ì´ë™í‰ê·  ê¸°ì¤€ì : {weighted_geometric_mean:.1f}Hz (ì•ˆì •ì„±: {stability_coefficient:.2f})")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì´ë™í‰ê·  ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì´ë™í‰ê·  ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

# â° ì£¼ê¸°ì  ì¬ì¸¡ì • ì•Œë¦¼ ì‹œìŠ¤í…œ API
@app.post("/api/remeasurement-schedule")
async def remeasurement_schedule(user_profile: dict):
    """
    ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì¬ì¸¡ì • ìŠ¤ì¼€ì¤„ ê´€ë¦¬
    user_profile: {
        "user_id": str,
        "last_measurement": str,       # ISO ë‚ ì§œ í˜•ì‹
        "measurement_frequency": int,  # ê°œì›” ë‹¨ìœ„ (ê¸°ë³¸: 3ê°œì›”)
        "voice_change_factors": [str], # ["age", "health", "training"]
        "current_age": int,
        "gender": str
    }
    """
    try:
        print("â° ì¬ì¸¡ì • ìŠ¤ì¼€ì¤„ ê´€ë¦¬ ì‹œì‘")
        
        from datetime import datetime, timedelta
        import json
        
        user_id = user_profile["user_id"]
        last_measurement_str = user_profile["last_measurement"]
        frequency_months = user_profile.get("measurement_frequency", 3)
        change_factors = user_profile.get("voice_change_factors", [])
        current_age = user_profile.get("current_age", 30)
        gender = user_profile.get("gender", "unknown")
        
        # ë‚ ì§œ íŒŒì‹±
        last_measurement = datetime.fromisoformat(last_measurement_str.replace('Z', '+00:00'))
        
        # ê¸°ë³¸ ì¬ì¸¡ì • ì£¼ê¸° ê³„ì‚°
        base_interval_months = frequency_months
        
        # ë‚˜ì´ë³„ ì¡°ì •
        if current_age < 18:
            base_interval_months = max(1, base_interval_months // 2)  # ì²­ì†Œë…„: ë” ìì£¼
        elif current_age > 60:
            base_interval_months = max(2, int(base_interval_months * 0.8))  # ê³ ë ¹: ì•½ê°„ ë” ìì£¼
        
        # ë³€í™” ìš”ì¸ë³„ ì£¼ê¸° ì¡°ì •
        adjustment_factor = 1.0
        for factor in change_factors:
            if factor == "training":
                adjustment_factor *= 0.5  # ìŒì„± í›ˆë ¨ ì¤‘: ë” ìì£¼
            elif factor == "health":
                adjustment_factor *= 0.7  # ê±´ê°• ë¬¸ì œ: ìì£¼
            elif factor == "medication":
                adjustment_factor *= 0.6  # ì•½ë¬¼ ë³µìš©: ìì£¼
            elif factor == "surgery":
                adjustment_factor *= 0.3  # ìˆ˜ìˆ  í›„: ë§¤ìš° ìì£¼
        
        adjusted_interval_months = max(1, int(base_interval_months * adjustment_factor))
        
        # ë‹¤ìŒ ì¸¡ì • ì˜ˆì •ì¼ ê³„ì‚°
        next_measurement = last_measurement + timedelta(days=adjusted_interval_months * 30)
        
        # í˜„ì¬ê¹Œì§€ì˜ ê²½ê³¼ ì‹œê°„
        now = datetime.now()
        days_since_last = (now - last_measurement).days
        days_until_next = (next_measurement - now).days
        
        # ì•Œë¦¼ ìƒíƒœ ê²°ì •
        if days_until_next <= 0:
            alert_status = "overdue"
            urgency = "high"
        elif days_until_next <= 7:
            alert_status = "due_soon"
            urgency = "medium"
        elif days_until_next <= 30:
            alert_status = "upcoming"
            urgency = "low"
        else:
            alert_status = "scheduled"
            urgency = "none"
        
        # ê¶Œì¥ ì¸¡ì • í•­ëª©
        recommended_tests = ["comfortable_pitch"]
        if days_since_last > 90:  # 3ê°œì›” ì´ìƒ
            recommended_tests.extend(["voice_range", "vowel_analysis"])
        if "training" in change_factors:
            recommended_tests.append("stability_analysis")
        
        result = {
            "user_id": user_id,
            "last_measurement_date": last_measurement_str,
            "next_measurement_date": next_measurement.isoformat(),
            "days_since_last": days_since_last,
            "days_until_next": days_until_next,
            "adjusted_interval_months": adjusted_interval_months,
            "alert_status": alert_status,
            "urgency_level": urgency,
            "recommended_tests": recommended_tests,
            "change_factors_considered": change_factors,
            "schedule_message": generate_schedule_message(alert_status, days_until_next, urgency)
        }
        
        print(f"â° ì‚¬ìš©ì {user_id}: {alert_status} (ë‹¤ìŒ ì¸¡ì •ê¹Œì§€ {days_until_next}ì¼)")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì¬ì¸¡ì • ìŠ¤ì¼€ì¤„ ê´€ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìŠ¤ì¼€ì¤„ ê´€ë¦¬ ì‹¤íŒ¨: {str(e)}")

def generate_schedule_message(status: str, days_until: int, urgency: str) -> str:
    """ì¬ì¸¡ì • ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±"""
    if status == "overdue":
        return f"âš ï¸ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ì¬ì¸¡ì •ì´ {abs(days_until)}ì¼ ì§€ì—°ë˜ì—ˆìŠµë‹ˆë‹¤. ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì§€ê¸ˆ ì¸¡ì •í•˜ì„¸ìš”."
    elif status == "due_soon":
        return f"ğŸ”” {days_until}ì¼ í›„ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ì¬ì¸¡ì •ì´ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    elif status == "upcoming":
        return f"ğŸ“… {days_until}ì¼ í›„ ê¸°ì¤€ ì£¼íŒŒìˆ˜ ì¬ì¸¡ì • ì˜ˆì •ì…ë‹ˆë‹¤."
    else:
        return f"âœ… ë‹¤ìŒ ì¬ì¸¡ì •ê¹Œì§€ {days_until}ì¼ ë‚¨ì•˜ìŠµë‹ˆë‹¤."

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)