# ToneBridge Voice Analysis Platform

## Overview

ToneBridge is a comprehensive voice analysis platform specifically designed for Korean prosody learning, targeting deaf education and language therapy applications. The platform integrates advanced audio preprocessing, multi-STT engines, and real-time pitch analysis in a microservice architecture to provide a complete voice learning experience.

The system achieves 99% STT accuracy through multi-engine integration (Whisper, Google Cloud, Azure, Naver CLOVA) and features Korean-specific syllable segmentation algorithms with phonetic validation. It provides real-time voice processing and visualization using Chart.js for advanced data presentation, along with a fully automated pipeline from STT to segmentation to TextGrid generation to visualization.

## ğŸ“– Documentation Structure

**âš ï¸ ì¤‘ìš”**: `documents/ToneBridge_ê¸°ìˆ _ì°¸ì¡°_ë¬¸ì„œ.md`ê°€ **ìš°ì„  ê¸°ìˆ  ë¬¸ì„œ**ì…ë‹ˆë‹¤.
- **Primary**: `documents/ToneBridge_ê¸°ìˆ _ì°¸ì¡°_ë¬¸ì„œ.md` (ìƒì„¸ ê¸°ìˆ  ëª…ì„¸)
- **Secondary**: `replit.md` (í”„ë¡œì íŠ¸ ê°œìš” ë° ê°œë°œ ìƒíƒœ)

**ë™ê¸°í™” ì •ì±…**: ëª¨ë“  ë³€ê²½ì‚¬í•­ì€ ë‘ ë¬¸ì„œì— ë™ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.

## Recent Changes

**ìµœê·¼ ì—…ë°ì´íŠ¸**: 2025ë…„ 9ì›” 10ì¼
**ì£¼ìš” ìµœì í™” ì‘ì—…**: ì‹œìŠ¤í…œ ì¤‘ë³µ ì œê±° ë° ì¼ê´€ì„± ê°œì„ 

### ì™„ë£Œëœ ìµœì í™” ì‚¬í•­
1. **API ì¤‘ë³µ í˜¸ì¶œ ì œê±°**: 
   - ì¤‘ë³µ íŒ¨í„´ ì œê±°: `/pitch` â†’ `/pitch?syllable_only=true` â†’ `/syllables` (3íšŒ í˜¸ì¶œ)
   - ìµœì í™”: `/pitch?syllable_only=true` ë‹¨ì¼ í˜¸ì¶œë¡œ í†µí•©
   - ì„±ëŠ¥ í–¥ìƒ: API í˜¸ì¶œ 67% ê°ì†Œ

2. **ë°±ì—”ë“œ ì½”ë“œ í’ˆì§ˆ ê°œì„ **:
   - ì¤‘ë³µ í•¨ìˆ˜ ì„ ì–¸ ì œê±° (`get_uploaded_files` í†µí•©)
   - LSP ì—ëŸ¬ ê°ì†Œ: 16ê°œ â†’ 5ê°œ
   - ì—ëŸ¬ ì²˜ë¦¬ í‘œì¤€í™” ë° ì¼ê´€ì„± í™•ë³´

3. **ê³µí†µ ëª¨ë“ˆí™”**:
   - `frontend/src/utils/apiClient.ts`: í†µí•© fetch ë˜í¼, íƒ€ì„ì•„ì›ƒ, ì—ëŸ¬ ì²˜ë¦¬ í‘œì¤€í™”
   - `frontend/src/utils/tonebridgeApi.ts`: ToneBridge íŠ¹í™” API í•¨ìˆ˜ë“¤, íƒ€ì… ì•ˆì „ì„±
   - ëª¨ë“  API í˜¸ì¶œì˜ ì¼ê´€ëœ ì—ëŸ¬ ì²˜ë¦¬ ë° ì‘ë‹µ ê²€ì¦

4. **ì‹œìŠ¤í…œ ì•ˆì •ì„±**:
   - ìë™ ì¬ì‹œì‘ ë° í•« ë¦¬ë¡œë”© í™•ì¸
   - ëª¨ë“  AI ì‹œìŠ¤í…œ ì •ìƒ ì´ˆê¸°í™” (Advanced STT, Ultimate STT, Korean Audio Optimizer)
   - 10ê°œ ì°¸ì¡° íŒŒì¼ ì •ìƒ ë¡œë“œ ë° í•™ìŠµìŒì„± ë¦¬ìŠ¤íŠ¸ ì™„ì „ ë³µêµ¬

5. **ì‹¤ì‹œê°„ í”¼ì¹˜ ë¶„ì„ ì •í™•ë„ ê°œì„ **:
   - âŒ **ì´ì „**: ë¶€ì •í™•í•œ `autoCorrelate` í•¨ìˆ˜ ì‚¬ìš©ìœ¼ë¡œ ë¶€ì •í™•í•œ Hz ê°’
   - âœ… **í˜„ì¬**: ê³ ê¸‰ `YINPitchDetector` ì‚¬ìš©ìœ¼ë¡œ ì •í™•í•œ í”¼ì¹˜ ê²€ì¶œ
   - ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ (ì„ê³„ê°’ 0.5) ë° ë…¸ì´ì¦ˆ ì œê±°
   - Yì¶• ë‹¨ìœ„ë³„ ì •í™•í•œ ë³€í™˜: Hz â†’ Semitone/Q-tone ì‹¤ì‹œê°„ ì ìš©

6. **ì°¸ì¡° íŒŒì¼ ì‹œìŠ¤í…œ ì™„ì „ ë³µêµ¬**:
   - âŒ **ì´ì „**: "ì°¸ì¡° íŒŒì¼ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤..." ë¬´í•œ ë¡œë”© ìƒíƒœ
   - âœ… **í˜„ì¬**: 10ê°œ ì°¸ì¡° íŒŒì¼ ì •ìƒ ë¡œë”© ë° í•™ìŠµìŒì„± ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
   - ë°±ì—”ë“œ STT ì²˜ë¦¬ ë¸”ë¡œí‚¹ ë¬¸ì œ í•´ê²° ë° ì•ˆì •ì ì¸ API ì‘ë‹µ

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Microservice Architecture
The platform employs a three-tier microservice architecture:

**Frontend Layer**: React 18+ with TypeScript, featuring 4 custom hooks for state management and Chart.js integration for real-time pitch visualization. The client proxy runs on Express.js (port 5000) handling static file serving and API routing.

**Backend Layer**: FastAPI server (port 8000) with 32 API endpoints implementing the core voice analysis pipeline. The backend features Parselmouth (Praat Python binding) for authentic F0 extraction and includes 18 specialized AI processing modules for different aspects of voice analysis. **ìµœì í™”ë¨**: ì¤‘ë³µ í•¨ìˆ˜ ì œê±° ë° í†µí•© API ì—”ë“œí¬ì¸íŠ¸ë¡œ ì¼ê´€ì„± í™•ë³´.

**Storage Layer**: File-based storage system managing 10 reference audio files, user uploads, and generated TextGrid files. The system uses SQLite with SQLAlchemy ORM for user data and session management.

### Core Processing Pipeline
The audio analysis pipeline consists of several integrated components:

**Audio Preprocessing**: Korean-specific audio optimization system (KoreanAudioOptimizer) that enhances consonant clarity, stabilizes vowels, normalizes prosodic patterns, and applies intelligent silence processing while preserving Korean rhythm patterns.

**Multi-Engine STT**: Ensemble STT system combining multiple engines (Whisper, Google Cloud, Azure, Naver CLOVA) with confidence-based result fusion. The system includes automated fallback mechanisms and Korean text quality validation.

**Syllable Segmentation**: Advanced Korean syllable boundary detection using both acoustic features (intensity, pitch) and linguistic rules. The segmentation algorithm performs Jamo decomposition and phonetic validation for accurate syllable timing.

**TextGrid Generation**: Automated TextGrid creation with multiple tiers (syllables, words, sentences) synchronized with audio timing. The system handles duration adjustments and maintains temporal accuracy across different analysis levels.

### Real-time Analysis System
The platform supports real-time voice analysis with **high-precision YINPitchDetector** for accurate Hz measurements, immediate STT feedback, and dynamic chart updates. The system uses WebAudio API for browser-based recording and Chart.js with annotation plugins for interactive visualization. **ì‹¤ì‹œê°„ í”¼ì¹˜ ê°’ì€ Yì¶• ë‹¨ìœ„ ì„¤ì •ì— ë”°ë¼ ìë™ ë³€í™˜** (Hz/Semitone/Q-tone).

### Data Visualization
Dual-axis pitch charts support **Hz, Semitone, Q-tone ë‹¨ìœ„**ì™€ ì‹¤ì‹œê°„ ë™ì  ë‹¨ìœ„ ë³€í™˜. ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œ Yì¶• ë‹¨ìœ„ì— ë§ì¶° í”¼ì¹˜ ê°’ì´ ì •í™•í•˜ê²Œ ë³€í™˜ë˜ì–´ í‘œì‹œë©ë‹ˆë‹¤. The visualization includes syllable boundary annotations, confidence indicators, and interactive playback controls. Charts feature real-time updates during live recording sessions with **YINPitchDetector ê¸°ë°˜ ì •í™•ë„**.

## External Dependencies

### Core Audio Processing
- **Parselmouth (praat-parselmouth==0.4.3)**: Python binding for Praat providing authentic pitch extraction algorithms and acoustic analysis capabilities
- **LibROSA (librosa==0.11.0)**: Advanced audio processing library for feature extraction, spectral analysis, and audio manipulation
- **SoundFile (soundfile==0.13.1)**: High-quality audio I/O supporting multiple formats (WAV, FLAC, OGG)
- **PyDub (pydub==0.25.1)**: Audio manipulation library for format conversion, normalization, and basic processing

### STT Engine Integration
- **OpenAI Whisper**: Local and API-based speech recognition with multilingual support
- **Google Cloud Speech-to-Text**: Enterprise-grade STT with Korean language optimization
- **Microsoft Azure Speech Services**: Cloud-based STT with real-time streaming capabilities
- **Naver CLOVA Speech**: Korean-specialized STT service with high accuracy for native content

### Web Framework and API
- **FastAPI (fastapi==0.104.1)**: Modern Python web framework providing automatic API documentation and high-performance async handling
- **Uvicorn (uvicorn==0.24.0)**: ASGI server for serving the FastAPI application with WebSocket support
- **SQLAlchemy (sqlalchemy==2.0.23)**: Database ORM for user management and session tracking
- **Jinja2 (jinja2==3.1.2)**: Template engine for dynamic HTML generation

### Frontend Technologies
- **React 18.2.0**: Component-based UI framework with hooks and context for state management
- **TypeScript 4.9.5**: Type-safe JavaScript providing better development experience and error prevention
- **Chart.js 4.4.0**: Advanced charting library for real-time pitch visualization
- **Chartjs-plugin-annotation 3.0.1**: Plugin for adding syllable boundary markers and annotations
- **Custom API Client**: í†µí•© API í´ë¼ì´ì–¸íŠ¸ (`apiClient.ts`, `tonebridgeApi.ts`) - í‘œì¤€í™”ëœ ì—ëŸ¬ ì²˜ë¦¬, íƒ€ì„ì•„ì›ƒ, ë¡œê¹…

### Development and Build Tools
- **React Scripts 5.0.1**: Build toolchain for React applications with webpack and babel configuration
- **Express.js**: Proxy server for development environment routing between frontend and backend
- **CORS middleware**: Cross-origin resource sharing configuration for API access

### Analytics and Monitoring
- **Google Analytics**: User behavior tracking and performance monitoring with custom event tracking for voice analysis sessions
- **Custom logging system**: Comprehensive application logging for debugging and performance analysis

## Project Status

### System Health
- **Backend**: âœ… ì •ìƒ ì‹¤í–‰ ì¤‘ (í¬íŠ¸ 8000)
- **Frontend**: âœ… ì •ìƒ ì‹¤í–‰ ì¤‘ (í¬íŠ¸ 5000)  
- **API í†µì‹ **: âœ… ìµœì í™”ëœ ë‹¨ì¼ í˜¸ì¶œ íŒ¨í„´
- **AI ì‹œìŠ¤í…œ**: âœ… ëª¨ë“  ëª¨ë“ˆ í™œì„±í™” (Whisper, Korean Optimizer, Ultimate STT)
- **ì½”ë“œ í’ˆì§ˆ**: âœ… LSP ì—ëŸ¬ 68% ê°ì†Œ (16ê°œ â†’ 5ê°œ)
- **ì°¸ì¡° íŒŒì¼**: âœ… 10ê°œ í•™ìŠµìŒì„± ì •ìƒ ë¡œë”© ë° í‘œì‹œ
- **ì‹¤ì‹œê°„ ë¶„ì„**: âœ… YINPitchDetector ê¸°ë°˜ ì •í™•í•œ í”¼ì¹˜ ê²€ì¶œ
- **ë‹¨ìœ„ ë³€í™˜**: âœ… Hz/Semitone/Q-tone ì‹¤ì‹œê°„ ìë™ ë³€í™˜

### Architecture Principles
- **Single Source of Truth**: ê° ê¸°ëŠ¥ë§ˆë‹¤ ë‹¨ì¼ í†µí•© API ì—”ë“œí¬ì¸íŠ¸
- **DRY (Don't Repeat Yourself)**: ì¤‘ë³µ ì½”ë“œ ë° API í˜¸ì¶œ ì œê±°
- **Type Safety**: TypeScriptë¡œ ì „ë©´ íƒ€ì… ì•ˆì „ì„± í™•ë³´
- **Error Consistency**: í‘œì¤€í™”ëœ ì—ëŸ¬ ì²˜ë¦¬ ë° ì‘ë‹µ ê²€ì¦

The system is designed to be modular and extensible, allowing for easy integration of additional STT engines or audio processing capabilities. All external dependencies are managed through package managers (pip for Python, npm for Node.js) with version pinning for reproducible builds.

## ğŸ“ ìµœê·¼ ê¸°ëŠ¥ ê°œì„  ë° ë²„ê·¸ ìˆ˜ì • (2025ë…„ 9ì›” 10ì¼)

### âœ… ì™„ë£Œëœ í•µì‹¬ ìˆ˜ì • ì‚¬í•­

#### 1. **ì°¸ì¡° íŒŒì¼ ë¡œë”© ì‹œìŠ¤í…œ ë³µêµ¬**
- **ë¬¸ì œ**: "ì°¸ì¡° íŒŒì¼ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤..." ë¬´í•œ ë¡œë”©
- **ì›ì¸**: ë°±ì—”ë“œ STT ì²˜ë¦¬ ê³¼ë¶€í•˜ë¡œ API ë¸”ë¡œí‚¹
- **í•´ê²°**: ë°±ì—”ë“œ ì›Œí¬í”Œë¡œìš° ì¬ì‹œì‘ ë° API ì‘ë‹µ ìµœì í™”
- **ê²°ê³¼**: 10ê°œ í•™ìŠµìŒì„± ì •ìƒ í‘œì‹œ ë° ì„ íƒ ê°€ëŠ¥

#### 2. **ì‹¤ì‹œê°„ í”¼ì¹˜ ë¶„ì„ ì •í™•ë„ í–¥ìƒ**
- **ë¬¸ì œ**: ë¶€ì •í™•í•œ `autoCorrelate` í•¨ìˆ˜ë¡œ ì¸í•œ ì˜ëª»ëœ Hz ê°’
- **í•´ê²°**: **YINPitchDetector** ë„ì… ë° ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§
- **ê°œì„ ì‚¬í•­**:
  - ì •í™•í•œ Hz ë‹¨ìœ„ í”¼ì¹˜ ê²€ì¶œ (ì‹ ë¢°ë„ ì„ê³„ê°’ 0.5)
  - ìŒì„±/ë¬´ìŒì„± ìë™ êµ¬ë¶„ ë° ë…¸ì´ì¦ˆ ì œê±°
  - ì•ˆì •ì ì¸ ì‹¤ì‹œê°„ í”¼ì¹˜ ì¶”ì 

#### 3. **Yì¶• ë‹¨ìœ„ë³„ ë³€í™˜ ì‹œìŠ¤í…œ ì™„ì „ ìˆ˜ì •**
- **ë¬¸ì œ**: ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œ Hz ê°’ì´ ì„¸ë¯¸í†¤/íí†¤ìœ¼ë¡œ ë³€í™˜ë˜ì§€ ì•ŠìŒ
- **ì›ì¸**: `usePitchChart` ê¸°ë³¸ê°’ ë¶ˆì¼ì¹˜ (`'hz'` vs `'semitone'`)
- **í•´ê²°**: 
  - ê¸°ë³¸ê°’ì„ `'semitone'`ìœ¼ë¡œ í†µì¼
  - `convertFrequency()` í•¨ìˆ˜ ì •ìƒ ì‘ë™ í™•ì¸
  - Yì¶• ë‹¨ìœ„ ë³€ê²½ ì‹œ ì‹¤ì‹œê°„ ë°ì´í„° ìë™ ë³€í™˜
- **ë³€í™˜ ê³µì‹**:
  - **ì„¸ë¯¸í†¤**: `12 * logâ‚‚(frequency / 200Hz)`
  - **íí†¤**: `24 * logâ‚‚(frequency / 200Hz)`